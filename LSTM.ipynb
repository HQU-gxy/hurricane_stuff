{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2f7424da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 21:37:15.540 | INFO     | __main__:<module>:64 - example_file: c:\\Users\\cross\\Desktop\\code\\hurrican\\CMABSTdata\\CH1950BST.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union\n",
    "from datetime import datetime, timedelta\n",
    "from pydantic import BaseModel\n",
    "from loguru import logger\n",
    "from enum import Enum\n",
    "import random\n",
    "\n",
    "\n",
    "class EndStatus(Enum):\n",
    "    DISSIPATED = 0\n",
    "    MOVE_OUT_OF_RESPONSIBILITY = 1\n",
    "    MERGED = 2\n",
    "    NEARLY_STATIONARY = 3\n",
    "\n",
    "\n",
    "class CycloneCategory(Enum):\n",
    "    BELOW_TD_OR_UNKNOWN = 0\n",
    "    TROPICAL_DEPRESSION = 1  # 热带低压 (TD, 10.8-17.1m/s)\n",
    "    TROPICAL_STORM = 2  # 热带风暴 (TS, 17.2-24.4 m/s)\n",
    "    SEVERE_TROPICAL_STORM = 3  # 强热带风暴 (STS, 24.5-32.6 m/s)\n",
    "    TYPHOON = 4  # 台风 (TY, 32.7-41.4 m/s)\n",
    "    SEVERE_TYPHOON = 5  # 强台风 (STY, 41.5-50.9 m/s)\n",
    "    SUPER_TYPHOON = 6  # 超强台风 (SuperTY, ≥51.0 m/s)\n",
    "    EXTRATROPICAL = 9  # 变性 (The change is complete)\n",
    "\n",
    "\n",
    "class HurricaneHeader(BaseModel):\n",
    "    data_type: int\n",
    "    country_code: int\n",
    "    data_count: int\n",
    "    hurricane_code: int\n",
    "    china_hurricane_code: int\n",
    "    end_status: EndStatus\n",
    "    time_interval_hr: int\n",
    "    hurricane_name: str\n",
    "    dataset_record_time: datetime\n",
    "\n",
    "\n",
    "class HurricaneEntry(BaseModel):\n",
    "    date: datetime\n",
    "    category: CycloneCategory\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    lowest_pressure: int\n",
    "    wind_speed: int\n",
    "\n",
    "\n",
    "class Hurricane(BaseModel):\n",
    "    header: HurricaneHeader\n",
    "    entries: List[HurricaneEntry]\n",
    "\n",
    "\n",
    "script_folder = Path(os.getcwd())\n",
    "dataset_folder = script_folder / \"CMABSTdata\"\n",
    "\n",
    "# https://tcdata.typhoon.org.cn/zjljsjj.html\n",
    "# example_file = dataset_folder / \"CH2022BST.txt\"\n",
    "example_file = dataset_folder / \"CH1950BST.txt\"\n",
    "logger.info(f\"example_file: {example_file}\")\n",
    "\n",
    "\n",
    "def parse_header(line: str) -> HurricaneHeader:\n",
    "    entry = line.split()\n",
    "    data_type = int(entry[0])\n",
    "    country_code = int(entry[1])\n",
    "    data_count = int(entry[2])\n",
    "    hurricane_code = int(entry[3])\n",
    "    try:\n",
    "        china_hurricane_code = int(entry[4])\n",
    "    except ValueError:\n",
    "        # might be a tuple (a,b)\n",
    "        codes = entry[4].split(\",\")\n",
    "        china_hurricane_code = int(codes[0])\n",
    "    hurricane_end_enum = int(entry[5])\n",
    "    end_status = EndStatus(hurricane_end_enum)\n",
    "    time_interval_hr = int(entry[6])\n",
    "    hurricane_name = entry[7]\n",
    "    dataset_record_time = entry[8]\n",
    "    time_format = \"%Y%m%d\"\n",
    "    dataset_record_time = datetime.strptime(dataset_record_time, time_format)\n",
    "    return HurricaneHeader(data_type=data_type,\n",
    "                           country_code=country_code,\n",
    "                           data_count=data_count,\n",
    "                           hurricane_code=hurricane_code,\n",
    "                           china_hurricane_code=china_hurricane_code,\n",
    "                           end_status=end_status,\n",
    "                           time_interval_hr=time_interval_hr,\n",
    "                           hurricane_name=hurricane_name,\n",
    "                           dataset_record_time=dataset_record_time)\n",
    "\n",
    "\n",
    "def parse_entry(line: str) -> HurricaneEntry:\n",
    "    entry = line.split()\n",
    "    date_str = entry[0]\n",
    "    time_format = \"%Y%m%d%H\"\n",
    "    date = datetime.strptime(date_str, time_format)\n",
    "    category = int(entry[1])\n",
    "    hurricane_category = CycloneCategory(category)\n",
    "    latitude = float(int(entry[2])) / 10.0\n",
    "    longitude = float(int(entry[3])) / 10.0\n",
    "    # in hPa\n",
    "    lowest_pressure = int(entry[4])\n",
    "    # 2分钟平均近中心最大风速(MSW, m/s)\n",
    "    # WND=9 表示 MSW < 10m/s,\n",
    "    # WND=0 为缺测\n",
    "    wind_speed = int(entry[5])\n",
    "    # not sure about OWD\n",
    "    return HurricaneEntry(date=date,\n",
    "                          category=hurricane_category,\n",
    "                          latitude=latitude,\n",
    "                          longitude=longitude,\n",
    "                          lowest_pressure=lowest_pressure,\n",
    "                          wind_speed=wind_speed)\n",
    "\n",
    "\n",
    "def parse_dataset(filename: str | Path):\n",
    "    hurricanes: list[Hurricane] = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        try:\n",
    "            while True:\n",
    "                # check if the line is empty\n",
    "                l = f.readline()\n",
    "                if not l:\n",
    "                    break\n",
    "                header = parse_header(l)\n",
    "                count = header.data_count\n",
    "                hurricane_entries = []\n",
    "                for i in range(count):\n",
    "                    entry = parse_entry(f.readline())\n",
    "                    hurricane_entries.append(entry)\n",
    "                hurricane = Hurricane(header=header, entries=hurricane_entries)\n",
    "                hurricanes.append(hurricane)\n",
    "        except ValueError as e:\n",
    "            logger.error(f\"ValueError: {e} for {filename}\")\n",
    "        except IndexError as e:\n",
    "            logger.warning(f\"IndexError: {e} for {filename}\")\n",
    "        except EOFError:\n",
    "            logger.info(f\"EOFError for {filename}\")\n",
    "    return hurricanes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3c4b76a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 21:37:26.885 | INFO     | __main__:<module>:7 - total_dataset: 2469\n"
     ]
    }
   ],
   "source": [
    "total_dataset: list[Hurricane] = []\n",
    "\n",
    "for file in dataset_folder.glob(\"*.txt\"):\n",
    "    hurricanes = parse_dataset(file)\n",
    "    total_dataset.extend(hurricanes)\n",
    "\n",
    "logger.info(f\"total_dataset: {len(total_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4a494943",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatHurricaneEntry(BaseModel):\n",
    "    name: str\n",
    "    china_hurricane_code: int\n",
    "    date: datetime\n",
    "    category: CycloneCategory\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    lowest_pressure: int\n",
    "    wind_speed: int\n",
    "\n",
    "\n",
    "def flat_hurricane_entries(\n",
    "        hurricanes: list[Hurricane]) -> List[FlatHurricaneEntry]:\n",
    "\n",
    "    def flat_one(h: Hurricane):\n",
    "        name = h.header.hurricane_name\n",
    "        hurricane_code = h.header.hurricane_code\n",
    "        entries = h.entries\n",
    "        return [\n",
    "            FlatHurricaneEntry(name=name,\n",
    "                               china_hurricane_code=hurricane_code,\n",
    "                               date=e.date,\n",
    "                               category=e.category,\n",
    "                               latitude=e.latitude,\n",
    "                               longitude=e.longitude,\n",
    "                               lowest_pressure=e.lowest_pressure,\n",
    "                               wind_speed=e.wind_speed) for e in entries\n",
    "        ]\n",
    "\n",
    "    entries = []\n",
    "    for h in hurricanes:\n",
    "        entries.extend(flat_one(h))\n",
    "    return entries\n",
    "\n",
    "\n",
    "flatten_entries = [\n",
    "    e.model_dump() for e in flat_hurricane_entries(total_dataset)\n",
    "]\n",
    "\n",
    "\n",
    "def entry_enum_to_number(entry: dict[str, any]) -> dict[str, any]:\n",
    "    entry['category'] = entry['category'].value\n",
    "    return entry\n",
    "\n",
    "\n",
    "flatten_entries_without_enum = [\n",
    "    entry_enum_to_number(e) for e in flatten_entries\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "03d2810a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Fengshen',\n",
       "  'china_hurricane_code': 7,\n",
       "  'date': datetime.datetime(2008, 6, 19, 6, 0),\n",
       "  'category': 2,\n",
       "  'latitude': 10.2,\n",
       "  'longitude': 130.0,\n",
       "  'lowest_pressure': 990,\n",
       "  'wind_speed': 23},\n",
       " {'name': 'Hester',\n",
       "  'china_hurricane_code': 21,\n",
       "  'date': datetime.datetime(1957, 10, 11, 0, 0),\n",
       "  'category': 9,\n",
       "  'latitude': 51.5,\n",
       "  'longitude': 160.5,\n",
       "  'lowest_pressure': 974,\n",
       "  'wind_speed': 0},\n",
       " {'name': 'Tess',\n",
       "  'china_hurricane_code': 36,\n",
       "  'date': datetime.datetime(1978, 10, 31, 12, 0),\n",
       "  'category': 0,\n",
       "  'latitude': 13.5,\n",
       "  'longitude': 146.5,\n",
       "  'lowest_pressure': 1002,\n",
       "  'wind_speed': 10},\n",
       " {'name': 'Trix',\n",
       "  'china_hurricane_code': 4,\n",
       "  'date': datetime.datetime(1957, 5, 11, 6, 0),\n",
       "  'category': 4,\n",
       "  'latitude': 21.8,\n",
       "  'longitude': 150.4,\n",
       "  'lowest_pressure': 973,\n",
       "  'wind_speed': 40},\n",
       " {'name': 'Judy',\n",
       "  'china_hurricane_code': 24,\n",
       "  'date': datetime.datetime(1957, 10, 19, 18, 0),\n",
       "  'category': 0,\n",
       "  'latitude': 15.1,\n",
       "  'longitude': 152.5,\n",
       "  'lowest_pressure': 1000,\n",
       "  'wind_speed': 0}]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(flatten_entries_without_enum, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6794859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(flatten_entries_without_enum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "58c5c345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       ".pl-dataframe > thead > tr > th {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<table border=\"1\" class=\"dataframe pl-dataframe\">\n",
       "<small>shape: (7, 9)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "describe\n",
       "</th>\n",
       "<th>\n",
       "name\n",
       "</th>\n",
       "<th>\n",
       "china_hurricane_code\n",
       "</th>\n",
       "<th>\n",
       "date\n",
       "</th>\n",
       "<th>\n",
       "category\n",
       "</th>\n",
       "<th>\n",
       "latitude\n",
       "</th>\n",
       "<th>\n",
       "longitude\n",
       "</th>\n",
       "<th>\n",
       "lowest_pressure\n",
       "</th>\n",
       "<th>\n",
       "wind_speed\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;count&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;71705&quot;\n",
       "</td>\n",
       "<td>\n",
       "71705.0\n",
       "</td>\n",
       "<td>\n",
       "&quot;71705&quot;\n",
       "</td>\n",
       "<td>\n",
       "71705.0\n",
       "</td>\n",
       "<td>\n",
       "71705.0\n",
       "</td>\n",
       "<td>\n",
       "71705.0\n",
       "</td>\n",
       "<td>\n",
       "71705.0\n",
       "</td>\n",
       "<td>\n",
       "71705.0\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;null_count&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;0&quot;\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "&quot;0&quot;\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;mean&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "<td>\n",
       "17.650066\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "<td>\n",
       "2.821588\n",
       "</td>\n",
       "<td>\n",
       "20.902251\n",
       "</td>\n",
       "<td>\n",
       "134.228423\n",
       "</td>\n",
       "<td>\n",
       "986.340004\n",
       "</td>\n",
       "<td>\n",
       "23.758218\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;std&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "<td>\n",
       "10.47291\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "<td>\n",
       "2.330128\n",
       "</td>\n",
       "<td>\n",
       "9.283707\n",
       "</td>\n",
       "<td>\n",
       "16.616481\n",
       "</td>\n",
       "<td>\n",
       "20.931241\n",
       "</td>\n",
       "<td>\n",
       "15.36339\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;min&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;(nameless)&quot;\n",
       "</td>\n",
       "<td>\n",
       "1.0\n",
       "</td>\n",
       "<td>\n",
       "&quot;1949-01-13 00:...\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.5\n",
       "</td>\n",
       "<td>\n",
       "95.0\n",
       "</td>\n",
       "<td>\n",
       "870.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;max&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;Zola&quot;\n",
       "</td>\n",
       "<td>\n",
       "53.0\n",
       "</td>\n",
       "<td>\n",
       "&quot;2022-12-13 06:...\n",
       "</td>\n",
       "<td>\n",
       "9.0\n",
       "</td>\n",
       "<td>\n",
       "70.1\n",
       "</td>\n",
       "<td>\n",
       "243.9\n",
       "</td>\n",
       "<td>\n",
       "1022.0\n",
       "</td>\n",
       "<td>\n",
       "110.0\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;median&quot;\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "<td>\n",
       "17.0\n",
       "</td>\n",
       "<td>\n",
       "null\n",
       "</td>\n",
       "<td>\n",
       "2.0\n",
       "</td>\n",
       "<td>\n",
       "19.3\n",
       "</td>\n",
       "<td>\n",
       "132.5\n",
       "</td>\n",
       "<td>\n",
       "995.0\n",
       "</td>\n",
       "<td>\n",
       "20.0\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (7, 9)\n",
       "┌───────────┬───────────┬────────────┬──────────┬─────┬──────────┬─────────┬────────────┬──────────┐\n",
       "│ describe  ┆ name      ┆ china_hurr ┆ date     ┆ ... ┆ latitude ┆ longitu ┆ lowest_pre ┆ wind_spe │\n",
       "│ ---       ┆ ---       ┆ icane_code ┆ ---      ┆     ┆ ---      ┆ de      ┆ ssure      ┆ ed       │\n",
       "│ str       ┆ str       ┆ ---        ┆ str      ┆     ┆ f64      ┆ ---     ┆ ---        ┆ ---      │\n",
       "│           ┆           ┆ f64        ┆          ┆     ┆          ┆ f64     ┆ f64        ┆ f64      │\n",
       "╞═══════════╪═══════════╪════════════╪══════════╪═════╪══════════╪═════════╪════════════╪══════════╡\n",
       "│ count     ┆ 71705     ┆ 71705.0    ┆ 71705    ┆ ... ┆ 71705.0  ┆ 71705.0 ┆ 71705.0    ┆ 71705.0  │\n",
       "│ null_coun ┆ 0         ┆ 0.0        ┆ 0        ┆ ... ┆ 0.0      ┆ 0.0     ┆ 0.0        ┆ 0.0      │\n",
       "│ t         ┆           ┆            ┆          ┆     ┆          ┆         ┆            ┆          │\n",
       "│ mean      ┆ null      ┆ 17.650066  ┆ null     ┆ ... ┆ 20.90225 ┆ 134.228 ┆ 986.340004 ┆ 23.75821 │\n",
       "│           ┆           ┆            ┆          ┆     ┆ 1        ┆ 423     ┆            ┆ 8        │\n",
       "│ std       ┆ null      ┆ 10.47291   ┆ null     ┆ ... ┆ 9.283707 ┆ 16.6164 ┆ 20.931241  ┆ 15.36339 │\n",
       "│           ┆           ┆            ┆          ┆     ┆          ┆ 81      ┆            ┆          │\n",
       "│ min       ┆ (nameless ┆ 1.0        ┆ 1949-01- ┆ ... ┆ 0.5      ┆ 95.0    ┆ 870.0      ┆ 0.0      │\n",
       "│           ┆ )         ┆            ┆ 13 00:00 ┆     ┆          ┆         ┆            ┆          │\n",
       "│           ┆           ┆            ┆ :00.0000 ┆     ┆          ┆         ┆            ┆          │\n",
       "│           ┆           ┆            ┆ 00       ┆     ┆          ┆         ┆            ┆          │\n",
       "│ max       ┆ Zola      ┆ 53.0       ┆ 2022-12- ┆ ... ┆ 70.1     ┆ 243.9   ┆ 1022.0     ┆ 110.0    │\n",
       "│           ┆           ┆            ┆ 13 06:00 ┆     ┆          ┆         ┆            ┆          │\n",
       "│           ┆           ┆            ┆ :00.0000 ┆     ┆          ┆         ┆            ┆          │\n",
       "│           ┆           ┆            ┆ 00       ┆     ┆          ┆         ┆            ┆          │\n",
       "│ median    ┆ null      ┆ 17.0       ┆ null     ┆ ... ┆ 19.3     ┆ 132.5   ┆ 995.0      ┆ 20.0     │\n",
       "└───────────┴───────────┴────────────┴──────────┴─────┴──────────┴─────────┴────────────┴──────────┘"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6e6b34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.write_csv(\"hurricane.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cebaf98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 335/2293 [===>..........................] - ETA: 11s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# 保存模型\u001b[39;00m\n\u001b[0;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Software\\envs\\pytorch\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Software\\envs\\pytorch\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mD:\\Software\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Software\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mD:\\Software\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mD:\\Software\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Software\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mD:\\Software\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mD:\\Software\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "# 文件夹路径\n",
    "folder_path = \"D:\\\\毕业论文\\\\数据集\\\\insert\"\n",
    "\n",
    "# 获取文件夹中所有文件\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "X_all, y_all = [], []\n",
    "\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    data = np.loadtxt(file_path, delimiter=' ')\n",
    "    X, y = create_dataset(data, time_steps)\n",
    "    X_all.extend(X)\n",
    "    y_all.extend(y)\n",
    "\n",
    "X_all = np.array(X_all)\n",
    "y_all = np.array(y_all)\n",
    "\n",
    "# 定义和编译 LSTM 模型\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(X_all.shape[1], X_all.shape[2]), kernel_regularizer=l2(0.01)),\n",
    "    Dense(y_all.shape[1], kernel_regularizer=l2(0.01))\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_all, y_all, epochs=2, batch_size=32)\n",
    "\n",
    "# 保存模型\n",
    "model.save('lstm_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14fb34d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 64)                17920     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,245\n",
      "Trainable params: 18,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 打印模型摘要\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2403529",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch._prims_common'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLSTMModel\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_size, hidden_size, num_layers, output_size):\n",
      "File \u001b[1;32mD:\\Software\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     Parameter \u001b[38;5;28;01mas\u001b[39;00m Parameter,\n\u001b[0;32m      4\u001b[0m     UninitializedParameter \u001b[38;5;28;01mas\u001b[39;00m UninitializedParameter,\n\u001b[0;32m      5\u001b[0m     UninitializedBuffer \u001b[38;5;28;01mas\u001b[39;00m UninitializedBuffer,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataParallel \u001b[38;5;28;01mas\u001b[39;00m DataParallel\n",
      "File \u001b[1;32mD:\\Software\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Identity, Linear, Bilinear, LazyLinear\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv1d, Conv2d, Conv3d, \\\n\u001b[0;32m      4\u001b[0m     ConvTranspose1d, ConvTranspose2d, ConvTranspose3d, \\\n\u001b[0;32m      5\u001b[0m     LazyConv1d, LazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d, LazyConvTranspose3d\n",
      "File \u001b[1;32mD:\\Software\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mweakref\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeviceLikeType\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parameter\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhooks\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch._prims_common'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x) # LSTM层\n",
    "        out = self.fc(out[:, -1, :]) # 全连接层\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
