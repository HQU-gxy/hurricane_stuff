{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f7424da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-22 22:26:34.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mexample_file: /home/crosstyan/code/hurricane_stuff/CMABSTdata/CH1950BST.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union\n",
    "from datetime import datetime, timedelta\n",
    "from pydantic import BaseModel\n",
    "from loguru import logger\n",
    "from enum import Enum\n",
    "import random\n",
    "\n",
    "\n",
    "class EndStatus(Enum):\n",
    "    DISSIPATED = 0\n",
    "    MOVE_OUT_OF_RESPONSIBILITY = 1\n",
    "    MERGED = 2\n",
    "    NEARLY_STATIONARY = 3\n",
    "\n",
    "\n",
    "class CycloneCategory(Enum):\n",
    "    BELOW_TD_OR_UNKNOWN = 0\n",
    "    TROPICAL_DEPRESSION = 1  # 热带低压 (TD, 10.8-17.1m/s)\n",
    "    TROPICAL_STORM = 2  # 热带风暴 (TS, 17.2-24.4 m/s)\n",
    "    SEVERE_TROPICAL_STORM = 3  # 强热带风暴 (STS, 24.5-32.6 m/s)\n",
    "    TYPHOON = 4  # 台风 (TY, 32.7-41.4 m/s)\n",
    "    SEVERE_TYPHOON = 5  # 强台风 (STY, 41.5-50.9 m/s)\n",
    "    SUPER_TYPHOON = 6  # 超强台风 (SuperTY, ≥51.0 m/s)\n",
    "    EXTRATROPICAL = 9  # 变性 (The change is complete)\n",
    "\n",
    "\n",
    "class HurricaneHeader(BaseModel):\n",
    "    data_type: int\n",
    "    country_code: int\n",
    "    data_count: int\n",
    "    hurricane_code: int\n",
    "    china_hurricane_code: int\n",
    "    end_status: EndStatus\n",
    "    time_interval_hr: int\n",
    "    hurricane_name: str\n",
    "    dataset_record_time: datetime\n",
    "\n",
    "\n",
    "class HurricaneEntry(BaseModel):\n",
    "    date: datetime\n",
    "    category: CycloneCategory\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    lowest_pressure: int\n",
    "    wind_speed: int\n",
    "\n",
    "\n",
    "class Hurricane(BaseModel):\n",
    "    header: HurricaneHeader\n",
    "    entries: List[HurricaneEntry]\n",
    "\n",
    "\n",
    "script_folder = Path(os.getcwd())\n",
    "dataset_folder = script_folder / \"CMABSTdata\"\n",
    "\n",
    "# https://tcdata.typhoon.org.cn/zjljsjj.html\n",
    "# example_file = dataset_folder / \"CH2022BST.txt\"\n",
    "example_file = dataset_folder / \"CH1950BST.txt\"\n",
    "logger.info(f\"example_file: {example_file}\")\n",
    "\n",
    "\n",
    "def parse_header(line: str) -> HurricaneHeader:\n",
    "    entry = line.split()\n",
    "    data_type = int(entry[0])\n",
    "    country_code = int(entry[1])\n",
    "    data_count = int(entry[2])\n",
    "    hurricane_code = int(entry[3])\n",
    "    try:\n",
    "        china_hurricane_code = int(entry[4])\n",
    "    except ValueError:\n",
    "        # might be a tuple (a,b)\n",
    "        codes = entry[4].split(\",\")\n",
    "        china_hurricane_code = int(codes[0])\n",
    "    hurricane_end_enum = int(entry[5])\n",
    "    end_status = EndStatus(hurricane_end_enum)\n",
    "    time_interval_hr = int(entry[6])\n",
    "    hurricane_name = entry[7]\n",
    "    dataset_record_time = entry[8]\n",
    "    time_format = \"%Y%m%d\"\n",
    "    dataset_record_time = datetime.strptime(dataset_record_time, time_format)\n",
    "    return HurricaneHeader(data_type=data_type,\n",
    "                           country_code=country_code,\n",
    "                           data_count=data_count,\n",
    "                           hurricane_code=hurricane_code,\n",
    "                           china_hurricane_code=china_hurricane_code,\n",
    "                           end_status=end_status,\n",
    "                           time_interval_hr=time_interval_hr,\n",
    "                           hurricane_name=hurricane_name,\n",
    "                           dataset_record_time=dataset_record_time)\n",
    "\n",
    "\n",
    "def parse_entry(line: str) -> HurricaneEntry:\n",
    "    entry = line.split()\n",
    "    date_str = entry[0]\n",
    "    time_format = \"%Y%m%d%H\"\n",
    "    date = datetime.strptime(date_str, time_format)\n",
    "    category = int(entry[1])\n",
    "    hurricane_category = CycloneCategory(category)\n",
    "    latitude = float(int(entry[2])) / 10.0\n",
    "    longitude = float(int(entry[3])) / 10.0\n",
    "    # in hPa\n",
    "    lowest_pressure = int(entry[4])\n",
    "    # 2分钟平均近中心最大风速(MSW, m/s)\n",
    "    # WND=9 表示 MSW < 10m/s,\n",
    "    # WND=0 为缺测\n",
    "    wind_speed = int(entry[5])\n",
    "    # not sure about OWD\n",
    "    return HurricaneEntry(date=date,\n",
    "                          category=hurricane_category,\n",
    "                          latitude=latitude,\n",
    "                          longitude=longitude,\n",
    "                          lowest_pressure=lowest_pressure,\n",
    "                          wind_speed=wind_speed)\n",
    "\n",
    "\n",
    "def parse_dataset(filename):\n",
    "    hurricanes: list[Hurricane] = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        try:\n",
    "            while True:\n",
    "                # check if the line is empty\n",
    "                l = f.readline()\n",
    "                if not l:\n",
    "                    break\n",
    "                header = parse_header(l)\n",
    "                count = header.data_count\n",
    "                hurricane_entries = []\n",
    "                for i in range(count):\n",
    "                    entry = parse_entry(f.readline())\n",
    "                    hurricane_entries.append(entry)\n",
    "                hurricane = Hurricane(header=header, entries=hurricane_entries)\n",
    "                hurricanes.append(hurricane)\n",
    "        except ValueError as e:\n",
    "            logger.error(f\"ValueError: {e} for {filename}\")\n",
    "        except IndexError as e:\n",
    "            logger.warning(f\"IndexError: {e} for {filename}\")\n",
    "        except EOFError:\n",
    "            logger.info(f\"EOFError for {filename}\")\n",
    "    return hurricanes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c4b76a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-22 22:26:35.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mtotal_dataset: 2469\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "total_dataset: list[Hurricane] = []\n",
    "\n",
    "for file in dataset_folder.glob(\"*.txt\"):\n",
    "    hurricanes = parse_dataset(file)\n",
    "    total_dataset.extend(hurricanes)\n",
    "\n",
    "logger.info(f\"total_dataset: {len(total_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a494943",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatHurricaneEntry(BaseModel):\n",
    "    sample_id: int\n",
    "    name: str\n",
    "    china_hurricane_code: int\n",
    "    date: datetime\n",
    "    category: CycloneCategory\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    lowest_pressure: int\n",
    "    wind_speed: int\n",
    "\n",
    "\n",
    "def flat_hurricane_entries(\n",
    "        hurricanes: list[Hurricane]) -> List[FlatHurricaneEntry]:\n",
    "    counter = 0\n",
    "    def flat_one(h: Hurricane, counter: int = counter):\n",
    "        name = h.header.hurricane_name\n",
    "        hurricane_code = h.header.hurricane_code\n",
    "        entries = h.entries\n",
    "        return [\n",
    "            FlatHurricaneEntry(sample_id=counter,\n",
    "                               name=name,\n",
    "                               china_hurricane_code=hurricane_code,\n",
    "                               date=e.date,\n",
    "                               category=e.category,\n",
    "                               latitude=e.latitude,\n",
    "                               longitude=e.longitude,\n",
    "                               lowest_pressure=e.lowest_pressure,\n",
    "                               wind_speed=e.wind_speed) for e in entries\n",
    "        ]\n",
    "\n",
    "    entries = []\n",
    "    for h in hurricanes:\n",
    "        entries.extend(flat_one(h, counter))\n",
    "        counter += 1\n",
    "    return entries\n",
    "\n",
    "\n",
    "flatten_entries = [\n",
    "    e.model_dump() for e in flat_hurricane_entries(total_dataset)\n",
    "]\n",
    "\n",
    "\n",
    "def entry_enum_to_number(entry: dict[str, any]) -> dict[str, any]:\n",
    "    entry['category'] = entry['category'].value\n",
    "    return entry\n",
    "\n",
    "\n",
    "flatten_entries_without_enum = [\n",
    "    entry_enum_to_number(e) for e in flatten_entries\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6794859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(flatten_entries_without_enum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58c5c345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>sample_id</th><th>name</th><th>china_hurricane_code</th><th>date</th><th>category</th><th>latitude</th><th>longitude</th><th>lowest_pressure</th><th>wind_speed</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>71705.0</td><td>&quot;71705&quot;</td><td>71705.0</td><td>&quot;71705&quot;</td><td>71705.0</td><td>71705.0</td><td>71705.0</td><td>71705.0</td><td>71705.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>1231.50288</td><td>null</td><td>17.650066</td><td>&quot;1983-09-15 19:…</td><td>2.821588</td><td>20.902251</td><td>134.228423</td><td>986.340004</td><td>23.758218</td></tr><tr><td>&quot;std&quot;</td><td>706.358165</td><td>null</td><td>10.47291</td><td>null</td><td>2.330128</td><td>9.283707</td><td>16.616481</td><td>20.931241</td><td>15.36339</td></tr><tr><td>&quot;min&quot;</td><td>0.0</td><td>&quot;(nameless)&quot;</td><td>1.0</td><td>&quot;1949-01-13 00:…</td><td>0.0</td><td>0.5</td><td>95.0</td><td>870.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>625.0</td><td>null</td><td>9.0</td><td>&quot;1965-09-21 06:…</td><td>1.0</td><td>14.2</td><td>121.8</td><td>980.0</td><td>15.0</td></tr><tr><td>&quot;50%&quot;</td><td>1223.0</td><td>null</td><td>17.0</td><td>&quot;1981-08-21 00:…</td><td>2.0</td><td>19.3</td><td>132.5</td><td>995.0</td><td>20.0</td></tr><tr><td>&quot;75%&quot;</td><td>1839.0</td><td>null</td><td>25.0</td><td>&quot;2001-09-03 06:…</td><td>4.0</td><td>25.8</td><td>145.0</td><td>1001.0</td><td>33.0</td></tr><tr><td>&quot;max&quot;</td><td>2468.0</td><td>&quot;Zola&quot;</td><td>53.0</td><td>&quot;2022-12-13 06:…</td><td>9.0</td><td>70.1</td><td>243.9</td><td>1022.0</td><td>110.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ statistic ┆ sample_id ┆ name      ┆ china_hur ┆ … ┆ latitude  ┆ longitude ┆ lowest_pr ┆ wind_spe │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ricane_co ┆   ┆ ---       ┆ ---       ┆ essure    ┆ ed       │\n",
       "│ str       ┆ f64       ┆ str       ┆ de        ┆   ┆ f64       ┆ f64       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ ---       ┆   ┆           ┆           ┆ f64       ┆ f64      │\n",
       "│           ┆           ┆           ┆ f64       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ count     ┆ 71705.0   ┆ 71705     ┆ 71705.0   ┆ … ┆ 71705.0   ┆ 71705.0   ┆ 71705.0   ┆ 71705.0  │\n",
       "│ null_coun ┆ 0.0       ┆ 0         ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ mean      ┆ 1231.5028 ┆ null      ┆ 17.650066 ┆ … ┆ 20.902251 ┆ 134.22842 ┆ 986.34000 ┆ 23.75821 │\n",
       "│           ┆ 8         ┆           ┆           ┆   ┆           ┆ 3         ┆ 4         ┆ 8        │\n",
       "│ std       ┆ 706.35816 ┆ null      ┆ 10.47291  ┆ … ┆ 9.283707  ┆ 16.616481 ┆ 20.931241 ┆ 15.36339 │\n",
       "│           ┆ 5         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ min       ┆ 0.0       ┆ (nameless ┆ 1.0       ┆ … ┆ 0.5       ┆ 95.0      ┆ 870.0     ┆ 0.0      │\n",
       "│           ┆           ┆ )         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 25%       ┆ 625.0     ┆ null      ┆ 9.0       ┆ … ┆ 14.2      ┆ 121.8     ┆ 980.0     ┆ 15.0     │\n",
       "│ 50%       ┆ 1223.0    ┆ null      ┆ 17.0      ┆ … ┆ 19.3      ┆ 132.5     ┆ 995.0     ┆ 20.0     │\n",
       "│ 75%       ┆ 1839.0    ┆ null      ┆ 25.0      ┆ … ┆ 25.8      ┆ 145.0     ┆ 1001.0    ┆ 33.0     │\n",
       "│ max       ┆ 2468.0    ┆ Zola      ┆ 53.0      ┆ … ┆ 70.1      ┆ 243.9     ┆ 1022.0    ┆ 110.0    │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ef8e4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>sample_id</th><th>name</th><th>china_hurricane_code</th><th>date</th><th>category</th><th>latitude</th><th>longitude</th><th>lowest_pressure</th><th>wind_speed</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>65796.0</td><td>&quot;65796&quot;</td><td>65796.0</td><td>&quot;65796&quot;</td><td>65796.0</td><td>65796.0</td><td>65796.0</td><td>65796.0</td><td>65796.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>1246.461107</td><td>null</td><td>17.502265</td><td>&quot;1985-09-05 05:…</td><td>2.866664</td><td>20.73495</td><td>133.459558</td><td>984.894963</td><td>25.891893</td></tr><tr><td>&quot;std&quot;</td><td>698.361356</td><td>null</td><td>10.381192</td><td>null</td><td>2.121499</td><td>8.752285</td><td>16.292624</td><td>21.13435</td><td>14.21218</td></tr><tr><td>&quot;min&quot;</td><td>0.0</td><td>&quot;(nameless)&quot;</td><td>1.0</td><td>&quot;1949-01-15 00:…</td><td>0.0</td><td>0.5</td><td>95.0</td><td>870.0</td><td>8.0</td></tr><tr><td>&quot;25%&quot;</td><td>656.0</td><td>null</td><td>9.0</td><td>&quot;1968-06-01 00:…</td><td>1.0</td><td>14.5</td><td>121.2</td><td>975.0</td><td>15.0</td></tr><tr><td>&quot;50%&quot;</td><td>1232.0</td><td>null</td><td>17.0</td><td>&quot;1984-10-31 00:…</td><td>2.0</td><td>19.4</td><td>131.7</td><td>992.0</td><td>20.0</td></tr><tr><td>&quot;75%&quot;</td><td>1843.0</td><td>null</td><td>25.0</td><td>&quot;2003-06-17 18:…</td><td>4.0</td><td>25.5</td><td>143.9</td><td>1000.0</td><td>35.0</td></tr><tr><td>&quot;max&quot;</td><td>2468.0</td><td>&quot;Zola&quot;</td><td>53.0</td><td>&quot;2022-12-13 06:…</td><td>9.0</td><td>70.1</td><td>243.9</td><td>1016.0</td><td>110.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬──────────┬───────────┬───────────┬───────────┐\n",
       "│ statistic ┆ sample_id ┆ name      ┆ china_hur ┆ … ┆ latitude ┆ longitude ┆ lowest_pr ┆ wind_spee │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ricane_co ┆   ┆ ---      ┆ ---       ┆ essure    ┆ d         │\n",
       "│ str       ┆ f64       ┆ str       ┆ de        ┆   ┆ f64      ┆ f64       ┆ ---       ┆ ---       │\n",
       "│           ┆           ┆           ┆ ---       ┆   ┆          ┆           ┆ f64       ┆ f64       │\n",
       "│           ┆           ┆           ┆ f64       ┆   ┆          ┆           ┆           ┆           │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ count     ┆ 65796.0   ┆ 65796     ┆ 65796.0   ┆ … ┆ 65796.0  ┆ 65796.0   ┆ 65796.0   ┆ 65796.0   │\n",
       "│ null_coun ┆ 0.0       ┆ 0         ┆ 0.0       ┆ … ┆ 0.0      ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ t         ┆           ┆           ┆           ┆   ┆          ┆           ┆           ┆           │\n",
       "│ mean      ┆ 1246.4611 ┆ null      ┆ 17.502265 ┆ … ┆ 20.73495 ┆ 133.45955 ┆ 984.89496 ┆ 25.891893 │\n",
       "│           ┆ 07        ┆           ┆           ┆   ┆          ┆ 8         ┆ 3         ┆           │\n",
       "│ std       ┆ 698.36135 ┆ null      ┆ 10.381192 ┆ … ┆ 8.752285 ┆ 16.292624 ┆ 21.13435  ┆ 14.21218  │\n",
       "│           ┆ 6         ┆           ┆           ┆   ┆          ┆           ┆           ┆           │\n",
       "│ min       ┆ 0.0       ┆ (nameless ┆ 1.0       ┆ … ┆ 0.5      ┆ 95.0      ┆ 870.0     ┆ 8.0       │\n",
       "│           ┆           ┆ )         ┆           ┆   ┆          ┆           ┆           ┆           │\n",
       "│ 25%       ┆ 656.0     ┆ null      ┆ 9.0       ┆ … ┆ 14.5     ┆ 121.2     ┆ 975.0     ┆ 15.0      │\n",
       "│ 50%       ┆ 1232.0    ┆ null      ┆ 17.0      ┆ … ┆ 19.4     ┆ 131.7     ┆ 992.0     ┆ 20.0      │\n",
       "│ 75%       ┆ 1843.0    ┆ null      ┆ 25.0      ┆ … ┆ 25.5     ┆ 143.9     ┆ 1000.0    ┆ 35.0      │\n",
       "│ max       ┆ 2468.0    ┆ Zola      ┆ 53.0      ┆ … ┆ 70.1     ┆ 243.9     ┆ 1016.0    ┆ 110.0     │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴──────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df.filter(df[\"wind_speed\"] != 0)\n",
    "df_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e0d9c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-22 22:27:05.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1m2013-01-02 12:00:00 -> (1.2246467991473532e-16, -1.0) (0.03442161162274574, 0.9994074007397048)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "time = df[\"date\"][6]\n",
    "assert isinstance(time, datetime)\n",
    "# use sin/cos to normalize the day in a year and the hour in a day\n",
    "\n",
    "def sinusoidal_hour_in_day(dt: datetime) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Return sin and cos corresponding to the hour of day from a datetime object.\n",
    "    \"\"\"\n",
    "    # Extract the hour from the datetime object\n",
    "    hour = dt.hour\n",
    "\n",
    "    # Calculate the radians for the given hour\n",
    "    radians_per_hour = 2 * math.pi / 24\n",
    "    hour_in_radians = hour * radians_per_hour\n",
    "\n",
    "    # Return the sine and cosine values\n",
    "    return math.sin(hour_in_radians), math.cos(hour_in_radians)\n",
    "\n",
    "def sinusoidal_day_in_year(dt: datetime) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Return sin and cos corresponding to the day of year from a datetime object.\n",
    "    \"\"\"\n",
    "    # Extract the day of year from the datetime object\n",
    "    day_of_year = dt.timetuple().tm_yday\n",
    "\n",
    "    # Handle leap years\n",
    "    year_length = 366 if dt.year % 4 == 0 and (dt.year % 100 != 0 or dt.year % 400 == 0) else 365\n",
    "\n",
    "    # Calculate the radians for the given day of year\n",
    "    radians_per_day = 2 * math.pi / year_length\n",
    "    day_in_radians = day_of_year * radians_per_day\n",
    "\n",
    "    # Return the sine and cosine values\n",
    "    return math.sin(day_in_radians), math.cos(day_in_radians)\n",
    "\n",
    "logger.info(f\"{time} -> {sinusoidal_hour_in_day(time)} {sinusoidal_day_in_year(time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8084585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# longitude and latitude\n",
    "lat_long_scaler = MinMaxScaler()\n",
    "latitude = lat_long_scaler.fit_transform(df_filtered[\"latitude\"].to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "longitude = lat_long_scaler.fit_transform(df_filtered[\"longitude\"].to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# wind speed\n",
    "wind_scaler = StandardScaler()\n",
    "wind_speed = wind_scaler.fit_transform(df_filtered[\"wind_speed\"].to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# lowest pressure\n",
    "lowest_pressure_scaler = StandardScaler()\n",
    "lowest_pressure = lowest_pressure_scaler.fit_transform(df_filtered[\"lowest_pressure\"].to_numpy().reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8c9f384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23102/1380966143.py:2: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  df_filtered[\"date\"].map_elements(lambda x: sinusoidal_day_in_year(x)[0]).alias(\"sin_day_in_year\"),\n",
      "/tmp/ipykernel_23102/1380966143.py:3: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  df_filtered[\"date\"].map_elements(lambda x: sinusoidal_day_in_year(x)[1]).alias(\"cos_day_in_year\"),\n",
      "/tmp/ipykernel_23102/1380966143.py:4: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  df_filtered[\"date\"].map_elements(lambda x: sinusoidal_hour_in_day(x)[0]).alias(\"sin_hour_in_day\"),\n",
      "/tmp/ipykernel_23102/1380966143.py:5: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  df_filtered[\"date\"].map_elements(lambda x: sinusoidal_hour_in_day(x)[1]).alias(\"cos_hour_in_day\"),\n"
     ]
    }
   ],
   "source": [
    "with_normalized_time = df_filtered.with_columns([\n",
    "    df_filtered[\"date\"].map_elements(lambda x: sinusoidal_day_in_year(x)[0]).alias(\"sin_day_in_year\"),\n",
    "    df_filtered[\"date\"].map_elements(lambda x: sinusoidal_day_in_year(x)[1]).alias(\"cos_day_in_year\"),\n",
    "    df_filtered[\"date\"].map_elements(lambda x: sinusoidal_hour_in_day(x)[0]).alias(\"sin_hour_in_day\"),\n",
    "    df_filtered[\"date\"].map_elements(lambda x: sinusoidal_hour_in_day(x)[1]).alias(\"cos_hour_in_day\"),\n",
    "    pl.Series(\"latitude_norm\", latitude),\n",
    "    pl.Series(\"longitude_norm\", longitude),\n",
    "    pl.Series(\"wind_speed_norm\", wind_speed),\n",
    "    pl.Series(\"lowest_pressure_norm\", lowest_pressure),\n",
    "])\n",
    "\n",
    "df_features = with_normalized_time.select([\n",
    "    \"sample_id\",\n",
    "    \"sin_day_in_year\",\n",
    "    \"cos_day_in_year\",\n",
    "    \"sin_hour_in_day\",\n",
    "    \"cos_hour_in_day\",\n",
    "    \"latitude_norm\",\n",
    "    \"longitude_norm\",\n",
    "    \"wind_speed_norm\",\n",
    "    \"lowest_pressure_norm\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65de21e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>sample_id</th><th>sin_day_in_year</th><th>cos_day_in_year</th><th>sin_hour_in_day</th><th>cos_hour_in_day</th><th>latitude_norm</th><th>longitude_norm</th><th>wind_speed_norm</th><th>lowest_pressure_norm</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>65796.0</td><td>65796.0</td><td>65796.0</td><td>65796.0</td><td>65796.0</td><td>65796.0</td><td>65796.0</td><td>65796.0</td><td>65796.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>1246.461107</td><td>-0.498177</td><td>-0.264362</td><td>0.006157</td><td>0.003637</td><td>0.290732</td><td>0.258291</td><td>7.5743e-17</td><td>-2.4017e-16</td></tr><tr><td>&quot;std&quot;</td><td>698.361356</td><td>0.550623</td><td>0.615432</td><td>0.705854</td><td>0.708332</td><td>0.125751</td><td>0.10942</td><td>1.000008</td><td>1.000008</td></tr><tr><td>&quot;min&quot;</td><td>0.0</td><td>-0.999991</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>0.0</td><td>0.0</td><td>-1.258922</td><td>-5.43645</td></tr><tr><td>&quot;25%&quot;</td><td>656.0</td><td>-0.927542</td><td>-0.809017</td><td>0.0</td><td>-0.707107</td><td>0.201149</td><td>0.175957</td><td>-0.766383</td><td>-0.468197</td></tr><tr><td>&quot;50%&quot;</td><td>1232.0</td><td>-0.699458</td><td>-0.413279</td><td>1.2246e-16</td><td>6.1232e-17</td><td>0.271552</td><td>0.246474</td><td>-0.41457</td><td>0.336187</td></tr><tr><td>&quot;75%&quot;</td><td>1843.0</td><td>-0.263665</td><td>0.209315</td><td>1.0</td><td>1.0</td><td>0.359195</td><td>0.328408</td><td>0.640871</td><td>0.71472</td></tr><tr><td>&quot;max&quot;</td><td>2468.0</td><td>0.999991</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>5.918075</td><td>1.471788</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ statistic ┆ sample_id ┆ sin_day_i ┆ cos_day_i ┆ … ┆ latitude_ ┆ longitude ┆ wind_spee ┆ lowest_p │\n",
       "│ ---       ┆ ---       ┆ n_year    ┆ n_year    ┆   ┆ norm      ┆ _norm     ┆ d_norm    ┆ ressure_ │\n",
       "│ str       ┆ f64       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ norm     │\n",
       "│           ┆           ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ count     ┆ 65796.0   ┆ 65796.0   ┆ 65796.0   ┆ … ┆ 65796.0   ┆ 65796.0   ┆ 65796.0   ┆ 65796.0  │\n",
       "│ null_coun ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ mean      ┆ 1246.4611 ┆ -0.498177 ┆ -0.264362 ┆ … ┆ 0.290732  ┆ 0.258291  ┆ 7.5743e-1 ┆ -2.4017e │\n",
       "│           ┆ 07        ┆           ┆           ┆   ┆           ┆           ┆ 7         ┆ -16      │\n",
       "│ std       ┆ 698.36135 ┆ 0.550623  ┆ 0.615432  ┆ … ┆ 0.125751  ┆ 0.10942   ┆ 1.000008  ┆ 1.000008 │\n",
       "│           ┆ 6         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ min       ┆ 0.0       ┆ -0.999991 ┆ -1.0      ┆ … ┆ 0.0       ┆ 0.0       ┆ -1.258922 ┆ -5.43645 │\n",
       "│ 25%       ┆ 656.0     ┆ -0.927542 ┆ -0.809017 ┆ … ┆ 0.201149  ┆ 0.175957  ┆ -0.766383 ┆ -0.46819 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 7        │\n",
       "│ 50%       ┆ 1232.0    ┆ -0.699458 ┆ -0.413279 ┆ … ┆ 0.271552  ┆ 0.246474  ┆ -0.41457  ┆ 0.336187 │\n",
       "│ 75%       ┆ 1843.0    ┆ -0.263665 ┆ 0.209315  ┆ … ┆ 0.359195  ┆ 0.328408  ┆ 0.640871  ┆ 0.71472  │\n",
       "│ max       ┆ 2468.0    ┆ 0.999991  ┆ 1.0       ┆ … ┆ 1.0       ┆ 1.0       ┆ 5.918075  ┆ 1.471788 │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "103e1de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65796"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5c00c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23102/1895117370.py:44: DeprecationWarning: `group_by` iteration will change to always return group identifiers as tuples. Pass `by` as a list to silence this warning, e.g. `group_by(['sample_id'])`.\n",
      "  filtered = filter(filter_out_short_sequence, grouped)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1599, 20, 8), (1599, 20, 1))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((1599, 10, 8), (1599, 10, 4))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy.typing import NDArray\n",
    "from functools import reduce\n",
    "# group by sample_id and iterate over the groups\n",
    "grouped = df_features.group_by(\"sample_id\")\n",
    "from typing import Iterable, Iterator, Tuple, Union\n",
    "\n",
    "EXPECTED_TIMESTAMP_COUNT = 20\n",
    "\n",
    "\n",
    "def filter_out_short_sequence(id_and_df: tuple[int, pl.DataFrame]) -> bool:\n",
    "    return id_and_df[1].height >= EXPECTED_TIMESTAMP_COUNT\n",
    "\n",
    "\n",
    "def pad_or_truncate(\n",
    "        id_and_df: tuple[int, pl.DataFrame]) -> tuple[pl.Series, pl.DataFrame]:\n",
    "    group_id, df = id_and_df\n",
    "    if df.height < EXPECTED_TIMESTAMP_COUNT:\n",
    "        # pad with zeros\n",
    "        diff = EXPECTED_TIMESTAMP_COUNT - df.height\n",
    "        mask = pl.Series(\"mask\", [True] * df.height + [False] * diff)\n",
    "        zeros = pl.DataFrame({\n",
    "            \"sample_id\": [group_id] * diff,\n",
    "            \"sin_day_in_year\": [0.0] * diff,\n",
    "            \"cos_day_in_year\": [0.0] * diff,\n",
    "            \"sin_hour_in_day\": [0.0] * diff,\n",
    "            \"cos_hour_in_day\": [0.0] * diff,\n",
    "            \"latitude_norm\": [0.0] * diff,\n",
    "            \"longitude_norm\": [0.0] * diff,\n",
    "            \"wind_speed_norm\": [0.0] * diff,\n",
    "            \"lowest_pressure_norm\": [0.0] * diff,\n",
    "        })\n",
    "        stacked = df.vstack(zeros)\n",
    "        # sort by date\n",
    "        return mask, stacked.sort(\"date\")\n",
    "    elif df.height >= EXPECTED_TIMESTAMP_COUNT:\n",
    "        # truncate\n",
    "        mask = pl.Series(\"mask\", [True] * EXPECTED_TIMESTAMP_COUNT)\n",
    "        return mask, df.head(EXPECTED_TIMESTAMP_COUNT)\n",
    "    else:\n",
    "        mask = pl.Series(\"mask\", [True] * df.height)\n",
    "        return mask, df\n",
    "\n",
    "\n",
    "filtered = filter(filter_out_short_sequence, grouped)\n",
    "padded = map(pad_or_truncate, filtered)\n",
    "\n",
    "\n",
    "# for some reason, the reduce function is not working\n",
    "def to_tensor(\n",
    "        id_and_df: Iterable[tuple[int,\n",
    "                                  pl.DataFrame]]) -> tuple[NDArray, NDArray]:\n",
    "    init_mask, init_data = np.empty(\n",
    "        (0, EXPECTED_TIMESTAMP_COUNT, 1)), np.empty(\n",
    "            (0, EXPECTED_TIMESTAMP_COUNT, df_features.width))\n",
    "    for mask, df in id_and_df:\n",
    "        current_data = df.to_numpy()\n",
    "        current_mask = np.expand_dims(mask.to_numpy(), axis=-1)\n",
    "        try:\n",
    "            new_data = np.vstack(\n",
    "                (init_data, np.expand_dims(current_data, axis=0)))\n",
    "            new_mask = np.vstack(\n",
    "                (init_mask, np.expand_dims(current_mask, axis=0)))\n",
    "        except ValueError as e:\n",
    "            logger.error(f\"ValueError: {e}\")\n",
    "            logger.info(\n",
    "                f\"init_data: {init_data.shape}, current_data: {current_data.shape}\"\n",
    "            )\n",
    "            logger.info(\n",
    "                f\"init_mask: {init_mask.shape}, current_mask: {current_mask.shape}\"\n",
    "            )\n",
    "            logger.info(\n",
    "                f\"init_data: {init_data}, current_data: {current_data}\")\n",
    "            logger.info(\n",
    "                f\"init_mask: {init_mask}, current_mask: {current_mask}\")\n",
    "\n",
    "        init_data, init_mask = new_data, new_mask\n",
    "    return init_data, init_mask\n",
    "\n",
    "\n",
    "data_with_id, mask = to_tensor(padded)\n",
    "# remove the sample_id column\n",
    "features = data_with_id[:, :, 1:]\n",
    "display((features.shape, mask.shape))\n",
    "\n",
    "# y_train should be the last 4 features\n",
    "y_train = features[:, -10:, -4:]\n",
    "X_train = features[:, :10, :]\n",
    "display((X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acfc35b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65796, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>category</th><th>len</th></tr><tr><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>6</td><td>3914</td></tr><tr><td>1</td><td>17650</td></tr><tr><td>9</td><td>3165</td></tr><tr><td>4</td><td>9429</td></tr><tr><td>0</td><td>4133</td></tr><tr><td>2</td><td>11125</td></tr><tr><td>3</td><td>11435</td></tr><tr><td>5</td><td>4945</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8, 2)\n",
       "┌──────────┬───────┐\n",
       "│ category ┆ len   │\n",
       "│ ---      ┆ ---   │\n",
       "│ i64      ┆ u32   │\n",
       "╞══════════╪═══════╡\n",
       "│ 6        ┆ 3914  │\n",
       "│ 1        ┆ 17650 │\n",
       "│ 9        ┆ 3165  │\n",
       "│ 4        ┆ 9429  │\n",
       "│ 0        ┆ 4133  │\n",
       "│ 2        ┆ 11125 │\n",
       "│ 3        ┆ 11435 │\n",
       "│ 5        ┆ 4945  │\n",
       "└──────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# one hot encoding for category\n",
    "# with sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "category = df_filtered[\"category\"].to_numpy()\n",
    "category = category.reshape(-1, 1)\n",
    "encoder = OneHotEncoder()\n",
    "category = encoder.fit_transform(category)\n",
    "display(category.shape)\n",
    "# get the count of each category\n",
    "category_count = df_filtered.group_by(\"category\").len()\n",
    "display(category_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1e00c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>count</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>2469.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>26.648846</td></tr><tr><td>&quot;std&quot;</td><td>14.383362</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td></tr><tr><td>&quot;25%&quot;</td><td>15.0</td></tr><tr><td>&quot;50%&quot;</td><td>25.0</td></tr><tr><td>&quot;75%&quot;</td><td>36.0</td></tr><tr><td>&quot;max&quot;</td><td>97.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 2)\n",
       "┌────────────┬───────────┐\n",
       "│ statistic  ┆ count     │\n",
       "│ ---        ┆ ---       │\n",
       "│ str        ┆ f64       │\n",
       "╞════════════╪═══════════╡\n",
       "│ count      ┆ 2469.0    │\n",
       "│ null_count ┆ 0.0       │\n",
       "│ mean       ┆ 26.648846 │\n",
       "│ std        ┆ 14.383362 │\n",
       "│ min        ┆ 1.0       │\n",
       "│ 25%        ┆ 15.0      │\n",
       "│ 50%        ┆ 25.0      │\n",
       "│ 75%        ┆ 36.0      │\n",
       "│ max        ┆ 97.0      │\n",
       "└────────────┴───────────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the average count of samples per hurricane (by sample_id)\n",
    "average_samples_per_hurricane = df_features.group_by(\"sample_id\").agg(pl.col(\"sample_id\").count().alias(\"count\")).select(\"count\")\n",
    "average_samples_per_hurricane.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a6287e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(average_samples_per_hurricane[\"count\"], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e20284c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77b804da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "display(K.backend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0db1af2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m18,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,948</span> (74.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,948\u001b[0m (74.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,948</span> (74.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,948\u001b[0m (74.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, LSTM, Dense, Masking\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        LSTM(64, return_sequences=True),\n",
    "        Dense(y_train.shape[2]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.005), loss=\"mean_squared_error\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d359152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 22:27:16.393104: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-22 22:27:17.526853: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-22 22:27:18.194157: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.194593: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.194874: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.194922: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.194962: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.195002: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.305196: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.305282: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.305327: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.305365: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.305401: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.305438: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.331127: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.331384: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.331487: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.331501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-22 22:27:18.331543: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.331552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 1, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-22 22:27:18.331633: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-04-22 22:27:18.331723: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:3c:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.331759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21360 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:3c:00.0, compute capability: 8.9\n",
      "2024-04-22 22:27:18.332751: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-04-22 22:27:18.332854: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-22 22:27:18.332918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6704 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.6042\n",
      "Epoch 1: val_loss improved from inf to 0.55198, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.5961 - val_loss: 0.5520\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.4770\n",
      "Epoch 2: val_loss improved from 0.55198 to 0.50321, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.4772 - val_loss: 0.5032\n",
      "Epoch 3/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.4458\n",
      "Epoch 3: val_loss improved from 0.50321 to 0.47422, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.4452 - val_loss: 0.4742\n",
      "Epoch 4/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4110\n",
      "Epoch 4: val_loss improved from 0.47422 to 0.44670, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.4110 - val_loss: 0.4467\n",
      "Epoch 5/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4176\n",
      "Epoch 5: val_loss did not improve from 0.44670\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4160 - val_loss: 0.4472\n",
      "Epoch 6/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3911\n",
      "Epoch 6: val_loss improved from 0.44670 to 0.43531, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.3914 - val_loss: 0.4353\n",
      "Epoch 7/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3668\n",
      "Epoch 7: val_loss improved from 0.43531 to 0.42726, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3698 - val_loss: 0.4273\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3917\n",
      "Epoch 8: val_loss improved from 0.42726 to 0.42566, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3907 - val_loss: 0.4257\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3641\n",
      "Epoch 9: val_loss improved from 0.42566 to 0.41623, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.3654 - val_loss: 0.4162\n",
      "Epoch 10/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3713\n",
      "Epoch 10: val_loss improved from 0.41623 to 0.41529, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3707 - val_loss: 0.4153\n",
      "Epoch 11/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3793\n",
      "Epoch 11: val_loss did not improve from 0.41529\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3766 - val_loss: 0.4179\n",
      "Epoch 12/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3603\n",
      "Epoch 12: val_loss did not improve from 0.41529\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3615 - val_loss: 0.4189\n",
      "Epoch 13/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3714\n",
      "Epoch 13: val_loss improved from 0.41529 to 0.40661, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3700 - val_loss: 0.4066\n",
      "Epoch 14/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3606\n",
      "Epoch 14: val_loss improved from 0.40661 to 0.40281, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3598 - val_loss: 0.4028\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3744\n",
      "Epoch 15: val_loss improved from 0.40281 to 0.40123, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3727 - val_loss: 0.4012\n",
      "Epoch 16/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3547\n",
      "Epoch 16: val_loss improved from 0.40123 to 0.39532, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3541 - val_loss: 0.3953\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3280\n",
      "Epoch 17: val_loss did not improve from 0.39532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3296 - val_loss: 0.4037\n",
      "Epoch 18/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3662\n",
      "Epoch 18: val_loss improved from 0.39532 to 0.38844, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3628 - val_loss: 0.3884\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3697\n",
      "Epoch 19: val_loss did not improve from 0.38844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3678 - val_loss: 0.3984\n",
      "Epoch 20/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3613\n",
      "Epoch 20: val_loss did not improve from 0.38844\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3579 - val_loss: 0.3902\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3407\n",
      "Epoch 21: val_loss improved from 0.38844 to 0.38792, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3403 - val_loss: 0.3879\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3426\n",
      "Epoch 22: val_loss improved from 0.38792 to 0.38000, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.3419 - val_loss: 0.3800\n",
      "Epoch 23/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3345\n",
      "Epoch 23: val_loss did not improve from 0.38000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3342 - val_loss: 0.3885\n",
      "Epoch 24/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3250\n",
      "Epoch 24: val_loss did not improve from 0.38000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3266 - val_loss: 0.3943\n",
      "Epoch 25/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3407\n",
      "Epoch 25: val_loss did not improve from 0.38000\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3397 - val_loss: 0.3875\n",
      "Epoch 26/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3275\n",
      "Epoch 26: val_loss improved from 0.38000 to 0.37956, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3291 - val_loss: 0.3796\n",
      "Epoch 27/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3235\n",
      "Epoch 27: val_loss did not improve from 0.37956\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3247 - val_loss: 0.3824\n",
      "Epoch 28/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3330\n",
      "Epoch 28: val_loss improved from 0.37956 to 0.37932, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3318 - val_loss: 0.3793\n",
      "Epoch 29/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3320\n",
      "Epoch 29: val_loss improved from 0.37932 to 0.37818, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.3306 - val_loss: 0.3782\n",
      "Epoch 30/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3151\n",
      "Epoch 30: val_loss did not improve from 0.37818\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3174 - val_loss: 0.3845\n",
      "Epoch 31/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3200\n",
      "Epoch 31: val_loss did not improve from 0.37818\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3213 - val_loss: 0.3799\n",
      "Epoch 32/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3223\n",
      "Epoch 32: val_loss did not improve from 0.37818\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3224 - val_loss: 0.3785\n",
      "Epoch 33/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3110\n",
      "Epoch 33: val_loss did not improve from 0.37818\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3129 - val_loss: 0.3828\n",
      "Epoch 34/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3229\n",
      "Epoch 34: val_loss did not improve from 0.37818\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3221 - val_loss: 0.3810\n",
      "Epoch 35/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3241\n",
      "Epoch 35: val_loss did not improve from 0.37818\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3232 - val_loss: 0.3805\n",
      "Epoch 36/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3222\n",
      "Epoch 36: val_loss improved from 0.37818 to 0.37604, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.3224 - val_loss: 0.3760\n",
      "Epoch 37/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3062\n",
      "Epoch 37: val_loss did not improve from 0.37604\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3088 - val_loss: 0.3816\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3300\n",
      "Epoch 38: val_loss improved from 0.37604 to 0.37421, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3291 - val_loss: 0.3742\n",
      "Epoch 39/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3093\n",
      "Epoch 39: val_loss did not improve from 0.37421\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3103 - val_loss: 0.3763\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3083\n",
      "Epoch 40: val_loss did not improve from 0.37421\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3088 - val_loss: 0.3768\n",
      "Epoch 41/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3232\n",
      "Epoch 41: val_loss improved from 0.37421 to 0.37211, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3223 - val_loss: 0.3721\n",
      "Epoch 42/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.2962\n",
      "Epoch 42: val_loss did not improve from 0.37211\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2995 - val_loss: 0.3760\n",
      "Epoch 43/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3164\n",
      "Epoch 43: val_loss improved from 0.37211 to 0.36935, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3154 - val_loss: 0.3693\n",
      "Epoch 44/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3092\n",
      "Epoch 44: val_loss improved from 0.36935 to 0.36692, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3089 - val_loss: 0.3669\n",
      "Epoch 45/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.2999\n",
      "Epoch 45: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3014 - val_loss: 0.3728\n",
      "Epoch 46/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3143\n",
      "Epoch 46: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3125 - val_loss: 0.3768\n",
      "Epoch 47/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3215\n",
      "Epoch 47: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3188 - val_loss: 0.3732\n",
      "Epoch 48/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3023\n",
      "Epoch 48: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3032 - val_loss: 0.3699\n",
      "Epoch 49/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2871\n",
      "Epoch 49: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.2900 - val_loss: 0.3712\n",
      "Epoch 50/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3097\n",
      "Epoch 50: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3086 - val_loss: 0.3733\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.2996\n",
      "Epoch 51: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3004 - val_loss: 0.3817\n",
      "Epoch 52/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3111\n",
      "Epoch 52: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3104 - val_loss: 0.3691\n",
      "Epoch 53/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.2920\n",
      "Epoch 53: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2940 - val_loss: 0.3711\n",
      "Epoch 54/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3046\n",
      "Epoch 54: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3060 - val_loss: 0.3704\n",
      "Epoch 55/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.2940\n",
      "Epoch 55: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2965 - val_loss: 0.3691\n",
      "Epoch 56/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3083\n",
      "Epoch 56: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3069 - val_loss: 0.3790\n",
      "Epoch 57/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.2904\n",
      "Epoch 57: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2927 - val_loss: 0.3748\n",
      "Epoch 58/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3113\n",
      "Epoch 58: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3101 - val_loss: 0.3721\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3164\n",
      "Epoch 59: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.3159 - val_loss: 0.3780\n",
      "Epoch 60/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2887\n",
      "Epoch 60: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2906 - val_loss: 0.3729\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3006\n",
      "Epoch 61: val_loss did not improve from 0.36692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3005 - val_loss: 0.3739\n",
      "Epoch 62/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3001\n",
      "Epoch 62: val_loss improved from 0.36692 to 0.36606, saving model to hurricane_lstm.keras\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2991 - val_loss: 0.3661\n",
      "Epoch 63/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3072\n",
      "Epoch 63: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3048 - val_loss: 0.3784\n",
      "Epoch 64/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3036\n",
      "Epoch 64: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3017 - val_loss: 0.3701\n",
      "Epoch 65/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2952\n",
      "Epoch 65: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.2952 - val_loss: 0.3781\n",
      "Epoch 66/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2846\n",
      "Epoch 66: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.2862 - val_loss: 0.3754\n",
      "Epoch 67/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.2796\n",
      "Epoch 67: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2817 - val_loss: 0.3707\n",
      "Epoch 68/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.2868\n",
      "Epoch 68: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2876 - val_loss: 0.3776\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2750\n",
      "Epoch 69: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.2761 - val_loss: 0.3697\n",
      "Epoch 70/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2780\n",
      "Epoch 70: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.2795 - val_loss: 0.3797\n",
      "Epoch 71/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.2842\n",
      "Epoch 71: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2844 - val_loss: 0.3741\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.2841\n",
      "Epoch 72: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2847 - val_loss: 0.3793\n",
      "Epoch 73/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.2845\n",
      "Epoch 73: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2850 - val_loss: 0.3776\n",
      "Epoch 74/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.2918\n",
      "Epoch 74: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.2909 - val_loss: 0.3687\n",
      "Epoch 75/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2912\n",
      "Epoch 75: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.2900 - val_loss: 0.3873\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2797\n",
      "Epoch 76: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2804 - val_loss: 0.3845\n",
      "Epoch 77/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.2934\n",
      "Epoch 77: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2920 - val_loss: 0.3800\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2755\n",
      "Epoch 78: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2761 - val_loss: 0.3754\n",
      "Epoch 79/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.2710\n",
      "Epoch 79: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2718 - val_loss: 0.3815\n",
      "Epoch 80/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2592\n",
      "Epoch 80: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.2619 - val_loss: 0.3780\n",
      "Epoch 81/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.2622\n",
      "Epoch 81: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.2646 - val_loss: 0.3805\n",
      "Epoch 82/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2747\n",
      "Epoch 82: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.2747 - val_loss: 0.3887\n",
      "Epoch 83/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2709\n",
      "Epoch 83: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.2717 - val_loss: 0.3977\n",
      "Epoch 84/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.2716\n",
      "Epoch 84: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2733 - val_loss: 0.3860\n",
      "Epoch 85/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2654\n",
      "Epoch 85: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.2674 - val_loss: 0.3720\n",
      "Epoch 86/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.2770\n",
      "Epoch 86: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2765 - val_loss: 0.3934\n",
      "Epoch 87/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2739\n",
      "Epoch 87: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.2736 - val_loss: 0.3882\n",
      "Epoch 88/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2568\n",
      "Epoch 88: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.2587 - val_loss: 0.3784\n",
      "Epoch 89/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2745\n",
      "Epoch 89: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.2734 - val_loss: 0.3884\n",
      "Epoch 90/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2719\n",
      "Epoch 90: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.2712 - val_loss: 0.3902\n",
      "Epoch 91/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2690\n",
      "Epoch 91: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.2675 - val_loss: 0.3944\n",
      "Epoch 92/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2624\n",
      "Epoch 92: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.2632 - val_loss: 0.3982\n",
      "Epoch 93/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.2763\n",
      "Epoch 93: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2738 - val_loss: 0.3957\n",
      "Epoch 94/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.2547\n",
      "Epoch 94: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2556 - val_loss: 0.4088\n",
      "Epoch 95/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2677\n",
      "Epoch 95: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.2671 - val_loss: 0.4105\n",
      "Epoch 96/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2657\n",
      "Epoch 96: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.2654 - val_loss: 0.3868\n",
      "Epoch 97/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2548\n",
      "Epoch 97: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.2562 - val_loss: 0.4063\n",
      "Epoch 98/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2683\n",
      "Epoch 98: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.2670 - val_loss: 0.3903\n",
      "Epoch 99/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2657\n",
      "Epoch 99: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.2642 - val_loss: 0.4076\n",
      "Epoch 100/100\n",
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2448\n",
      "Epoch 100: val_loss did not improve from 0.36606\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.2472 - val_loss: 0.4018\n"
     ]
    }
   ],
   "source": [
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"hurricane_lstm.keras\", save_best_only=True, monitor=\"val_loss\", mode=\"min\", verbose=1\n",
    ")\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=128, validation_split=0.2, callbacks=[tensorboard_callback, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7842e2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.70720906e+01, -3.03599596e+00,  9.84894963e+02,\n",
       "         1.16798216e+01],\n",
       "       [-1.87430144e+01, -1.09233406e+00,  1.00602915e+03,\n",
       "         2.58918931e+01],\n",
       "       [-1.87430144e+01, -1.09233406e+00,  9.84894963e+02,\n",
       "         4.01039647e+01],\n",
       "       [-1.87430144e+01, -1.09233406e+00,  9.63760774e+02,\n",
       "         2.58918931e+01],\n",
       "       [-1.87430144e+01, -1.09233406e+00,  9.84894963e+02,\n",
       "         1.16798216e+01],\n",
       "       [-2.03802338e+01,  8.79802074e-01,  1.00602915e+03,\n",
       "         2.58918931e+01],\n",
       "       [-2.03802338e+01,  8.79802074e-01,  9.84894963e+02,\n",
       "         4.01039647e+01],\n",
       "       [-2.03802338e+01,  8.79802074e-01,  9.63760774e+02,\n",
       "         2.58918931e+01],\n",
       "       [-2.03802338e+01,  8.79802074e-01,  9.84894963e+02,\n",
       "         1.16798216e+01],\n",
       "       [-2.19832634e+01,  2.87982805e+00,  1.00602915e+03,\n",
       "         2.58918931e+01]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use the model to predict the next 10 time steps\n",
    "# use the last 10 time steps from the training set\n",
    "X_test = X_train[-1, :, :]\n",
    "X_test = X_test.reshape(1, X_test.shape[0], X_test.shape[1])\n",
    "X_test.shape\n",
    "wind_test=wind_scaler.inverse_transform(X_test[:,:,2])\n",
    "pressure_test = lowest_pressure_scaler.inverse_transform(X_test[:, :, 3])\n",
    "lat_test = lat_long_scaler.inverse_transform(X_test[:, :, 0])\n",
    "long_test = lat_long_scaler.inverse_transform(X_test[:, :, 1])\n",
    "# display((wind_test, pressure_test, lat_test, long_test))\n",
    "test = np.vstack((lat_test, long_test, pressure_test, wind_test)).T\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "403aa27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[134.63638 , 134.05153 , 985.12524 ,  28.587397],\n",
       "       [140.091   , 135.72192 , 973.59937 ,  38.334103],\n",
       "       [146.56557 , 137.44441 , 970.81024 ,  40.448463],\n",
       "       [144.46304 , 129.5969  , 973.14496 ,  36.99827 ],\n",
       "       [143.18835 , 127.22661 , 969.45276 ,  38.05645 ],\n",
       "       [142.84016 , 130.9437  , 970.4415  ,  40.573578],\n",
       "       [143.65883 , 130.9462  , 980.4562  ,  36.32695 ],\n",
       "       [146.64153 , 127.29662 , 980.7624  ,  36.421936],\n",
       "       [149.52463 , 125.692345, 982.2498  ,  35.119446],\n",
       "       [149.47858 , 124.603485, 987.7426  ,  31.065733]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred.shape\n",
    "# reverse the normalization\n",
    "wind_pred = wind_scaler.inverse_transform(y_pred[:, :, 2])\n",
    "pressure_pred = lowest_pressure_scaler.inverse_transform(y_pred[:, :, 3])\n",
    "lat_pred = lat_long_scaler.inverse_transform(y_pred[:, :, 0])\n",
    "long_pred = lat_long_scaler.inverse_transform(y_pred[:, :, 1])\n",
    "# display((wind_pred, pressure_pred, lat_pred, long_pred))\n",
    "pred = np.vstack((lat_pred, long_pred, pressure_pred, wind_pred)).T\n",
    "display(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
