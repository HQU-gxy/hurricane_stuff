{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f7424da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-20 17:19:16.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mexample_file: /home/crosstyan/Code/hurricane_stuff/CMABSTdata/CH1950BST.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union\n",
    "from datetime import datetime, timedelta\n",
    "from pydantic import BaseModel\n",
    "from loguru import logger\n",
    "from enum import Enum\n",
    "import random\n",
    "\n",
    "\n",
    "class EndStatus(Enum):\n",
    "    DISSIPATED = 0\n",
    "    MOVE_OUT_OF_RESPONSIBILITY = 1\n",
    "    MERGED = 2\n",
    "    NEARLY_STATIONARY = 3\n",
    "\n",
    "\n",
    "class CycloneCategory(Enum):\n",
    "    BELOW_TD_OR_UNKNOWN = 0\n",
    "    TROPICAL_DEPRESSION = 1  # 热带低压 (TD, 10.8-17.1m/s)\n",
    "    TROPICAL_STORM = 2  # 热带风暴 (TS, 17.2-24.4 m/s)\n",
    "    SEVERE_TROPICAL_STORM = 3  # 强热带风暴 (STS, 24.5-32.6 m/s)\n",
    "    TYPHOON = 4  # 台风 (TY, 32.7-41.4 m/s)\n",
    "    SEVERE_TYPHOON = 5  # 强台风 (STY, 41.5-50.9 m/s)\n",
    "    SUPER_TYPHOON = 6  # 超强台风 (SuperTY, ≥51.0 m/s)\n",
    "    EXTRATROPICAL = 9  # 变性 (The change is complete)\n",
    "\n",
    "\n",
    "class HurricaneHeader(BaseModel):\n",
    "    data_type: int\n",
    "    country_code: int\n",
    "    data_count: int\n",
    "    hurricane_code: int\n",
    "    china_hurricane_code: int\n",
    "    end_status: EndStatus\n",
    "    time_interval_hr: int\n",
    "    hurricane_name: str\n",
    "    dataset_record_time: datetime\n",
    "\n",
    "\n",
    "class HurricaneEntry(BaseModel):\n",
    "    date: datetime\n",
    "    category: CycloneCategory\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    lowest_pressure: int\n",
    "    wind_speed: int\n",
    "\n",
    "\n",
    "class Hurricane(BaseModel):\n",
    "    header: HurricaneHeader\n",
    "    entries: List[HurricaneEntry]\n",
    "\n",
    "\n",
    "script_folder = Path(os.getcwd())\n",
    "dataset_folder = script_folder / \"CMABSTdata\"\n",
    "\n",
    "# https://tcdata.typhoon.org.cn/zjljsjj.html\n",
    "# example_file = dataset_folder / \"CH2022BST.txt\"\n",
    "example_file = dataset_folder / \"CH1950BST.txt\"\n",
    "logger.info(f\"example_file: {example_file}\")\n",
    "\n",
    "\n",
    "def parse_header(line: str) -> HurricaneHeader:\n",
    "    entry = line.split()\n",
    "    data_type = int(entry[0])\n",
    "    country_code = int(entry[1])\n",
    "    data_count = int(entry[2])\n",
    "    hurricane_code = int(entry[3])\n",
    "    try:\n",
    "        china_hurricane_code = int(entry[4])\n",
    "    except ValueError:\n",
    "        # might be a tuple (a,b)\n",
    "        codes = entry[4].split(\",\")\n",
    "        china_hurricane_code = int(codes[0])\n",
    "    hurricane_end_enum = int(entry[5])\n",
    "    end_status = EndStatus(hurricane_end_enum)\n",
    "    time_interval_hr = int(entry[6])\n",
    "    hurricane_name = entry[7]\n",
    "    dataset_record_time = entry[8]\n",
    "    time_format = \"%Y%m%d\"\n",
    "    dataset_record_time = datetime.strptime(dataset_record_time, time_format)\n",
    "    return HurricaneHeader(data_type=data_type,\n",
    "                           country_code=country_code,\n",
    "                           data_count=data_count,\n",
    "                           hurricane_code=hurricane_code,\n",
    "                           china_hurricane_code=china_hurricane_code,\n",
    "                           end_status=end_status,\n",
    "                           time_interval_hr=time_interval_hr,\n",
    "                           hurricane_name=hurricane_name,\n",
    "                           dataset_record_time=dataset_record_time)\n",
    "\n",
    "\n",
    "def parse_entry(line: str) -> HurricaneEntry:\n",
    "    entry = line.split()\n",
    "    date_str = entry[0]\n",
    "    time_format = \"%Y%m%d%H\"\n",
    "    date = datetime.strptime(date_str, time_format)\n",
    "    category = int(entry[1])\n",
    "    hurricane_category = CycloneCategory(category)\n",
    "    latitude = float(int(entry[2])) / 10.0\n",
    "    longitude = float(int(entry[3])) / 10.0\n",
    "    # in hPa\n",
    "    lowest_pressure = int(entry[4])\n",
    "    # 2分钟平均近中心最大风速(MSW, m/s)\n",
    "    # WND=9 表示 MSW < 10m/s,\n",
    "    # WND=0 为缺测\n",
    "    wind_speed = int(entry[5])\n",
    "    # not sure about OWD\n",
    "    return HurricaneEntry(date=date,\n",
    "                          category=hurricane_category,\n",
    "                          latitude=latitude,\n",
    "                          longitude=longitude,\n",
    "                          lowest_pressure=lowest_pressure,\n",
    "                          wind_speed=wind_speed)\n",
    "\n",
    "\n",
    "def parse_dataset(filename: str | Path):\n",
    "    hurricanes: list[Hurricane] = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        try:\n",
    "            while True:\n",
    "                # check if the line is empty\n",
    "                l = f.readline()\n",
    "                if not l:\n",
    "                    break\n",
    "                header = parse_header(l)\n",
    "                count = header.data_count\n",
    "                hurricane_entries = []\n",
    "                for i in range(count):\n",
    "                    entry = parse_entry(f.readline())\n",
    "                    hurricane_entries.append(entry)\n",
    "                hurricane = Hurricane(header=header, entries=hurricane_entries)\n",
    "                hurricanes.append(hurricane)\n",
    "        except ValueError as e:\n",
    "            logger.error(f\"ValueError: {e} for {filename}\")\n",
    "        except IndexError as e:\n",
    "            logger.warning(f\"IndexError: {e} for {filename}\")\n",
    "        except EOFError:\n",
    "            logger.info(f\"EOFError for {filename}\")\n",
    "    return hurricanes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c4b76a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-20 17:19:17.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mtotal_dataset: 2469\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "total_dataset: list[Hurricane] = []\n",
    "\n",
    "for file in dataset_folder.glob(\"*.txt\"):\n",
    "    hurricanes = parse_dataset(file)\n",
    "    total_dataset.extend(hurricanes)\n",
    "\n",
    "logger.info(f\"total_dataset: {len(total_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a494943",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatHurricaneEntry(BaseModel):\n",
    "    sample_id: int\n",
    "    name: str\n",
    "    china_hurricane_code: int\n",
    "    date: datetime\n",
    "    category: CycloneCategory\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    lowest_pressure: int\n",
    "    wind_speed: int\n",
    "\n",
    "\n",
    "def flat_hurricane_entries(\n",
    "        hurricanes: list[Hurricane]) -> List[FlatHurricaneEntry]:\n",
    "    counter = 0\n",
    "    def flat_one(h: Hurricane, counter: int = counter):\n",
    "        name = h.header.hurricane_name\n",
    "        hurricane_code = h.header.hurricane_code\n",
    "        entries = h.entries\n",
    "        return [\n",
    "            FlatHurricaneEntry(sample_id=counter,\n",
    "                               name=name,\n",
    "                               china_hurricane_code=hurricane_code,\n",
    "                               date=e.date,\n",
    "                               category=e.category,\n",
    "                               latitude=e.latitude,\n",
    "                               longitude=e.longitude,\n",
    "                               lowest_pressure=e.lowest_pressure,\n",
    "                               wind_speed=e.wind_speed) for e in entries\n",
    "        ]\n",
    "\n",
    "    entries = []\n",
    "    for h in hurricanes:\n",
    "        entries.extend(flat_one(h, counter))\n",
    "        counter += 1\n",
    "    return entries\n",
    "\n",
    "\n",
    "flatten_entries = [\n",
    "    e.model_dump() for e in flat_hurricane_entries(total_dataset)\n",
    "]\n",
    "\n",
    "\n",
    "def entry_enum_to_number(entry: dict[str, any]) -> dict[str, any]:\n",
    "    entry['category'] = entry['category'].value\n",
    "    return entry\n",
    "\n",
    "\n",
    "flatten_entries_without_enum = [\n",
    "    entry_enum_to_number(e) for e in flatten_entries\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6794859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(flatten_entries_without_enum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "58c5c345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>sample_id</th><th>name</th><th>china_hurricane_code</th><th>date</th><th>category</th><th>latitude</th><th>longitude</th><th>lowest_pressure</th><th>wind_speed</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>71705.0</td><td>&quot;71705&quot;</td><td>71705.0</td><td>&quot;71705&quot;</td><td>71705.0</td><td>71705.0</td><td>71705.0</td><td>71705.0</td><td>71705.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>1238.613332</td><td>null</td><td>17.650066</td><td>&quot;1983-09-15 19:…</td><td>2.821588</td><td>20.902251</td><td>134.228423</td><td>986.340004</td><td>23.758218</td></tr><tr><td>&quot;std&quot;</td><td>712.786331</td><td>null</td><td>10.47291</td><td>null</td><td>2.330128</td><td>9.283707</td><td>16.616481</td><td>20.931241</td><td>15.36339</td></tr><tr><td>&quot;min&quot;</td><td>0.0</td><td>&quot;(nameless)&quot;</td><td>1.0</td><td>&quot;1949-01-13 00:…</td><td>0.0</td><td>0.5</td><td>95.0</td><td>870.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>621.0</td><td>null</td><td>9.0</td><td>&quot;1965-09-21 06:…</td><td>1.0</td><td>14.2</td><td>121.8</td><td>980.0</td><td>15.0</td></tr><tr><td>&quot;50%&quot;</td><td>1234.0</td><td>null</td><td>17.0</td><td>&quot;1981-08-21 00:…</td><td>2.0</td><td>19.3</td><td>132.5</td><td>995.0</td><td>20.0</td></tr><tr><td>&quot;75%&quot;</td><td>1869.0</td><td>null</td><td>25.0</td><td>&quot;2001-09-03 06:…</td><td>4.0</td><td>25.8</td><td>145.0</td><td>1001.0</td><td>33.0</td></tr><tr><td>&quot;max&quot;</td><td>2468.0</td><td>&quot;Zola&quot;</td><td>53.0</td><td>&quot;2022-12-13 06:…</td><td>9.0</td><td>70.1</td><td>243.9</td><td>1022.0</td><td>110.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ statistic ┆ sample_id ┆ name      ┆ china_hur ┆ … ┆ latitude  ┆ longitude ┆ lowest_pr ┆ wind_spe │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ricane_co ┆   ┆ ---       ┆ ---       ┆ essure    ┆ ed       │\n",
       "│ str       ┆ f64       ┆ str       ┆ de        ┆   ┆ f64       ┆ f64       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ ---       ┆   ┆           ┆           ┆ f64       ┆ f64      │\n",
       "│           ┆           ┆           ┆ f64       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ count     ┆ 71705.0   ┆ 71705     ┆ 71705.0   ┆ … ┆ 71705.0   ┆ 71705.0   ┆ 71705.0   ┆ 71705.0  │\n",
       "│ null_coun ┆ 0.0       ┆ 0         ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ mean      ┆ 1238.6133 ┆ null      ┆ 17.650066 ┆ … ┆ 20.902251 ┆ 134.22842 ┆ 986.34000 ┆ 23.75821 │\n",
       "│           ┆ 32        ┆           ┆           ┆   ┆           ┆ 3         ┆ 4         ┆ 8        │\n",
       "│ std       ┆ 712.78633 ┆ null      ┆ 10.47291  ┆ … ┆ 9.283707  ┆ 16.616481 ┆ 20.931241 ┆ 15.36339 │\n",
       "│           ┆ 1         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ min       ┆ 0.0       ┆ (nameless ┆ 1.0       ┆ … ┆ 0.5       ┆ 95.0      ┆ 870.0     ┆ 0.0      │\n",
       "│           ┆           ┆ )         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 25%       ┆ 621.0     ┆ null      ┆ 9.0       ┆ … ┆ 14.2      ┆ 121.8     ┆ 980.0     ┆ 15.0     │\n",
       "│ 50%       ┆ 1234.0    ┆ null      ┆ 17.0      ┆ … ┆ 19.3      ┆ 132.5     ┆ 995.0     ┆ 20.0     │\n",
       "│ 75%       ┆ 1869.0    ┆ null      ┆ 25.0      ┆ … ┆ 25.8      ┆ 145.0     ┆ 1001.0    ┆ 33.0     │\n",
       "│ max       ┆ 2468.0    ┆ Zola      ┆ 53.0      ┆ … ┆ 70.1      ┆ 243.9     ┆ 1022.0    ┆ 110.0    │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "5ef8e4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>sample_id</th><th>name</th><th>china_hurricane_code</th><th>date</th><th>category</th><th>latitude</th><th>longitude</th><th>lowest_pressure</th><th>wind_speed</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>64747.0</td><td>&quot;64747&quot;</td><td>64747.0</td><td>&quot;64747&quot;</td><td>64747.0</td><td>64747.0</td><td>64747.0</td><td>64747.0</td><td>64747.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>1301.991536</td><td>null</td><td>17.529013</td><td>&quot;1985-06-29 06:…</td><td>2.801829</td><td>20.406011</td><td>132.944987</td><td>984.873832</td><td>25.960832</td></tr><tr><td>&quot;std&quot;</td><td>696.735271</td><td>null</td><td>10.429097</td><td>null</td><td>2.037505</td><td>8.213721</td><td>15.601901</td><td>21.201008</td><td>14.245518</td></tr><tr><td>&quot;min&quot;</td><td>0.0</td><td>&quot;(nameless)&quot;</td><td>1.0</td><td>&quot;1949-01-15 00:…</td><td>0.0</td><td>0.5</td><td>95.0</td><td>870.0</td><td>8.0</td></tr><tr><td>&quot;25%&quot;</td><td>729.0</td><td>null</td><td>9.0</td><td>&quot;1968-02-29 06:…</td><td>1.0</td><td>14.4</td><td>121.0</td><td>975.0</td><td>15.0</td></tr><tr><td>&quot;50%&quot;</td><td>1330.0</td><td>null</td><td>17.0</td><td>&quot;1984-10-08 06:…</td><td>2.0</td><td>19.3</td><td>131.5</td><td>992.0</td><td>20.0</td></tr><tr><td>&quot;75%&quot;</td><td>1908.0</td><td>null</td><td>25.0</td><td>&quot;2002-10-26 18:…</td><td>4.0</td><td>25.3</td><td>143.4</td><td>1000.0</td><td>35.0</td></tr><tr><td>&quot;max&quot;</td><td>2468.0</td><td>&quot;Zola&quot;</td><td>53.0</td><td>&quot;2022-12-13 06:…</td><td>9.0</td><td>45.0</td><td>180.0</td><td>1016.0</td><td>110.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ statistic ┆ sample_id ┆ name      ┆ china_hur ┆ … ┆ latitude  ┆ longitude ┆ lowest_pr ┆ wind_spe │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ricane_co ┆   ┆ ---       ┆ ---       ┆ essure    ┆ ed       │\n",
       "│ str       ┆ f64       ┆ str       ┆ de        ┆   ┆ f64       ┆ f64       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆ ---       ┆   ┆           ┆           ┆ f64       ┆ f64      │\n",
       "│           ┆           ┆           ┆ f64       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ count     ┆ 64747.0   ┆ 64747     ┆ 64747.0   ┆ … ┆ 64747.0   ┆ 64747.0   ┆ 64747.0   ┆ 64747.0  │\n",
       "│ null_coun ┆ 0.0       ┆ 0         ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ mean      ┆ 1301.9915 ┆ null      ┆ 17.529013 ┆ … ┆ 20.406011 ┆ 132.94498 ┆ 984.87383 ┆ 25.96083 │\n",
       "│           ┆ 36        ┆           ┆           ┆   ┆           ┆ 7         ┆ 2         ┆ 2        │\n",
       "│ std       ┆ 696.73527 ┆ null      ┆ 10.429097 ┆ … ┆ 8.213721  ┆ 15.601901 ┆ 21.201008 ┆ 14.24551 │\n",
       "│           ┆ 1         ┆           ┆           ┆   ┆           ┆           ┆           ┆ 8        │\n",
       "│ min       ┆ 0.0       ┆ (nameless ┆ 1.0       ┆ … ┆ 0.5       ┆ 95.0      ┆ 870.0     ┆ 8.0      │\n",
       "│           ┆           ┆ )         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 25%       ┆ 729.0     ┆ null      ┆ 9.0       ┆ … ┆ 14.4      ┆ 121.0     ┆ 975.0     ┆ 15.0     │\n",
       "│ 50%       ┆ 1330.0    ┆ null      ┆ 17.0      ┆ … ┆ 19.3      ┆ 131.5     ┆ 992.0     ┆ 20.0     │\n",
       "│ 75%       ┆ 1908.0    ┆ null      ┆ 25.0      ┆ … ┆ 25.3      ┆ 143.4     ┆ 1000.0    ┆ 35.0     │\n",
       "│ max       ┆ 2468.0    ┆ Zola      ┆ 53.0      ┆ … ┆ 45.0      ┆ 180.0     ┆ 1016.0    ┆ 110.0    │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_q = df[\"latitude\"].quantile(0.98)\n",
    "df_filtered = df.filter(pl.col(\"wind_speed\") != 0).filter(\n",
    "    pl.col(\"longitude\") <= 180).filter(pl.col(\"latitude\") <= lat_q)\n",
    "df_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "433b06b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>latitude</th><th>longitude</th></tr><tr><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>64747.0</td><td>64747.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>20.406011</td><td>132.944987</td></tr><tr><td>&quot;std&quot;</td><td>8.213721</td><td>15.601901</td></tr><tr><td>&quot;min&quot;</td><td>0.5</td><td>95.0</td></tr><tr><td>&quot;25%&quot;</td><td>14.4</td><td>121.0</td></tr><tr><td>&quot;50%&quot;</td><td>19.3</td><td>131.5</td></tr><tr><td>&quot;75%&quot;</td><td>25.3</td><td>143.4</td></tr><tr><td>&quot;max&quot;</td><td>45.0</td><td>180.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 3)\n",
       "┌────────────┬───────────┬────────────┐\n",
       "│ statistic  ┆ latitude  ┆ longitude  │\n",
       "│ ---        ┆ ---       ┆ ---        │\n",
       "│ str        ┆ f64       ┆ f64        │\n",
       "╞════════════╪═══════════╪════════════╡\n",
       "│ count      ┆ 64747.0   ┆ 64747.0    │\n",
       "│ null_count ┆ 0.0       ┆ 0.0        │\n",
       "│ mean       ┆ 20.406011 ┆ 132.944987 │\n",
       "│ std        ┆ 8.213721  ┆ 15.601901  │\n",
       "│ min        ┆ 0.5       ┆ 95.0       │\n",
       "│ 25%        ┆ 14.4      ┆ 121.0      │\n",
       "│ 50%        ┆ 19.3      ┆ 131.5      │\n",
       "│ 75%        ┆ 25.3      ┆ 143.4      │\n",
       "│ max        ┆ 45.0      ┆ 180.0      │\n",
       "└────────────┴───────────┴────────────┘"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.select([pl.col(\"latitude\"), pl.col(\"longitude\")]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "778a4d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(df_filtered[\"latitude\"], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "7627d633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df_filtered[\"longitude\"], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "7bd5a564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-20 18:20:50.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mdevice: cuda\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# check if cuda is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "6e0d9c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-20 18:20:50.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1m1949-01-14 12:00:00 -> (1.2246467991473532e-16, -1.0) (0.2386727660059501, 0.9711000518829505)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "time = df[\"date\"][6]\n",
    "assert isinstance(time, datetime)\n",
    "# use sin/cos to normalize the day in a year and the hour in a day\n",
    "\n",
    "def sinusoidal_hour_in_day(dt: datetime) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Return sin and cos corresponding to the hour of day from a datetime object.\n",
    "    \"\"\"\n",
    "    # Extract the hour from the datetime object\n",
    "    hour = dt.hour\n",
    "\n",
    "    # Calculate the radians for the given hour\n",
    "    radians_per_hour = 2 * math.pi / 24\n",
    "    hour_in_radians = hour * radians_per_hour\n",
    "\n",
    "    # Return the sine and cosine values\n",
    "    return math.sin(hour_in_radians), math.cos(hour_in_radians)\n",
    "\n",
    "def sinusoidal_day_in_year(dt: datetime) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Return sin and cos corresponding to the day of year from a datetime object.\n",
    "    \"\"\"\n",
    "    # Extract the day of year from the datetime object\n",
    "    day_of_year = dt.timetuple().tm_yday\n",
    "\n",
    "    # Handle leap years\n",
    "    year_length = 366 if dt.year % 4 == 0 and (dt.year % 100 != 0 or dt.year % 400 == 0) else 365\n",
    "\n",
    "    # Calculate the radians for the given day of year\n",
    "    radians_per_day = 2 * math.pi / year_length\n",
    "    day_in_radians = day_of_year * radians_per_day\n",
    "\n",
    "    # Return the sine and cosine values\n",
    "    return math.sin(day_in_radians), math.cos(day_in_radians)\n",
    "\n",
    "logger.info(f\"{time} -> {sinusoidal_hour_in_day(time)} {sinusoidal_day_in_year(time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "b8084585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "# longitude and latitude\n",
    "lat_scaler = RobustScaler()\n",
    "latitude = lat_scaler.fit_transform(df_filtered[\"latitude\"].to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "long_scaler = RobustScaler()\n",
    "longitude = long_scaler.fit_transform(df_filtered[\"longitude\"].to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# wind speed\n",
    "wind_scaler = StandardScaler()\n",
    "wind_speed = wind_scaler.fit_transform(df_filtered[\"wind_speed\"].to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "# lowest pressure\n",
    "lowest_pressure_scaler = StandardScaler()\n",
    "lowest_pressure = lowest_pressure_scaler.fit_transform(df_filtered[\"lowest_pressure\"].to_numpy().reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "b2492142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(latitude, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "70168668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGiCAYAAAAGFdlYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABmQ0lEQVR4nO3deVxU9f4/8NeZlXWGnQEFBBfcwDUJS9M00KybaYtmpWlqfbUyu6Xeb4vW76ZX+9rqvda91+yW7beszNz3RFMUBVQURHBh34Z1mOX8/kAmJ3ABgTPL6/l4zOM653xm5nUuAW8+2xFEURRBRERE5MJkUgcgIiIikhoLIiIiInJ5LIiIiIjI5bEgIiIiIpfHgoiIiIhcHgsiIiIicnksiIiIiMjlsSAiIiIil8eCiIiIiFweCyIiIiJyeZIWREuXLsUtt9wCb29vBAUFYfz48cjIyLBpU1dXhzlz5sDf3x9eXl6YOHEiCgoKbNrk5uZi3Lhx8PDwQFBQEF588UWYTCabNrt27cLAgQOhVqvRrVs3rF27tr0vj4iIiByEpAXR7t27MWfOHBw4cABbt26F0WhEQkICqqurrW2ef/55/PTTT/jmm2+we/duXLp0CRMmTLCeN5vNGDduHOrr67F//3588sknWLt2LV599VVrm+zsbIwbNw4jR45ESkoK5s2bhyeffBKbN2/u0OslIiIi+yTY081di4qKEBQUhN27d2P48OGoqKhAYGAgPv/8czzwwAMAgFOnTqFXr15ISkrCrbfeil9++QX33HMPLl26hODgYADA6tWrsWDBAhQVFUGlUmHBggX4+eefkZaWZv2sSZMmoby8HJs2bZLkWomIiMh+KKQOcKWKigoAgJ+fHwAgOTkZRqMRo0ePtrbp2bMnwsPDrQVRUlISYmJirMUQACQmJuLpp59Geno6BgwYgKSkJJv3aGwzb968ZnMYDAYYDAbrc4vFgtLSUvj7+0MQhLa6XCIiImpHoiiisrISoaGhkMmuPShmNwWRxWLBvHnzcNttt6Fv374AgPz8fKhUKvj4+Ni0DQ4ORn5+vrXNlcVQ4/nGc9dqo9frUVtbC3d3d5tzS5cuxZIlS9rs2oiIiEg658+fR+fOna/Zxm4Kojlz5iAtLQ379u2TOgoWLVqE+fPnW59XVFQgPDwc58+fh0ajkTAZERER3Si9Xo+wsDB4e3tft61dFERz587Fhg0bsGfPHpsKTqfTob6+HuXl5Ta9RAUFBdDpdNY2v/32m837Na5Cu7LNH1emFRQUQKPRNOkdAgC1Wg21Wt3kuEajYUFERETkYG5kuoukq8xEUcTcuXPx/fffY8eOHYiMjLQ5P2jQICiVSmzfvt16LCMjA7m5uYiPjwcAxMfHIzU1FYWFhdY2W7duhUajQe/eva1trnyPxjaN70FERESuTdJVZv/zP/+Dzz//HD/88AOio6Otx7VarbXn5umnn8bGjRuxdu1aaDQaPPPMMwCA/fv3A2hYdt+/f3+EhoZi+fLlyM/Px2OPPYYnn3wSb775JoCGZfd9+/bFnDlzMH36dOzYsQPPPvssfv75ZyQmJl43p16vh1arRUVFBXuIiIiIHERLfn9LWhBdrQvr448/xrRp0wA0bMz4wgsv4IsvvoDBYEBiYiL+/ve/W4fDACAnJwdPP/00du3aBU9PT0ydOhXLli2DQvH7iOCuXbvw/PPP48SJE+jcuTNeeeUV62dcDwsiIiIix+MwBZGjYEFERETkeFry+5v3MiMiIiKXx4KIiIiIXB4LIiIiInJ5LIiIiIjI5bEgIiIiIpfHgoiIiIhcHgsiIiIicnksiIiIiMjlsSAiIiIil8eCiIiIiFye4vpNiIhaZvbc51BUVtnkeKCvNz784F0JEhERXRsLIiKy0RbFTFFZJYZNW9jk+N61y246HxFRe2BBREQ2WMwQkStiQUREkuMQGxFJjQUREbWLOqMZZTX18PFQwV0pBwCkpBzFhCnTm7Q9lpqKuf+3rslx9koRUUdhQUREbcZgMmPNvnM4ETwaR/actR7XuCnQJ1QLoyhrdjju0LMPd2RMIqImWBAR0U1pHO6qcAvGBZ/+MCi9AJUWAOChkqOm3gx9nQlJZ0sgu20GKmqN0LorJU5NRGSLBRER3ZTCskqo75iJrLOlAABPlRyVB7/FrGfmw1OtgMFoRmZRFfacLka9fwS+PJSLSbeEsygiIrvCjRmJqNXqTRbk+A3GgcvFUGxnLR6P7wIxNxme6oa/t9RKOfqEajElLhxi+SXUGS3YcPwSjGaLlNGJiGywICKiVjGZLXj2i6Mo9YyAIAB39gzCyOggqBTN/1jRuCthOfgZ3JVyFFfVY9vJAoii2MGpiYiax4KIiFrMbBEx/+tj2JSeD0E040+xoYjppL3+C+v0GBcTApkAnC6oQkZ+06X2RERSYEFERC0iiiIW/5iOH49dgkImILL4ILoEeN7w6zv5uiMuyh8A8GtWCYfOiMgusCAiohb5ZP85fHogB4IAvDOpP3zq8lr8HgPDfODtpkCVwYSjueVtH5KIqIVYEBHRDduZUYjXN5wAACwc0xP3xIa26n0UchmGdm3oJTqcUwqovdosIxFRa7AgIqIbYpB74LkvjsIiAg8O6oxZw6Nu6v2ig70RrFHDaBYh9LijjVISEbUOCyIiui6zRUS2fxz0dSYMCPfBX++PgSAIN/WegiBgaNeAhn+HD4TBaG6LqERErcKCiIiua19mMWrUftC6K/H+5AFXXVrfUmG+7vD3UkFQqJF2Sd8m70lE1BosiIjomnJKqpFyvhwA8NaD/dDZ16PN3lsQBAwI8wEApJwvh8XCfYmISBosiIjoqupNFmw/VQgACKzMwl29g9v8M6KDvSHWVaHKYEJmUVWbvz8R0Y1gQUREV7U/qxiVdSZ4uykQWpHaLp+hkMsgnvsNAKw9UUREHY0FERE161J5LY5dqAAAjOoZBLnYfpOexXO/QRCAvIo6lFbXt9vnEBFdDQsiImpCFEXsPl0EAOgdokGE/43vRN0qhip0ufwZJ/I4uZqIOp5C6gBEZH8y8itRWGmAUi5YN1BMSTmKCVOmN2l7LDUVw9rgM3uHaJBdXI1TeXoMjfKHTHZzy/qJiFqCBRER2bAIcvyaVQIAuKWLHzzVDT8mjBZg2LSFTdofevbhNvncyABPuCvlqK43I6e0BpEtuD8aEdHN4pAZEdko9OqGKkPDROrGJfEdQS4TEK3zBgCc5LAZEXUwSQuiPXv24N5770VoaCgEQcD69ettzguC0OxjxYoV1jZdunRpcn7ZsmU273P8+HEMGzYMbm5uCAsLw/Llyzvi8ogcTrXBhALv7gCAoV39oZB37I+I3iEaAMDZomrUcedqIupAkhZE1dXV6NevH1atWtXs+by8PJvHmjVrIAgCJk6caNPu9ddft2n3zDPPWM/p9XokJCQgIiICycnJWLFiBRYvXoyPPvqoXa+NyBF98VsuzHI1tO5K9Aj27vDPD/RWw99LBbMoIot7EhFRB5J0DtHYsWMxduzYq57X6XQ2z3/44QeMHDkSUVG2N5X09vZu0rbRunXrUF9fjzVr1kClUqFPnz5ISUnBypUrMWvWrJu/CCIHNXvucygqq7Q+t0CG9JBEQOGBwRG+kN3kvcpaq0eQN5KqSnCmoAr+kiQgIlfkMHOICgoK8PPPP2PGjBlNzi1btgz+/v4YMGAAVqxYAZPJZD2XlJSE4cOHQ6VSWY8lJiYiIyMDZWVlzX6WwWCAXq+3eRA5m6KySgybttD68E+YDaPCA2KtHj1DOr53qFH3YC8AQG5ZDUwy1XVaExG1DYdZZfbJJ5/A29sbEyZMsDn+7LPPYuDAgfDz88P+/fuxaNEi5OXlYeXKlQCA/Px8REZG2rwmODjYes7X17fJZy1duhRLlixppyshsj+iKCI5p+EPBDHrVyhkgyTL4uuhQqC3GkWVBpS7h0qWg4hci8MURGvWrMGUKVPg5uZmc3z+/PnWf8fGxkKlUmH27NlYunQp1Gp1qz5r0aJFNu+r1+sRFhbWuuBEDuB8WS3Ka4xQyWWozTkkdRx0D/JCUaUBZR6dpY5CRC7CIYbM9u7di4yMDDz55JPXbRsXFweTyYRz584BaJiHVFBQYNOm8fnV5h2p1WpoNBqbB5EzS7vYcIuOaJ03YJL+1hmNE7or1UEoqTJInIaIXIFDFET//ve/MWjQIPTr1++6bVNSUiCTyRAUFAQAiI+Px549e2A0Gq1ttm7diujo6GaHy4hcTU29ybqiK6aTVuI0DbTuSgR5qwFBwC9p+VLHISIXIGlBVFVVhZSUFKSkpAAAsrOzkZKSgtzcXGsbvV6Pb775ptneoaSkJLzzzjs4duwYzp49i3Xr1uH555/Ho48+ai12HnnkEahUKsyYMQPp6en46quv8O6779oMiRG5shN5elhEIFijRqB364aZ20NjL9HPx/MkTkJErkDSOUSHDx/GyJEjrc8bi5SpU6di7dq1AIAvv/wSoihi8uTJTV6vVqvx5ZdfYvHixTAYDIiMjMTzzz9vU+xotVps2bIFc+bMwaBBgxAQEIBXX32VS+6J0DCZOu1iwypKe+kdatQ9yAv7MotxMLsEhZV1CPJ2u/6LiIhaSdKCaMSIERBF8ZptZs2addXiZeDAgThw4MB1Pyc2NhZ79+5tVUYiZ3axvBYVtQ2TqaXYiPFaNO5KeBhKUKP2x6a0fDwe30XqSETkxBxiDhERtY/TBQ1zh7oFeUHZwbfpuBG+NRcAABs4bEZE7cz+fgISUYcQISCzsKEg6nF5M0R741t7EQBw6FwpCvR1EqchImfGgojIRendglBrNMNdKUeYr4fUcZqlMtdiUIQvRJGTq4mofbEgInJRjZsedg/ygkwmzX3LbsQ9sSEAgJ9TWRARUfthQUTkguqMZpS7dwIAu5tM/Ud3x4RAEIDknDJcKq+VOg4ROSkWREQuaPfpIlhkSnipFQj1se/l7MEaN9zSxQ8AsJG9RETUTlgQEbmgzekNuz93C/KCINjvcFmjxmEzrjYjovbCgojIxZjMFuw8VQgA6BroKXGaGzOmrw4yAUg5X47zpTVSxyEiJ8SCiMjFHMktR1mNEXJzPUK17lLHuSFB3m6Ii/QHwGEzImofLIiIXMy2kwUAAG1dnl2vLvuje/px2IyI2g8LIiIXs+3E5YKo1rEKizF9dFDIBKRerLBuKElE1FZYEBG5kKyiKpwtroZSLkBTVyB1nBbx91Ljjh6BAID1Ry9KnIaInA0LIiIXsv3ycNmtUf6QiyaJ07Tc+AENeyd9f/QiLJZr3xiaiKglWBARuZBtJxtWl43uFSxxkta5q3cwvNUKXCyvxaFzpVLHISInopA6ABG1r9lzn0NRWSXMggLHOt0LCDJ8vfr/cCo1FcOkDtdCbko5xsbo8PXhC/j+6EXERflLHYmInAQLIiInV1RWiWHTFuJscRWOHcuD1l2J0Y89g+OH9kkd7bpSUo5iwpTpNscq1QFA0B34OTUPi//UB25KuUTpiMiZsCAichG5JQ0bGob72eed7ZtjtADDpi20OSaKInK2HENlnSc2peVb5xUREd0MziEichG5pY5XEDVHEAT4V58DAHx2IEfaMETkNFgQEbkAfZ0RZTVGCAIQ5usYu1NfS0DVOShkAg7nlOFUvl7qOETkBFgQEbmAxt4hncYNaieYc6O01CGhT8NKOfYSEVFbYEFE5AIccf7Q9TwaFwEA+P7IRVQZHG9PJSKyLyyIiJycCFjvEO9MBVF8V39EBXiiut6M745ckDoOETk4FkRETq5G6YM6kwUquQw6jZvUcdqMIAiYdlsXAMCHu8/CaLZIG4iIHBqX3RM5uUq3hrk2YX7uDnV3+xvx0OAwvLc9ExfLa7H+6EU8ODjshl/buGHlHwX6euPDD95ty5hE5ABYEBE5Of3lgsiZhssauSnlmDksEkt/OYV/7MrChIGdIb/Boq9xw8o/2rt2WVvHJCIHwCEzIidWbTChWt1wewtnLIgAYMqtEdC6K3G2uBobU/OkjkNEDooFEZETO5hdAlGQQeuuhI+HSuo47cJLrcD02yIBACu3nka9iXOJiKjlOGRG5CSamxNz3qcf4N3NaXuHGk2/vQs+PZCD7OJqrPk1G0/d0VXqSETkYFgQETmJ5ubE/CfpHFBjdPqCyNtNiYVje+LP3xzD+9vP4P4BnRDsRCvqiKj9cciMyElVXr5dhyhanOJ2HdczYUAnDAj3QXW9GUs3npQ6DhE5GBZERE6q8XYdKLvgFLfruB6ZTMCSP/WBIADrUy5hUxonWBPRjWNBROSkGm/XIRZmSpyk48R29sHs4Q3zhxb8NxWXymslTkREjoIFEZETEkURuWWXC6Ii1ymIAOCFhB7o11mLiloj5n2ZAhN3sCaiG8CCiMgJFVYaUGdsuF0HylzrPl9KuQzvTR4AL7UCv50rxZKfTkAURaljEZGdY0FE5IQa5w919nUHRNfrIYnw98RbD8ZCEIBPD+Tg3/uypY5ERHZO0oJoz549uPfeexEaGgpBELB+/Xqb89OmTYMgCDaPMWPG2LQpLS3FlClToNFo4OPjgxkzZqCqqsqmzfHjxzFs2DC4ubkhLCwMy5cvb+9LI5JUY0EU7u/cy+2vZUzfEPzv3b0AAH/deBI/pFyUOBER2TNJC6Lq6mr069cPq1atumqbMWPGIC8vz/r44osvbM5PmTIF6enp2Lp1KzZs2IA9e/Zg1qxZ1vN6vR4JCQmIiIhAcnIyVqxYgcWLF+Ojjz5qt+sikpLRbLFOJnb2/YeuZ8btkZgaHwFRBJ7/KgU/HrskdSQislOSbsw4duxYjB079ppt1Go1dDpds+dOnjyJTZs24dChQxg8eDAA4P3338fdd9+Nt956C6GhoVi3bh3q6+uxZs0aqFQq9OnTBykpKVi5cqVN4UTkLC6W1cIiAho3BXzclVLHkZQgCHjt3j6oNZrx9eELmPflUQDAn/qFSpyMiOyN3c8h2rVrF4KCghAdHY2nn34aJSUl1nNJSUnw8fGxFkMAMHr0aMhkMhw8eNDaZvjw4VCpfr+PU2JiIjIyMlBWVtbsZxoMBuj1epsHkaPIaRwu8/OAINzYnd+dmUwmoHzXGvhXZcMiAs9+fgQjnnwVx1JTpY5GRHbErm/dMWbMGEyYMAGRkZHIysrCX/7yF4wdOxZJSUmQy+XIz89HUFCQzWsUCgX8/PyQn58PAMjPz0dkZKRNm+DgYOs5X1/fJp+7dOlSLFmypJ2uiqh95V5REDmrlJSjmDBlepPjgb7e+PCDd5scLy6rxJSpd2HbyUKcyNMjJyAO5qBzHZCUiByFXRdEkyZNsv47JiYGsbGx6Nq1K3bt2oVRo0a12+cuWrQI8+fPtz7X6/UICwtrt88jaitVdSaUVtcDAMKcuCAyWtDkvm0AsHftsqu+RhAEjO7V8AfUiTw9hEEP4nRBJXoEe7dbTiJyHHY/ZHalqKgoBAQEIDOzYaM5nU6HwsJCmzYmkwmlpaXWeUc6nQ4FBQU2bRqfX21uklqthkajsXkQOYLG3qFgjRpuLnC7jpZqLIp6h2ggCDJsSs/HmYJKqWMRkR1wqILowoULKCkpQUhICAAgPj4e5eXlSE5OtrbZsWMHLBYL4uLirG327NkDo9FobbN161ZER0c3O1xG5MgaC6IIP0+Jk9ivxqLIknsEogj8kp6PzMKq67+QiJyapENmVVVV1t4eAMjOzkZKSgr8/Pzg5+eHJUuWYOLEidDpdMjKysJLL72Ebt26ITExEQDQq1cvjBkzBjNnzsTq1athNBoxd+5cTJo0CaGhDatIHnnkESxZsgQzZszAggULkJaWhnfffRdvv/22JNdM1F5EuMb8oWu52tyiY6mpGHbFc0EQIB79Hj2H3IFT+ZX4JS0Pd8eEoGugV8eFJSK7ImlBdPjwYYwcOdL6vHHeztSpU/GPf/wDx48fxyeffILy8nKEhoYiISEBb7zxBtRqtfU169atw9y5czFq1CjIZDJMnDgR7733nvW8VqvFli1bMGfOHAwaNAgBAQF49dVXueSenE6tUotaoxlKuQCd1k3qOJK42tyiQ88+3ExrEXf1DoYIICO/EhtT8zAuJqTdMxKRfZK0IBoxYsQ17zG0efPm676Hn58fPv/882u2iY2Nxd69e1ucj+h6Zs99DkVlTeegXG21U3vSuzWsnuzs6wG5jMvtb4RMEJDQKxiiKOJ0QRU2puYjUh10/RcSkdOx61VmRPauqKyyxaud2kvl5YLIVYfLWksmE5DYWwezJQ9ZRdXICojHb9mlGBLpJ3U0IupADjWpmoiap68zokodAACIcOH7l7WWTCZgbN8QRPh7QJQpMH3tIaScL5c6FhF1IBZERE5gV0YRREEGXw8lfD1U138BNSGXCbgnJgRedYWoMpgwdc1vOJnHXeqJXAULIiInsO1Ew95aUVwldVMUchm6Fu/HwHAfVNQa8ei/DnJJPpGLYEFE5OCMZgt2ZjRsUBoVwP2HbpZcNOPjJ4agT6gGJdX1mPKvA8gtqZE6FhG1MxZERA7ut+xSVNaZoDDXuexy+7amdVfi0xlx6B7khQK9AY/86wAultdKHYuI2hFXmRE5uK2Xh8u0tXmQCTESp3Eefp4qrHsyDg99mIRzJTUY/eYGdM3fBZXZtjCSYosFImp7LIiIHJgoijYFEbWtII0bPp95Kyb/8wBySoDcqD9h4sDO0LgrrW2k2GKBiNoeh8yIHNixCxW4WF4LN6UMGkPh9V9ALRbq444vZ90KtbEK+joT/nvkAvS1xuu/kIgcCgsiIge2/uhFAEBiHx1kolniNM4rROuO7kV7oHVXQl9nwrcsioicDgsiIgdlNFvw07FLAIDxAzpJnMb5qcy1eGBgZ/i4K1F5uSiqYFFE5DQ4h4icnj3db6wt7TtTjJLqegR4qTCsWwDelzqQC/ByU2DiwM7479ELKK8x4r9HLiBczq0OiJwBCyJyevZ0v7G29P3l4bJ7+4VCIWdnb0exFkVHGoqi00HDkVtSg3DeMoXIofGnKJEDqjKYsOVEPgDgfg6XdTgvtQIPDOwMXw8ljAoPTPooCTkl1VLHIqKbwB4iIgf0Y8ol1BktiAr0REwnrdRxXJKnuqGn6F+/HMQlBGH00o3oUbgHanNDYeToQ7JEroY9REQOxmIR8a99ZwEAU+IiIAiCxIlcl6daAfOva+DnoYJR4YELXe/FwMl/xrBpC5udt0ZE9osFEZGD2X6qEGeLqqFxU+DhW8KkjkOGKkwY2AkaNwUqao348dglGEzcAoHI0XDIjKgFRFFEZmEVUs6XI+1iBbIC4pF3+DzMFhHuKjm81AqEaN1QL3dvtwwf7ckCAEy5NQJean4L2wNPtQLjB3TCN4cvoLDSgI2p+fAHe+6IHAl/mhJdh9kiIimrBD+n5mFXRiHyKup+P+keioornwNIv6QHQu/G/X//FTNuj8SYPro2WwV2JLcMh86VQSkX8MTQLm3yntQ2fD1UuK9/KL5NvoDc0hrU+sRKHYmIWoAFEdFVXCqvxacHcvDf5Ia/+hupFTL0C/NBbCcttvz4X/S9427IZQJq682oqDXifGkt8itqcTS3HHM/P4pwPw/85e6eSOyju6n5PqIoYsWmDACApiIbTz39Pzbnj6WmYlir353aQrDGDYl9dPg5NQ9F3t3w2YEcPHprhNSxiOgGsCAi+oPzpTVYsTkDP6fmwWwRAQAK0Qif6vPQ1l6Ct6EIpmwLjgC4mJqK+x982PYNugI7/vM27nz8eXx2IAe5pTV46rMjiI/yx/+7vy+6Bnq1Ktc3yReQdLYEgsWEexNGQOt+l835Q88+fJVXUkfqFuSF+Ch/JJ0tweIf09ErRINBEb5SxyKi62BBRHRZndGMD3Zk4qO9Z1FvsgAAbo3yw7ShXbB66cu4Y9qCJq+5WhGSfuQAlJZl6CzIofSORoF3DySdLcFdb+3AC2N6Y9bwKChbMIxWXGXAX38+CQAI1Z+E1r1XK66QOsotXXxxMu0Yyj06Y+7nR/Dzs8Pg56mSOhYRXQMLIiIAhZV1mP1pMo7mlgMAhnb1x1/u7oW+l/f4+Qhii97PaIHN7tj6WiN2ZBQip+Ry79PxPCx/INb6/tdiMlvwl+9SUVFrRO8QDdTnz7QoC7VMSspRTJgyvcnxlgxJCoKAiNJk+IVH42xxNZ778ijWPjEEchknWhPZKxZE5LIaf/HVKjXIDLgNRoUHFKIRHzwWd9Pzff5I467Eff1C8cM3X6AibChO5Olx36pfMf22Lpg7sjteeunPze5b4++rgXro49hyogAKmYBlE2Ow+LeWFWfUMn8sZhu1dEhSLprwj0cH4b5V+7D3TDH+ve8sZg3v2lYxiaiNsSAil2W0AAMn/xlfHjoPo8EEXw8lQrI2Y0zf8e3yeYIgwL8mF98+vwiLf0rHz8fz8M+92fj68AV4mkIwdtJseLn9/i1ZXGXAT7sOQn88D0q5gA8eGYjYzj7tko3aR7TOG4vv7YOF36Xirc2nMax7IHqFaKSORUTNYEFErksmx8+peai6XAw9NDgMhzKq2v1jA73VWPXIQDwwqBBLN57E6YIqVPjE4N+/ZiNYo4ZaIUe9yYJ8fR3gHgKVQobVjw7EnT2D2z0btZ3GHkgRgDYgHhXuoZiw4ifcXn8I//zgHanjEdEfsCAilyX0vRt5FXVQKWS4t18o3JTyDv38kdFBGNYtAN8dvYgl63agWh2AAv3vy/sFANqai/jPSw+xZ8gBXTn0NshgwrqDuaiFD47XhUucjIiaw1t3kEvKr6iDLDIOADC2rw6+HtKsAFLIZXhocBiiC3fjidu6YGxfHRJ6ByOhdzCm3dYFUSUHWAw5AU+1AqN6BQEACrx74ODZEokTEdEfsSAilyOKIvacKQIA9ArxRhd/T4kTNdC4KdEj2Bu9QjToFaKBxk0pdSRqQ10DvdA7RAMIAuZ/fQyVdUapIxHRFVgQkcvJLKxCXkUdRFM9hkYFSB2HXMgdPQKhMlXjYnktXv/phNRxiOgKnENELsVsEfFrVsNwhZi5D16JfTr089tijxtyXCqFDMaDnwNDn8Q3yRdw9JcvoDEUAgACfb3x4QfvSpyQyHWxICKXcqawEhW1Rnio5KjM3Atgdod+flvtcUOOy1ScgwFhPjh+oQKF4SORcGsElHIZ9q5dJnU0IpfGITNyKakXKwAAsZ20gJlzOEgat3UNgJdaAX2dCQc4wZrILrAgIpdRUmXApfI6CALQJ/T6t8wgai8qhQx39mxYdXY0txwF+jqJExERh8zIZaRd1AMAogI8bXaEvhLn+FBHiQzwRI9gL5wuqMK2kwUIA+9zRiQlFkTkEoxmC07kNxREMde4oSrn+FBHuqNHIHJLalBcVQ+Vd3ep4xC5NEmHzPbs2YN7770XoaGhEAQB69evt54zGo1YsGABYmJi4OnpidDQUDz++OO4dOmSzXt06dIFgiDYPJYts52cePz4cQwbNgxubm4ICwvD8uXLO+LyyI6cKaxCvckCjZsC4X4eUschAgB4qBQY3iMQAJCn7Y3s4mqJExG5LkkLourqavTr1w+rVq1qcq6mpgZHjhzBK6+8giNHjuC7775DRkYG/vSnPzVp+/rrryMvL8/6eOaZZ6zn9Ho9EhISEBERgeTkZKxYsQKLFy/GRx991K7XRvYls7DhHmW9QjRtehd7opvVU+eNcD8PiIIcr/2YDlEUpY5E5JIkHTIbO3Ysxo4d2+w5rVaLrVu32hz74IMPMGTIEOTm5iI8/Pf7AXl7e0On0zX7PuvWrUN9fT3WrFkDlUqFPn36ICUlBStXrsSsWbOafY3BYIDB8Ps9pfR6fUsvjeyIWZAjt7QGANAtyEviNES2BEHAiOhAfLr/LPacLsLm9HyM6RsidSwil+NQq8wqKiogCAJ8fHxsji9btgz+/v4YMGAAVqxYAZPJZD2XlJSE4cOHQ6X6/V5ViYmJyMjIQFlZWbOfs3TpUmi1WusjLCysXa6HOkalWzDMFhEaNwX8PaW5ZxnRtfh6qCCe2QMAeGbtPtz36ExMmDIds+c+J3EyItfhMAVRXV0dFixYgMmTJ0Oj0ViPP/vss/jyyy+xc+dOzJ49G2+++SZeeukl6/n8/HwEBwfbvFfj8/z8/GY/a9GiRaioqLA+zp8/3w5XRB2l3D0UQMO9pDhcRvbKfHoPNG4KGBUeUNz2BIZNW4iiskqpYxG5DIdYZWY0GvHQQw9BFEX84x//sDk3f/58679jY2OhUqkwe/ZsLF26FGq1ulWfp1arW/1asi8mswUVbg3DD10DOVxGdsxsxB09AvHT8TwczS1ruBEsEXUYu+8haiyGcnJysHXrVpveoebExcXBZDLh3LlzAACdToeCggKbNo3PrzbviJzHb+dKYZar4K6UI0TrJnUcomuKCvRCZIAnLCKwM6MQnF5N1HHsuiBqLIbOnDmDbdu2wd/f/7qvSUlJgUwmQ1BQwy6w8fHx2LNnD4zG32/TsHXrVkRHR8PX17fdspN92HqiofiNDPCETMbhMrJ/d/QIhFwm4EJZLcrcO0sdh8hlSDpkVlVVhczMTOvz7OxspKSkwM/PDyEhIXjggQdw5MgRbNiwAWaz2Trnx8/PDyqVCklJSTh48CBGjhwJb29vJCUl4fnnn8ejjz5qLXYeeeQRLFmyBDNmzMCCBQuQlpaGd999F2+//bYk10ztZ/bc55rMuUjX3QUoNYgM8JQoFVHLaN2VGNLFD0lnS3DRJxY19SZ4qBxidgORQ5P0u+zw4cMYOXKk9XnjfKCpU6di8eLF+PHHHwEA/fv3t3ndzp07MWLECKjVanz55ZdYvHgxDAYDIiMj8fzzz9vMK9JqtdiyZQvmzJmDQYMGISAgAK+++upVl9yT4yoqq7TZZbraYMKRfdkQRQs6+7pLmIyoZQaG+yD9UgX0de74aM9ZzBvdQ+pIRE5P0oJoxIgR19yE7HoblA0cOBAHDhy47ufExsZi7969Lc5Hju1CWW3DPyry4aaMljYMUQso5DLc3i0AG9Py8eHus5h0Szh0nANH1K7seg4R0c24UNawGaNYfFbiJEQt1y3IC56GYtQazVi++ZTUcYicHgsiclqNPURicbbESYhaThAEdC4/DgD47shFpF+qkDgRkXNjQUROqarOhPJaIwQAKDkncRqi1vGsL8O9/Ro2Fn1rc4bEaYicG5cukFNqHC4L9FYjz2S4Tmv7lZJyFBOmTLc5diw1FcMkykMd74W7euCX1DzszCjCwbMliIu6/vYjRNRyLIjIKZ2/PFwW5uuBPImz3AyjBTYr5wDg0LMPS5SGpNAlwBMP3xKGdQdzsXxzBr59Kp63oCFqBxwyI6d0sbyhIOJye3IGz47qDjelDMk5ZdiZUSh1HCKnxIKInE61wYSKy/OHQn1YEJHjC9a4YWp8FwDAu9szr7slCRG1HAsicjr5+joAgJ+XCioF/xMn5zBzeBTclDIcO1+OPWeKpY5D5HT424KcTl5FQ0EUouFGduQ8ArzUeDQuAgDw7rbT7CUiamMsiMjpFFwuiIK5sy85mVl3REGtkOFIbjl+zSyROg6RU+EqM3IqFlFEQSV7iMg5NLftgsYnFkXe3bFqZyZu7x4gUTIi58OCiJxKSVU9jGYRKrkMvp4qqeMQ3ZTmtl2orDNizd4sJJ0tQeK0+fA0llvPBfp648MP3u3glETOgQUROZXGCdXBGjVk3KuFnJC3mxKWi8chCxsAS+x9GBYTYj23d+0yCZMROTbOISKnkn95/hDvDE7OTDyzDwCQWViFilqjxGmInAMLInIqjT1EOs4fImdWWYAIfw+IAI7klEmdhsgpsCAip2EWFCitrgfAHiJyfoPCfQEAJ/L0qDOaJU5D5PhYEJHTqFY1/ILQuCngoeL0OHJunX3dEeClgski4sQlvdRxiBweCyJyGrWXC6JgDpeRCxAEAf3CfAAAxy6Uw8KNGoluCgsicho1Sh8AQKC3WtogRB2kZ7A33BQy6OtMOFdcLXUcIofGgoicRo3KBwAQxIKIXIRCLkOfTloAQMr5cmnDEDk4FkTkFKoMJhgUXgDYQ0SuJbaTFgKA82W1qFV4Sx2HyGG1qiCKiopCSUnT++iUl5cjKirqpkMRtdTJPD0gCPBSc0I1uRaNuxJRgZ4AgCLvbhKnIXJcrSqIzp07B7O56TJPg8GAixcv3nQoopZKv1gBgL1D5Jr6X55cXeoRzo0aiVqpRX9K//jjj9Z/b968GVqt1vrcbDZj+/bt6NKlS5uFI7pRaZeXHXP+ELmiTj7u8PdUoaQa+ObweTw5jD31RC3VooJo/PjxABqWe06dOtXmnFKpRJcuXfB///d/bRaO6EalXe4hYkFErqhxCf6OU4X4T1IOnrgtEnIZ7+VH1BItGjKzWCywWCwIDw9HYWGh9bnFYoHBYEBGRgbuueee9spK1Kw6oxlnCqsAcMiMXFdPnTfk5nrkltZg56lCqeMQOZxWzSHKzs5GQEBAW2chapXTBZUwW0QozAZ4qTmhmlyTUi6Df/U5AMAnSeckzULkiFr922P79u3Yvn27tafoSmvWrLnpYEQ3Ku1iw/wh9/pyCAKHCch1BVZloUjbA3vPFCOrqApdA72kjkTkMFrVQ7RkyRIkJCRg+/btKC4uRllZmc2DqCOdyGuYP+RhLJc2CJHE1OYajOoZBAD4z/5z0oYhcjCt6iFavXo11q5di8cee6yt8xC12Mm8SgCAOwsiIkwd2gXbThbi2+QL+HNiNLzdlFJHInIIreohqq+vx9ChQ9s6C1GLWSwiMvIvF0T1FRKnIZLe7d0CEBXoiep6M747wn3hiG5UqwqiJ598Ep9//nlbZyFqsYvltagymKCSy+BmqpI6DpHkBEHA1PguABomV1ssorSBiBxEq4bM6urq8NFHH2Hbtm2IjY2FUmnbJbty5co2CUd0PSfyGiZUdwvygnCOP/iJAGDioM5YsTkDZ4uq8WtWMYZ1D5Q6EpHda1VBdPz4cfTv3x8AkJaWZnOOq3yoI526PH+oV4gG2RJnIbIXXmoFHhjUGWv3n8Mn+8+xICK6Aa0qiHbu3NnWOYha5VR+Qw9RrxBvFkTk8lJSjmLClOkAgDqFFxCSiG0nCvDYMwvx6fvLJE5HZN9aNYeorezZswf33nsvQkNDIQgC1q9fb3NeFEW8+uqrCAkJgbu7O0aPHo0zZ87YtCktLcWUKVOg0Wjg4+ODGTNmoKrKdi7J8ePHMWzYMLi5uSEsLAzLly9v70ujDnLy8pBZT51G4iRE0jNagGHTFmLYtIW469G5CPfzAAQBGeZgqaMR2b1W9RCNHDnymkNjO3bsuKH3qa6uRr9+/TB9+nRMmDChyfnly5fjvffewyeffILIyEi88sorSExMxIkTJ+Dm5gYAmDJlCvLy8rB161YYjUY88cQTmDVrlnXSt16vR0JCAkaPHo3Vq1cjNTUV06dPh4+PD2bNmtWKqyd7UW0wIae0BgDQM8Rb4jRE9qdfZy1yS2tQ4tUF1QYTPLmTO9FVteq7o3H+UCOj0YiUlBSkpaU1uenrtYwdOxZjx45t9pwoinjnnXfw8ssv47777gMA/Oc//0FwcDDWr1+PSZMm4eTJk9i0aRMOHTqEwYMHAwDef/993H333XjrrbcQGhqKdevWob6+HmvWrIFKpUKfPn2QkpKClStXsiBycKcLKiGKDfcvC/DiPcyI/qhLgCe07kpU1AJfHz6PJ26LlDoSkd1qVUH09ttvN3t88eLFTYarWis7Oxv5+fkYPXq09ZhWq0VcXBySkpIwadIkJCUlwcfHx1oMAcDo0aMhk8lw8OBB3H///UhKSsLw4cOhUqmsbRITE/G3v/0NZWVl8PX1bfLZBoMBBoPB+lyv17fJNVHbatyQsaeOvUNEzZEJAgaG+2BnRhH+vS8bj90aAYVc0pkSRHarTb8zHn300Ta7j1l+fj4AIDjYduw7ODjYei4/Px9BQUE25xUKBfz8/GzaNPceV37GHy1duhRardb6CAsLu/kLojb3+4Rqzh8iuppeIRoozAZcKKvFpvTmf+YRURsXRElJSda5PY5s0aJFqKiosD7Onz8vdSRqxin2EBFdl1IuQ0BVFgDgn3vOQhS5XxdRc1o1ZPbHCdCiKCIvLw+HDx/GK6+80ibBdDodAKCgoAAhISHW4wUFBdY5TDqdDoWFhTavM5lMKC0ttb5ep9OhoKDApk3j88Y2f6RWq6FWc06KPRNF0dpDxBVmRNcWWHUWZf59cexCBZKySjC0W4DUkYjsTqt6iK4cTtJqtfDz88OIESOwceNGvPbaa20SLDIyEjqdDtu3b7ce0+v1OHjwIOLj4wEA8fHxKC8vR3JysrXNjh07YLFYEBcXZ22zZ88eGI1Ga5utW7ciOjq62flD5BgK9Abo60yQywREBXpKHYfIrqUfOQDvsoYtS2Z98BMmTJmOCVOmY/bc5yRORmQ/WtVD9PHHH7fJh1dVVSEzM9P6PDs7GykpKfDz80N4eDjmzZuH//f//h+6d+9uXXYfGhqK8ePHAwB69eqFMWPGYObMmVi9ejWMRiPmzp2LSZMmITQ0FADwyCOPYMmSJZgxYwYWLFiAtLQ0vPvuu1edGE6OIaOgYbisi78H3JRyidMQ2TejBbh3zCh8sv8cqtyC0HX8cwj1ccfetdyskajRTW1KkZycjJMnTwIA+vTpgwEDBrTo9YcPH8bIkSOtz+fPnw8AmDp1KtauXYuXXnoJ1dXVmDVrFsrLy3H77bdj06ZNNvOU1q1bh7lz52LUqFGQyWSYOHEi3nvvPet5rVaLLVu2YM6cORg0aBACAgLw6quvcsm9A5s99zmkmXSATyxKcjIwYcp/AADHUlMxTOJsRPZK46ZErxAN0i/p8Vt2KcYP6CR1JCK70qqCqLCwEJMmTcKuXbvg4+MDACgvL8fIkSPx5ZdfIjDwxu6bM2LEiGtO8BMEAa+//jpef/31q7bx8/OzbsJ4NbGxsdi7d+8NZSL7V1RWCc2QibiYV4noPrG4NaqhqD707MMSJyOyb7d08cOJPD1ySmuQX1EndRwiu9KqOUTPPPMMKisrkZ6ejtLSUpSWliItLQ16vR7PPvtsW2ckaqKkqh4AuCEjUQto3ZXWVZkHzpZInIbIvrSqh2jTpk3Ytm0bevXqZT3Wu3dvrFq1CgkJCW0Wjqg5IoDS6oaCyN9Lde3GRGRjSBc/ZORXIqe0Bio1V5sRNWpVD5HFYoFSqWxyXKlUwmKx3HQoomsxKDxhsoiQywRo3Zv+d0hEV+fjoUKfUC0A4JK2D/clIrqsVQXRnXfeieeeew6XLl2yHrt48SKef/55jBo1qs3CETWnTtnww9zPUwXZNW4yTETNi4v0g0ImoFodgB2nCq//AiIX0KqC6IMPPoBer0eXLl3QtWtXdO3aFZGRkdDr9Xj//ffbOiORjVplw0aM/p4cLiNqDU+1Av3CfAAAyzdlwGxhLxFRq+YQhYWF4ciRI9i2bRtOnToFoGFPoCtvxErUXuouF0ScUE3UeoMjfJFytgAZBZX4+vB5TB4SLnUkIkm1qIdox44d6N27N/R6PQRBwF133YVnnnkGzzzzDG655Rb06dOHy9up3dVeHjJjDxFR67kp5QjRN+wj939bTqPKYJI4EZG0WlQQvfPOO5g5cyY0mqb3jtJqtZg9ezZWrlzZZuGI/shgMqNO4QWAK8yIblZAVRa6+HuguMqA1buypI5DJKkWFUTHjh3DmDFjrno+ISHB5r5iRG0tu7gaEGRQyWXwUt/URutELk8GEYvubtg+5Z97z+JSea3EiYik06KCqKCgoNnl9o0UCgWKiopuOhTR1WTkN9zDzN9LBYErzIhuWkLvYAyJ9IPBZMGKzRlSxyGSTIsKok6dOiEtLe2q548fP46QkJCbDkV0NacLfi+IiOjmCYKAV8b1BgB8f/Qijl8olzYQkURaVBDdfffdeOWVV1BX1/QeOLW1tXjttddwzz33tFk4oj/KyK8CAAR4coUZ0c1KSTmKCVOm47UFz8OvOgcA8Mhb6zFr7nMSJyPqeC2ahPHyyy/ju+++Q48ePTB37lxER0cDAE6dOoVVq1bBbDbjf//3f9slKBHAHiKitmS0AMOmLQQA9K8z4j9JOahyC8TWQ0WYMGV6k/aBvt748IN3OzomUYdoUUEUHByM/fv34+mnn8aiRYusW74LgoDExESsWrUKwcHB7RKUqNpgQm5pDYCGXaqJqO14uykxMNwXv50rhaVXIobeeyvkMtt5envXLpMoHVH7a/EynYiICGzcuBFlZWXIzMyEKIro3r07fH192yMfkdWZwobhMoW5Dh4qrjAjamuDInyRdqkCNV4BOH6hHAPC+XOdXEerf6v4+vrilltuacssRNd0+vIKM3ejXuIkRM5JpZAhPsof208V4mB2KXqFaOCmlEsdi6hDtOpeZkRSyChoLIgqJE5C5Lx6h2ogVuTDYLLgYHap1HGIOgzHHchhNE6odmMPEVG7kQkCLOm/QD70CRy/UI7Yzlr4ejTM2WtclXYlTrQmZ8GCiBxGRj57iIg6RFHDLT3OldTg18xi3BMbCsB2VVojTrQmZ8EhM3IIZdX1KKw0AADcjJUSpyFyfrd3C4AgAFlF1bhYxlt6kPNjQUQOoXH+UGdfd8hF3pWbqL35e6nRN1QLANibWWTdZoXIWbEgIofQOH+op85b4iREruPWKD8oZAIK9AZkl1RLHYeoXbEgIofQOH+oRzALIqKO4qFSoF+YDwDgwFmuOCPnxoKIHEJjD1E0e4iIOtSgCF8o5QKKKg1ASC+p4xC1GxZEZPdEUWQPEZFE3JVyDAhr2LFaFj2Kc4nIabEgIruXr6+Dvs4EuUxAVKCn1HGIXM6AcB+o5DIIWh0yL99Ch8jZsCAiu9fYOxQZ4Am1grcRIOpobko5BoT7AAAOZJfCwl4ickIsiMjucf4QkfQGhPtArK9FaXU9zhSwl4icDwsisnsZ+Q0/fKM5f4hIMmqFHGLWPgDAgewSWCzsJSLnwoKI7F5jDxEnVBNJSzybBDeFDOU1RutmqUTOggUR2TWzRcSZQg6ZEdkFUz0GRjSsOPvtHOcSkXNhQUR2Lbe0BnVGC9yUMoT7eUgdh8jl9evsY+0lOs1eInIiLIjIrjWuMOse5A25TJA4DRGpFDIMaOwlyi4F+4jIWbAgIrvG+UNE9qdfZy3UChnKaowo8+gsdRyiNsGCiOxaYw9RtM5L4iRE1EitkGNgeEMvUb6mF8xccUZOwO4Loi5dukAQhCaPOXPmAABGjBjR5NxTTz1l8x65ubkYN24cPDw8EBQUhBdffBEmk0mKy6EWmD33OWw7kgEA+PqTf2HClOmYMGU6jqWmSpyMiPqFNfQS1Sk12JiaJ3UcopumkDrA9Rw6dAhms9n6PC0tDXfddRcefPBB67GZM2fi9ddftz738Ph98q3ZbMa4ceOg0+mwf/9+5OXl4fHHH4dSqcSbb77ZMRdBrVJQXo36zhoAwIj7H4OnuuE/10PPPixlLCJCQy9R/zAfHMwuxfs7zmBcTAhknOdHDszue4gCAwOh0+msjw0bNqBr16644447rG08PDxs2mg0Guu5LVu24MSJE/jss8/Qv39/jB07Fm+88QZWrVqF+vp6KS6JblCdQgMRgJtSBg8Vb9lBZG8GhPlAbqnH6YIq/JKWL3Ucopti9wXRlerr6/HZZ59h+vTpEITf/xJZt24dAgIC0LdvXyxatAg1NTXWc0lJSYiJiUFwcLD1WGJiIvR6PdLT05v9HIPBAL1eb/Ogjler1AIAArzUNl9vIrIPaqUcgZWZAIB3t5/mXCJyaA5VEK1fvx7l5eWYNm2a9dgjjzyCzz77DDt37sSiRYvw6aef4tFHH7Wez8/PtymGAFif5+c3/xfN0qVLodVqrY+wsLC2vxi6rlpVQ09fgKda4iREdDVBlZnQuClwuqAKPx67KHUcolaz+zlEV/r3v/+NsWPHIjQ01Hps1qxZ1n/HxMQgJCQEo0aNQlZWFrp27dqqz1m0aBHmz59vfa7X61kUSaCxh8jfWyVxEiK6GoVoxOw7umLF5gys3Hoa42JCoVI41N/aRAAcqIcoJycH27Ztw5NPPnnNdnFxcQCAzMyGblydToeCggKbNo3PdTpds++hVquh0WhsHtTxrENm7CEismtP3NYFAV5qnC+txVeHcqWOQ9QqDlMQffzxxwgKCsK4ceOu2S4lJQUAEBISAgCIj49HamoqCgsLrW22bt0KjUaD3r17t1teujnFVQaY5G4AAH8v9hAR2TMPlQLPjeoGAHhvRyaqDdzWhByPQxREFosFH3/8MaZOnQqF4vdRvqysLLzxxhtITk7GuXPn8OOPP+Lxxx/H8OHDERsbCwBISEhA79698dhjj+HYsWPYvHkzXn75ZcyZMwdqNXse7FXjhoxadyWUcof4z5TIpT18SzjC/TxQVGnA6t1ZUschajGH+E2zbds25ObmYvr06TbHVSoVtm3bhoSEBPTs2RMvvPACJk6ciJ9++snaRi6XY8OGDZDL5YiPj8ejjz6Kxx9/3GbfIrI/J/MaVvYFsHeIyCGoFDL85e5eAICP9pzFhbKa67yCyL44xKTqhIQEiGLT5ZxhYWHYvXv3dV8fERGBjRs3tkc0aieNPUQBXuzFI3IUiX2CER/lj6SzJVj6yymsemSg1JGIbphD9BCR6znFgojI4QiCgFfv7Q2ZAPx8PA8HzpZIHYnohrEgIrtjtojWu9xzQjWRY+kVosEjceEAgL98l4o6o/k6ryCyDyyIyO6cK6mGwWSBzGKC1l0pdRwiaqEXE3siyFuNs8XV+GBHptRxiG4ICyKyO6fyGnqH3Ix6yHjLDiKHo3VX4vX7+gIAVu/Osi6SILJnDjGpmlxLRn7DD093Y4XESYjoelJSjmLClOlNjgf6emNM3OPYlJ6PF74+hu/nDIVawZs0k/1iQUR25+TlCdXuRv5VSWTvjBZg2LSFTY7vXbsMq+/rg9/OleJEnh4rNmXg5Xu4GS7ZLw6Zkd3JsBZE7CEicmRBGjcsn9iwSe6/9mVj9+kiiRMRXR0LIrIrVQYTcksbNnRjQUTk+Eb3Dsbj8REAgBe+TkFeRa3EiYiax4KI7ErjcvsgbzUUlnqJ0xBRW/jL3b3QU+eN4qp6PP3ZERhMXIpP9ocFEdmVxhVm0TpviZMQUVtxU8rx0WODoXVXIuV8ORb/mC51JKImWBCRXWlcYdYrRCNxEiJqS+H+Hnhv8gAIAvDFb+ex9tdsqSMR2WBBRHalcYVZdDB7iIiczR09ArFwTE8AwOsbTmDnqUKJExH9jsvuyW6IomhdYdYzhAURkSO72v5Ep06kwf+2x1HiFYkZa/ajR+EueBj1CPT1xocfvCtBUqIGLIjIbuTr61BRa4RcJqBroJfUcYjoJlxtf6JDzz6M6ffehfUpF3GhDLgQMRaTbgnDkS/ekiAl0e84ZEZ2I/1iw/yhboFecFNyR1siZyWXCRgXEwJfDyWqDCb8dPwSLAK/50laLIjIbpy4fL+j3qGcUE3k7NyUcvypXyjclDIU6A045zcYFosodSxyYSyIyG6kX2rYiLEPCyIil+DjocI9MaGQCUC5R2e8tSVD6kjkwlgQkd1Iv8QeIiJX08nXHaN7BQMA/r4rC18fPi9xInJVnFRNdqGixogLZQ1b+vcJ0Uqchog6Uq8QDbas/xLoMRILvknBP//+PrwNxQDA1WfUYdhDRHYhPa9huKyzrzu0HkqJ0xBRRzOf3IEeQV4QBRlyQ0ei70PzMWzaQhSVVUodjVwECyKyCycuD5dx/hCRqxJxV+9g6DRuMJgs+DHlEmqNvOcZdRwOmZHkZs99DoeEaMAzAsf378CETX8HABxLTcUwibMRUcdRyGW4JzYEXx0+j/JaI34+nodACFLHIhfBgogkV1RWCaFnd6C6HoOHjUZU4HgADRu4EZFr8VQrcF+/UHx9+AIultei1m8gRFGEILAwovbFITOSnEWQobSmHgAQ6K2WOA0RSc3fS427Y3QQBKDUsws+2nNW6kjkAlgQkeRqlVqIIuCulMNLzU5LIgIi/D1xR/dAAMDfNp1CUlaJxInI2bEgIsnVKn0ANPQOsVuciBrFdtbCrzoHFhF45osjKNDXSR2JnBgLIpJcjaph36FALw6XEdHvBEFAeNlR9NR5o7iqHnPWHYHRbJE6FjkpFkQkuSt7iIiIriQTzVj96CB4qxU4nFOGZb+ckjoSOSlO2CBJmS0iapWXe4hYEBFRM7oEeOL/HuqHWZ8m49/7sjEw3Bc/frSs2U0bubM1tRYLIpJUdnEVLDIFFDIBPtyhmoiuIqGPDk/d0RWrd2fhpW+PIaJSxF3TFjZpt3ftMgnSkTPgkBlJqvGGroHeasg4oZqIruHPCT0QF+mH6nozzvkPgdkiSh2JnAh7iEhSjbfs4IRqImpOSspRTJgy3fq8Xu4OefAo1Kh88WtWMYZfXppPdLNYEJGkruwhIiL6I6MFGPaHobHIoir8dDwPR3PLEe7rgS4BnhKlI2fCITOSjCiKSL/UcJd7FkREdKOiAr1gOZsEANhyogDVBpPEicgZsCAiyeRV1KGsxgiIFvh7qqSOQ0QOREzfjAAvFWqNZmxOz4cocj4R3Ry7LogWL14MQRBsHj179rSer6urw5w5c+Dv7w8vLy9MnDgRBQUFNu+Rm5uLcePGwcPDA0FBQXjxxRdhMvGvCXvQOFzmZqyEQm7X/ykSkb2xmHB33xAoZALOl9XicE6Z1InIwdn9b6E+ffogLy/P+ti3b5/13PPPP4+ffvoJ33zzDXbv3o1Lly5hwoQJ1vNmsxnjxo1DfX099u/fj08++QRr167Fq6++KsWl0B80Tqj2MJZLG4SIHJKvpwojohsmVR84W4KiSoPEiciR2f2kaoVCAZ1O1+R4RUUF/v3vf+Pzzz/HnXfeCQD4+OOP0atXLxw4cAC33nortmzZghMnTmDbtm0IDg5G//798cYbb2DBggVYvHgxVCoO00gp7fL8IY/6cmmDEJHD6h2iQXZxNbKKqrE5PR9h9v93Ptkpu/8v58yZMwgNDUVUVBSmTJmC3NxcAEBycjKMRiNGjx5tbduzZ0+Eh4cjKalhsl1SUhJiYmIQHBxsbZOYmAi9Xo/09PSrfqbBYIBer7d5UNs7fqEcAOBRz65uImodQRBwZ88guCvlKKmuxyVtH6kjkYOy6x6iuLg4rF27FtHR0cjLy8OSJUswbNgwpKWlIT8/HyqVCj4+PjavCQ4ORn5+PgAgPz/fphhqPN947mqWLl2KJUuWtO3FkI0CfR0K9AbIBMCdQ2ZEdBM8VAqM7hWEn47nodC7G+6a/hK8DcXW87ydB90Iuy6Ixo4da/13bGws4uLiEBERga+//hru7u7t9rmLFi3C/Pnzrc/1ej3CwsLa7fNcUeqFhuGy7kHekOeaJU5DRI4uKtALfUI1SL+kR374KIyKC4daIQfA23nQjbH7IbMr+fj4oEePHsjMzIROp0N9fT3Ky8tt2hQUFFjnHOl0uiarzhqfNzcvqZFarYZGo7F5UNtqHC6L6ayVNggROY3h3QMhVpeiss6E3aeLpI5DDsahCqKqqipkZWUhJCQEgwYNglKpxPbt263nMzIykJubi/j4eABAfHw8UlNTUVhYaG2zdetWaDQa9O7du8Pz0++OX2zoIerHgoiI2ohKIYPlyH8BACfzKpFVVCVxInIkdl0Q/fnPf8bu3btx7tw57N+/H/fffz/kcjkmT54MrVaLGTNmYP78+di5cyeSk5PxxBNPID4+HrfeeisAICEhAb1798Zjjz2GY8eOYfPmzXj55ZcxZ84cqNXcGVkqoiji+OUhs5jOPtKGISLnUpqDQRG+AIDtJwu5izXdMLueQ3ThwgVMnjwZJSUlCAwMxO23344DBw4gMLBh34m3334bMpkMEydOhMFgQGJiIv7+979bXy+Xy7FhwwY8/fTTiI+Ph6enJ6ZOnYrXX39dqksiABfLa1FaXQ+lXECvEG+p4xCRk7k1yg85JdUorqrH9lOF8JE6EDkEuy6Ivvzyy2ued3Nzw6pVq7Bq1aqrtomIiMDGjRvbOhrdhMbeoWidt3XSIxFRW1HIZEjorcNXh84ju7ga4Z5dpI5EDsCuh8zIOTUWRLEcLiOidhLorcatXf0AABd8YpFbUiNxIrJ3LIiowzWuMIvtxAnVRNR+Bob7ItTHDRaZEvO/ToHZwhvA0tWxIKIOZbGISL3IHiIian8yQUBibx1kFiMO55Thwz1ZUkciO8aCiDpUVlEVKutMcFfK0SPYS+o4ROTkNO5KhJUdAwC8vfU00i7/QUb0RyyIqEM9v7RhFaC8Mh8PPf4kJkyZjmOpqRKnIiJn5leTg8Q+wTCaRTz/VQrqjNwdn5piQUQdKt/kAQCIju6BYdMWYti0hag3cp8QImo/AoA3749BgJcaZwqrsGJzhtSRyA6xIKIOVa1qWPWh07hJnISIXIm/lxrLH4gBAPx7XzZ2niq8zivI1bAgog5TZTChVtmwskynZUFERB3rzp7BmDa0CwBg/tcpyKuolTYQ2RUWRNRhjl8oBwQB3m4KeKntek9QInJSi+7uib6dNCirMeK5L1JgMlukjkR2ggURdZijueUAOFxGRNJRK+T4YPJAeKkV+O1cKd7bfkbqSGQnWBBRh0k5Xw6Aw2VEJK0uAZ54c0LDfKL3d2Zi35liiRORPWBBRB1CFEX2EBGR3fhTv1BMHhIGUQTmfZWCwso6qSORxDiRgzrEhbJaFFcZANGCIG+11HGIyIWkpBzFhCnTmxz389Uiuuv9yCioxP98dgSfz7wVKgX7CVwVCyLqEMk5ZQAAj/pyKOT8gUNEHcdoAYZNW9jk+N61y/D3Rwdi/KpfcTinDK/9mIY374+BIAgSpCSp8TcTdYhD50oBAF71HKsnIvvRNdAL700eAEEAvvjtPD49kCN1JJIICyLqEIfPNfQQeRlKJE5CRGRrZHQQFozpCQBY8tMJJGXx55QrYkFE7a6ixoiMgkoAgCcLIiKyQ7OHR+G+/qEwW0T8z7pknC+tkToSdTDOIaJ2l5zbMFwWFeAJ5XmDxGmIiBr8cbK1RZDBI2gEyuCLJz85jG+ejofGTSlhQupILIio3R26PFw2uIsvMo9KHIaI6LLmJlsPrDPiP3tOIqMAmPWfw/hk+hCoFXKJElJH4pAZtbvDlydUD+7iJ3ESIqJr83ZTolvRr/BSK3DgbCnmf3UMFosodSzqACyIqF3VGc04dr4CAHALCyIicgAexgqsfnQQlHIBP6fm4fUNJyCKLIqcHQsialdpFytQb7YgwEuNLv4eUschIrqulJSjWLn4JXQqOAAAWLv/HG57+m+YPfc5iZNRe+IcImpXB7MvD5dF+HKzMyJyCFfOLTqaW4Y9Z4pxyScGitJ6iZNRe2IPEbWrA2cbltnfGsXhMiJyPAPCfTEowhcAkOs3CJ9x40anxYKI2o3BZLbuUD20W4DEaYiIWue2rv4YEOYDAHh5fRo+2X9O0jzUPjhkRu3m2PkK1BktCPBSoXuQl9RxiIhaRRAEDOsegKM7fwK6DcNrP6bjn598jqCqTABAoK83PvzgXYlT0s1iDxG1m8bt7+Oi/Dl/iIgcmiAIMKdvxuDLw2cXfPvBY+RsDJu2EEVllRKno7bAHiJqN/uzGm7kOrSrv8RJiIjaxtCu/pAJAn47V4p9mcWorDNCBv7B5wzYQ0Ttos5oxtHccgBAfBQLIiJyDoIgIL6rP27r1vBz7diFCmQFDEVlnVHiZHSzWBBRuziSU4Z6swXBGjUiAzyljkNE1KYGR/jh7hgdFDIBencdHvhHEi6U8YawjowFEbWL/ZfnDw3tGsD5Q0TklLoHeeOBQZ2hMNcio6AS41ftR3JOqdSxqJVYEFG7+PXy/CEOlxGRMwvWuKFnwU70DtGguMqAhz88gI/2ZPFWHw6Ik6qpzZVV1+NoThkgCPjP+8vwpbnWeu5YaiqGSZiNiKitqcy1+PSpePzl+1T8kHIJb248hd+yS/HWg/3g46GSOh7dIBZE1Ob2ZhYDggB/LxVGPWZ7759Dzz4sUSoiovbjqVbgnYf7Y0ikH5b8dALbThZi3Hv78MEjAzAg3FfqeHQDWBBRm9uVUQgA6OLHydRE5DoEQcCUuAj06+yDuZ8fwbmSGkxYtQ+dylMRWJVpXZzPjRztk13PIVq6dCluueUWeHt7IygoCOPHj0dGRoZNmxEjRkAQBJvHU089ZdMmNzcX48aNg4eHB4KCgvDiiy/CZDJ15KW4DItFxJ7TDfOHInh3eyJyQX07afHTM7fDp+YCREGGC779oB/4OIZMeZEbOdoxuy6Idu/ejTlz5uDAgQPYunUrjEYjEhISUF1dbdNu5syZyMvLsz6WL19uPWc2mzFu3DjU19dj//79+OSTT7B27Vq8+uqrHX05LuFEnh7FVQbILCaE+rhLHYeISBLebkpElhzEiB6BkAsCsoqq8cWh8yiqNEgdja7CrofMNm3aZPN87dq1CAoKQnJyMoYPH2497uHhAZ1O1+x7bNmyBSdOnMC2bdsQHByM/v3744033sCCBQuwePFiqFSc8NaWdp8uAgB4Gwohl/WSOA0RkXQEAP3CfKDTumFjah4qao34+vB5dPIIlzoaNcOue4j+qKKiAgDg5+dnc3zdunUICAhA3759sWjRItTU/L45VlJSEmJiYhAcHGw9lpiYCL1ej/T09GY/x2AwQK/X2zzoxuzOaCiINLX5EichIuoYKSlHMWHK9CaPY6mpABqW5k8eEo4Ifw+YLCJy/G/B/36fCoPJLHFyupJd9xBdyWKxYN68ebjtttvQt29f6/FHHnkEERERCA0NxfHjx7FgwQJkZGTgu+++AwDk5+fbFEMArM/z85v/pb106VIsWbKkna7EeZVV1yM5twwAoKkrkDgNEVHHMFqAYdMWNjl+5apaN6Uc9/ULxcHsUhw8W4J1B3ORdkmPv08ZiE6cXmAXHKYgmjNnDtLS0rBv3z6b47NmzbL+OyYmBiEhIRg1ahSysrLQtWvXVn3WokWLMH/+fOtzvV6PsLCw1gV3IdtOFsBsEdFT5w31eW5hT0R0JUEQcGuUP3774m3IbpmMY+fLMfyvvyCy5Dd09ajlyjOJOcSQ2dy5c7Fhwwbs3LkTnTt3vmbbuLg4AEBmZiYAQKfToaDAtrei8fnV5h2p1WpoNBqbB13f5vSG/18T+zT//ysREQGmgjN4fFgPBHmrYZarkRk0DKmmEO5uLTG7LohEUcTcuXPx/fffY8eOHYiMjLzua1JSUgAAISEhAID4+HikpqaisLDQ2mbr1q3QaDTo3bt3u+R2RdUGE/aeaZg/NKYvCyIiomvRuCvx4KDO6BPa8Af3JZ8Y/M+6I6gycEsYqdh1QTRnzhx89tln+Pzzz+Ht7Y38/Hzk5+ejtrbhVhBZWVl44403kJycjHPnzuHHH3/E448/juHDhyM2NhYAkJCQgN69e+Oxxx7DsWPHsHnzZrz88suYM2cO1Gq1lJfnVHafLoLBZEG4nwd66ryljkNEZPcUchlG9wrGnT2DIIgW/JKWj/tX/YqzRVVSR3NJdl0Q/eMf/0BFRQVGjBiBkJAQ6+Orr74CAKhUKmzbtg0JCQno2bMnXnjhBUycOBE//fST9T3kcjk2bNgAuVyO+Ph4PProo3j88cfx+uuvS3VZTmlzesME9cQ+wby7PRFRC8R00qJH4W4Ea9Q4U1iF+z74FVtPcGFKR7PrSdXXG08NCwvD7t27r/s+ERER2LhxY1vFoj+oN1mw41TDkCSHy4iIWs6zvhSfPnM75q47it/OlWLmfw7j2VHdMW9Ud8hk/COzI9h1QUSOYV9mESrrTAj0VmNAGG9iSETUGkHeblg3Mw5//fkk1u4/h/e2n8EXm/cjJD8JCtFo05b3Q2t7LIjopn1/9BIAYFxMCP+SISJqhcbNHRtFeIQj13cgihSBqO8+EffEhiDA6/d5r3vXLpMiplNjQUQ3pbLOiC2X5w9NGNhJ4jRERI6puc0dC/V1+Hz3cVTAF18fPo/RvYLRI5iLVtqLXU+qJvv3S1o+DCYLogI9EdNJK3UcIiKnEaRxg2X3PxDm6w6jWcQvafnYd6YYFgv3K2oPLIjopqw/ehEAMGFAJ64uIyJqa/U1GN+/EwaFN8zPTM4tw/cpF2GUcduYtsaCiFotr6IWSWdLAAD39edwGRFRe5DJBNzePQBj++qglAu4UFaLU8F3IjmnTOpoToUFEbXad0cuQhSBIV38EObnIXUcIiKn1iPYGw8PDoOvhxJGhQce/jAJa3/N5i0/2ggnVVOrmC0iPj+YCwB4YPC17y9HRERtw99LjUm3hOMfX6yHKTQGi386gXe/3ITwsiOQi2Yux78J7CGiVtl5qhAXy2uhdVfiT/1CpY5DROQyVAoZzIe+wvDuAZAJQJlnOC5EP4S+D85HUVml1PEcFgsiapVPD+QAAB4a3BluSrnEaYiIXM+AcF9MGNgZnio5Sqrr8eWh8yhz5x+orcWCiFosp6Qau08XQRCAR2+NkDoOEZHL6uTjjslDwtHJxx31ZguyA+Lx159PwGS2SB3N4bAgohb77HLv0B09AhHh7ylxGiIi1+apVuD+AZ0wMNwHAPDPvdl45F8HUVhZJ20wB8NJ1dQiFTVGfPHbeQDA4/ERmD33uWbHrI+lpmJYR4cjInJRcpmAYd0DUXbkFxR1Gobfsksx7r19+GDyAMRF+UsdzyGwIKIWWbv/HKoMJvTUeWNEjyB8UFbZZLt5ADj07MMSpCMicm2+tZfwr7m34alPk3GmsAqT/nkAs4ZHYf5dPaBWcL7ntXDIjG5YlcGENb9mAwDm3tmNN3IlIrIzKSlH8eK8Z+Fx5DP4VZ+DKAIf7j6LQYu+weFzpVLHs2vsIaIb9tmBHFTUGhEV6ImxfUOkjkNERH/wx5vEZhVVYfvJQlTBGw+sTsJDgzvjzwnRCNK4SZjSPrGHiG5IlcGEf+09CwCYM6Ib5OwdIiKye10DvfDYrRHwr2ro3f/68AUMX7ETSzeeRFGlQeJ09oUFEd2Qf+zKRHFVPbr4e+BP/bnPBRGRo3BXyRFRdgTfPhWPgeE+qDNa8OGes7ht2Q7M+/IoDpwtgdnC239wyIyu60JZDf65t+Gvi0V394JSzjqaiMjRDO7ih/8+PRQ7Mwrx3vZMpJwvx/qUS1ifcgkBXmrc1TsI8V0DcGukn0sOqbEgouta9ssp1Jss8KorxOo3/4IPrzjH5fVERI5DEATc2TMYd/YMxvEL5fjsQA42peWjuMqAL347b91WJUTrhr6dtIjtpEXfzlrEdNIiwEstcfr2xYKIrunA2RJsOJ4HiCL+NHwwAr1vsznP5fVERI4ptrMPlj/gg/83Pgb7s4qx90wxDpwtwYk8PfIq6pBXUYetJwqs7d0sdRjeNwIxTloksSCiq6o2mPDSt8cBAAHV2Qj07iFxIiIiao2UlKOYMGV6k+OBvt748IN3MSI6CCOigwA0LKK5/+m/QHfbRBTqDSisrENZjRF1MjdsOVGALVcUSUpTDQLFMrzx5H24rVuAQ9/bkgURXdXfNp1CbmkNOvm4I+BCKoBEqSMREVEr/HE5fqP35z3cbKF0NjUVd09+0vq83mTBB39dhBFPLLQpkowKD1yCB2Z8chhycz38anIQUJUNd1OltdhyFCyIqFm/ZhbjP0kN9yz728RYrEz9TOJERETU1q5WKP1xOoRKIQNKzmFguK/1mMFkRoHegP/+91t497od1QYViry7o8i7O6ICPFGd/lO7529LLIioiYvltXj2i6MAgClx4bi9ewBWSpyJiIjsi1ohR7ifB8TUnzH9yceQW1KD1IsVOFtcjbPF1UDwnej33D/RqTwVbqYq6+vsteeIBRHZqDOa8dSnySiprkfvEA1eHtdb6khERGTnZIKALgGe6BLgibLqehzKKcWJi+WocA+F3iMU/Tr7ID7KHyqFDHvXLpM6brNYEJGVxSLipW+PI/ViBXw9lPjwsUFwVznuBDkiIup4vp4qJPTWIe2zN9Dt4f9FdnE1Us6X42xRFe7sGXTdCd5SYUFEAABRFPG/69Pw47FLkMsErHpkIML8PKSORUREjqqqGH/qF4pzJdXYcaoQ+joT1qdcgiX2ftwy5cEmK9Kk7jnilsMEi0XEkp9O4IvfciETgLcf7o+h3QKkjkVERE6gi78nHo2LQP/OPgAAWcQgfHogB2eLqq79wg7GHiIXV2c048/fHGvYfBFA79o0rF3+X6z9QzvuSE1ERK2lUshwR3Qgeui88NXOI6jxDsJPx/PQO0SD4T0CoFZIPz2DBZELy6uoxZx1R3AktxxKuYClE2Lx+cr/3tASTCIiopYK0brDsmsVhsx5D8m5ZTiRp8eFshok9NZJHY0Fkav6IeUiXlmfBn2dCVp3JVY/OgjxXf3xudTBiIjIuVnMuL17ACIDPLHlRD70dSZ8e+QCgrQxqDOaJdvtmgWRi8ksrMSbG09hx6lCAEBsZy3enTQAkQGeEicjIiJX0snXHVPiIrDnTBHSL+lR5hnGgojaX2ZhJf65JxvfHrkAs0WEXCZg7shumHtnNyjlnFtPREQdT6WQYXSvYEQFeuLk1q/h4/GAZFlYEDmxmnoTtp4owH+PXMSe00XW46N7BaPu8H+xd+232LvW9jWcPE1ERB0tKsALFw2FkmZgQeRETGYLzhRW4fC5UuzKKML+rBLUGs0AAEEAEnoHY+awKAzu4ocJW/7OydNERESXuVRBtGrVKqxYsQL5+fno168f3n//fQwZMkTqWC1mtojIq6jF+dJanC+twYk8PY5fKMeJPD3qjBabtu6WGmgrz8G/OhdFudV4c1PDcfYEERER/c5lCqKvvvoK8+fPx+rVqxEXF4d33nkHiYmJyMjIQFBQkCSZzBYRpdX1qDaYUGUwodpgQnW9CVUGc8O/DSaU1dSjtLoeJVUN/1tYacCl8lqYLGKz7ymzGOFZXwbvugJo6gpw+sg+PPx/65q0Y08QERHR71ymIFq5ciVmzpyJJ554AgCwevVq/Pzzz1izZg0WLrQdOjIYDDAYDNbnFRUVAAC9Xt+mmS6V1yLh7T2teq1SLiBE64ZOvh7oFuSFvqEarFn1DkY+NBOCEG5tl7p/O+qqm+4GajGb7eY4szAjMzIjM9pPFqkyGo31bf57tvH9RLH5ToQrCeKNtHJw9fX18PDwwLfffovx48dbj0+dOhXl5eX44YcfbNovXrwYS5Ys6eCURERE1B7Onz+Pzp07X7ONS/QQFRcXw2w2Izg42OZ4cHAwTp061aT9okWLMH/+fOtzi8WC0tJS+Pv7QxCEds97o/R6PcLCwnD+/HloNBqp47Q7V7peV7pWwLWul9fqvFzpeh3lWkVRRGVlJUJDQ6/b1iUKopZSq9VQq9U2x3x8fKQJcwM0Go1d/wfZ1lzpel3pWgHXul5eq/Nypet1hGvVarU31M4lduQLCAiAXC5HQUGBzfGCggLodNLfP4WIiIik5RIFkUqlwqBBg7B9+3brMYvFgu3btyM+Pl7CZERERGQPXGbIbP78+Zg6dSoGDx6MIUOG4J133kF1dbV11ZkjUqvVeO2115oM7zkrV7peV7pWwLWul9fqvFzpep3xWl1ilVmjDz74wLoxY//+/fHee+8hLi5O6lhEREQkMZcqiIiIiIia4xJziIiIiIiuhQURERERuTwWREREROTyWBARERGRy2NB5GD++te/YujQofDw8Ljh3bOnTZsGQRBsHmPGjGnfoG2gNdcqiiJeffVVhISEwN3dHaNHj8aZM2faN2gbKS0txZQpU6DRaODj44MZM2agqqrpDRCvNGLEiCZf26eeeqqDErfMqlWr0KVLF7i5uSEuLg6//fbbNdt/88036NmzJ9zc3BATE4ONGzd2UNKb15JrXbt2bZOvoZubWwembb09e/bg3nvvRWhoKARBwPr166/7ml27dmHgwIFQq9Xo1q0b1q5d2+4520JLr3XXrl1Nvq6CICA/P79jAt+EpUuX4pZbboG3tzeCgoIwfvx4ZGRkXPd1jvw9C7Agcjj19fV48MEH8fTTT7fodWPGjEFeXp718cUXX7RTwrbTmmtdvnw53nvvPaxevRoHDx6Ep6cnEhMTUVdX145J28aUKVOQnp6OrVu3YsOGDdizZw9mzZp13dfNnDnT5mu7fPnyDkjbMl999RXmz5+P1157DUeOHEG/fv2QmJiIwsLCZtvv378fkydPxowZM3D06FGMHz8e48ePR1paWgcnb7mWXivQcPuDK7+GOTk5HZi49aqrq9GvXz+sWrXqhtpnZ2dj3LhxGDlyJFJSUjBv3jw8+eST2Lx5czsnvXktvdZGGRkZNl/boKCgdkrYdnbv3o05c+bgwIED2Lp1K4xGIxISElBdXX3V1zjy96yVSA7p448/FrVa7Q21nTp1qnjfffe1a572dKPXarFYRJ1OJ65YscJ6rLy8XFSr1eIXX3zRjglv3okTJ0QA4qFDh6zHfvnlF1EQBPHixYtXfd0dd9whPvfccx2Q8OYMGTJEnDNnjvW52WwWQ0NDxaVLlzbb/qGHHhLHjRtncywuLk6cPXt2u+ZsCy291pZ8L9szAOL3339/zTYvvfSS2KdPH5tjDz/8sJiYmNiOydrejVzrzp07RQBiWVlZh2RqT4WFhSIAcffu3Vdt48jfs43YQ+Qidu3ahaCgIERHR+Ppp59GSUmJ1JHaXHZ2NvLz8zF69GjrMa1Wi7i4OCQlJUmY7PqSkpLg4+ODwYMHW4+NHj0aMpkMBw8evOZr161bh4CAAPTt2xeLFi1CTU1Ne8dtkfr6eiQnJ9t8XWQyGUaPHn3Vr0tSUpJNewBITEy0+69ja64VAKqqqhAREYGwsDDcd999SE9P74i4Hc5Rv643o3///ggJCcFdd92FX3/9Veo4rVJRUQEA8PPzu2obZ/jausytO1zZmDFjMGHCBERGRiIrKwt/+ctfMHbsWCQlJUEul0sdr800js0HBwfbHA8ODrb7cfv8/PwmXekKhQJ+fn7XzP7II48gIiICoaGhOH78OBYsWICMjAx899137R35hhUXF8NsNjf7dTl16lSzr8nPz3fIr2NrrjU6Ohpr1qxBbGwsKioq8NZbb2Ho0KFIT09H586dOyJ2h7na11Wv16O2thbu7u4SJWt7ISEhWL16NQYPHgyDwYB//etfGDFiBA4ePIiBAwdKHe+GWSwWzJs3D7fddhv69u171XaO+j17JRZEdmDhwoX429/+ds02J0+eRM+ePVv1/pMmTbL+OyYmBrGxsejatSt27dqFUaNGteo9W6u9r9Xe3Oj1ttaVc4xiYmIQEhKCUaNGISsrC127dm31+1LHiY+Pt7nJ9NChQ9GrVy98+OGHeOONNyRMRjcjOjoa0dHR1udDhw5FVlYW3n77bXz66acSJmuZOXPmIC0tDfv27ZM6SrtjQWQHXnjhBUybNu2abaKiotrs86KiohAQEIDMzMwOL4ja81p1Oh0AoKCgACEhIdbjBQUF6N+/f6ve82bd6PXqdLomk25NJhNKS0ut13UjGu/Nl5mZaTcFUUBAAORyOQoKCmyOFxQUXPXadDpdi9rbi9Zc6x8plUoMGDAAmZmZ7RFRUlf7umo0GqfqHbqaIUOGOFRhMXfuXOsCj+v1Vjrq9+yVWBDZgcDAQAQGBnbY5124cAElJSU2RUNHac9rjYyMhE6nw/bt260FkF6vx8GDB1u8Kq+t3Oj1xsfHo7y8HMnJyRg0aBAAYMeOHbBYLC26AXFKSgoASPK1vRqVSoVBgwZh+/btGD9+PICGbvjt27dj7ty5zb4mPj4e27dvx7x586zHtm7datOTYo9ac61/ZDabkZqairvvvrsdk0ojPj6+yVJsR/i6tpWUlBS7+t68GlEU8cwzz+D777/Hrl27EBkZed3XOOr3rA2pZ3VTy+Tk5IhHjx4VlyxZInp5eYlHjx4Vjx49KlZWVlrbREdHi999950oiqJYWVkp/vnPfxaTkpLE7Oxscdu2beLAgQPF7t27i3V1dVJdxg1p6bWKoiguW7ZM9PHxEX/44Qfx+PHj4n333SdGRkaKtbW1UlxCi4wZM0YcMGCAePDgQXHfvn1i9+7dxcmTJ1vPX7hwQYyOjhYPHjwoiqIoZmZmiq+//rp4+PBhMTs7W/zhhx/EqKgocfjw4VJdwlV9+eWXolqtFteuXSueOHFCnDVrlujj4yPm5+eLoiiKjz32mLhw4UJr+19//VVUKBTiW2+9JZ48eVJ87bXXRKVSKaampkp1CTespde6ZMkScfPmzWJWVpaYnJwsTpo0SXRzcxPT09OluoQbVllZaf2+BCCuXLlSPHr0qJiTkyOKoiguXLhQfOyxx6ztz549K3p4eIgvvviiePLkSXHVqlWiXC4XN23aJNUl3LCWXuvbb78trl+/Xjxz5oyYmpoqPvfcc6JMJhO3bdsm1SXcsKefflrUarXirl27xLy8POujpqbG2saZvmcbsSByMFOnThUBNHns3LnT2gaA+PHHH4uiKIo1NTViQkKCGBgYKCqVSjEiIkKcOXOm9YezPWvptYpiw9L7V155RQwODhbVarU4atQoMSMjo+PDt0JJSYk4efJk0cvLS9RoNOITTzxhU/xlZ2fbXH9ubq44fPhw0c/PT1Sr1WK3bt3EF198UayoqJDoCq7t/fffF8PDw0WVSiUOGTJEPHDggPXcHXfcIU6dOtWm/ddffy326NFDVKlUYp8+fcSff/65gxO3Xkuudd68eda2wcHB4t133y0eOXJEgtQt17i0/I+PxuubOnWqeMcddzR5Tf/+/UWVSiVGRUXZfP/as5Ze69/+9jexa9euopubm+jn5yeOGDFC3LFjhzThW6i56/zjz1pn+54VRVEURFEUO6AjioiIiMhucR8iIiIicnksiIiIiMjlsSAiIiIil8eCiIiIiFweCyIiIiJyeSyIiIiIyOWxICIiIiKXx4KIiIiIXB4LIiIiInJ5LIiIiIjI5bEgIiIiIpf3/wHwkT07sx2skgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(longitude, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "e8c9f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_normalized_time = df_filtered.with_columns([\n",
    "    df_filtered[\"date\"].map_elements(lambda x: sinusoidal_day_in_year(x)[0]).alias(\"sin_day_in_year\"),\n",
    "    df_filtered[\"date\"].map_elements(lambda x: sinusoidal_day_in_year(x)[1]).alias(\"cos_day_in_year\"),\n",
    "    df_filtered[\"date\"].map_elements(lambda x: sinusoidal_hour_in_day(x)[0]).alias(\"sin_hour_in_day\"),\n",
    "    df_filtered[\"date\"].map_elements(lambda x: sinusoidal_hour_in_day(x)[1]).alias(\"cos_hour_in_day\"),\n",
    "    pl.Series(\"latitude_norm\", latitude),\n",
    "    pl.Series(\"longitude_norm\", longitude),\n",
    "    pl.Series(\"wind_speed_norm\", wind_speed),\n",
    "    pl.Series(\"lowest_pressure_norm\", lowest_pressure),\n",
    "])\n",
    "\n",
    "df_features = with_normalized_time.select([\n",
    "    \"sample_id\",\n",
    "    \"sin_day_in_year\",\n",
    "    \"cos_day_in_year\",\n",
    "    \"sin_hour_in_day\",\n",
    "    \"cos_hour_in_day\",\n",
    "    \"latitude_norm\",\n",
    "    \"longitude_norm\",\n",
    "    \"wind_speed_norm\",\n",
    "    \"lowest_pressure_norm\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "65de21e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>sample_id</th><th>sin_day_in_year</th><th>cos_day_in_year</th><th>sin_hour_in_day</th><th>cos_hour_in_day</th><th>latitude_norm</th><th>longitude_norm</th><th>wind_speed_norm</th><th>lowest_pressure_norm</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>64747.0</td><td>64747.0</td><td>64747.0</td><td>64747.0</td><td>64747.0</td><td>64747.0</td><td>64747.0</td><td>64747.0</td><td>64747.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>1301.991536</td><td>-0.495119</td><td>-0.260607</td><td>0.006231</td><td>0.003568</td><td>0.101469</td><td>0.064508</td><td>-1.7229e-16</td><td>2.6338e-18</td></tr><tr><td>&quot;std&quot;</td><td>696.735271</td><td>0.552118</td><td>0.618157</td><td>0.705943</td><td>0.708244</td><td>0.753552</td><td>0.696513</td><td>1.000008</td><td>1.000008</td></tr><tr><td>&quot;min&quot;</td><td>0.0</td><td>-0.999991</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>-1.724771</td><td>-1.629464</td><td>-1.260816</td><td>-5.418361</td></tr><tr><td>&quot;25%&quot;</td><td>729.0</td><td>-0.927542</td><td>-0.809017</td><td>0.0</td><td>-0.707107</td><td>-0.449541</td><td>-0.46875</td><td>-0.769429</td><td>-0.465728</td></tr><tr><td>&quot;50%&quot;</td><td>1330.0</td><td>-0.697944</td><td>-0.413279</td><td>1.2246e-16</td><td>6.1232e-17</td><td>0.0</td><td>0.0</td><td>-0.418439</td><td>0.336127</td></tr><tr><td>&quot;75%&quot;</td><td>1908.0</td><td>-0.263665</td><td>0.226116</td><td>1.0</td><td>1.0</td><td>0.550459</td><td>0.53125</td><td>0.634532</td><td>0.71347</td></tr><tr><td>&quot;max&quot;</td><td>2468.0</td><td>0.999991</td><td>1.0</td><td>1.0</td><td>1.0</td><td>2.357798</td><td>2.165179</td><td>5.899387</td><td>1.468157</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ statistic ┆ sample_id ┆ sin_day_i ┆ cos_day_i ┆ … ┆ latitude_ ┆ longitude ┆ wind_spee ┆ lowest_p │\n",
       "│ ---       ┆ ---       ┆ n_year    ┆ n_year    ┆   ┆ norm      ┆ _norm     ┆ d_norm    ┆ ressure_ │\n",
       "│ str       ┆ f64       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ norm     │\n",
       "│           ┆           ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ count     ┆ 64747.0   ┆ 64747.0   ┆ 64747.0   ┆ … ┆ 64747.0   ┆ 64747.0   ┆ 64747.0   ┆ 64747.0  │\n",
       "│ null_coun ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0.0      │\n",
       "│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ mean      ┆ 1301.9915 ┆ -0.495119 ┆ -0.260607 ┆ … ┆ 0.101469  ┆ 0.064508  ┆ -1.7229e- ┆ 2.6338e- │\n",
       "│           ┆ 36        ┆           ┆           ┆   ┆           ┆           ┆ 16        ┆ 18       │\n",
       "│ std       ┆ 696.73527 ┆ 0.552118  ┆ 0.618157  ┆ … ┆ 0.753552  ┆ 0.696513  ┆ 1.000008  ┆ 1.000008 │\n",
       "│           ┆ 1         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ min       ┆ 0.0       ┆ -0.999991 ┆ -1.0      ┆ … ┆ -1.724771 ┆ -1.629464 ┆ -1.260816 ┆ -5.41836 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 1        │\n",
       "│ 25%       ┆ 729.0     ┆ -0.927542 ┆ -0.809017 ┆ … ┆ -0.449541 ┆ -0.46875  ┆ -0.769429 ┆ -0.46572 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 8        │\n",
       "│ 50%       ┆ 1330.0    ┆ -0.697944 ┆ -0.413279 ┆ … ┆ 0.0       ┆ 0.0       ┆ -0.418439 ┆ 0.336127 │\n",
       "│ 75%       ┆ 1908.0    ┆ -0.263665 ┆ 0.226116  ┆ … ┆ 0.550459  ┆ 0.53125   ┆ 0.634532  ┆ 0.71347  │\n",
       "│ max       ┆ 2468.0    ┆ 0.999991  ┆ 1.0       ┆ … ┆ 2.357798  ┆ 2.165179  ┆ 5.899387  ┆ 1.468157 │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "103e1de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64747"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "e5c00c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_931600/2103490197.py:47: DeprecationWarning: `group_by` iteration will change to always return group identifiers as tuples. Pass `by` as a list to silence this warning, e.g. `group_by(['sample_id'])`.\n",
      "  filtered = filter(filter_out_short_sequence, grouped)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1813, 16, 8), (1813, 16, 1))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((1813, 8, 8), (1813, 8, 4))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy.typing import NDArray\n",
    "from functools import reduce\n",
    "# group by sample_id and iterate over the groups\n",
    "grouped = df_features.group_by(\"sample_id\")\n",
    "from typing import Iterable, Iterator, Tuple, Union\n",
    "\n",
    "EXPECTED_TIMESTAMP_COUNT = 16\n",
    "X_TIME_STEPS = 8\n",
    "Y_TIME_STEPS = 8\n",
    "assert EXPECTED_TIMESTAMP_COUNT == X_TIME_STEPS + Y_TIME_STEPS\n",
    "\n",
    "\n",
    "def filter_out_short_sequence(id_and_df: tuple[int, pl.DataFrame]) -> bool:\n",
    "    return id_and_df[1].height >= EXPECTED_TIMESTAMP_COUNT\n",
    "\n",
    "\n",
    "def pad_or_truncate(\n",
    "        id_and_df: tuple[int, pl.DataFrame]) -> tuple[pl.Series, pl.DataFrame]:\n",
    "    group_id, df = id_and_df\n",
    "    if df.height < EXPECTED_TIMESTAMP_COUNT:\n",
    "        # pad with zeros\n",
    "        diff = EXPECTED_TIMESTAMP_COUNT - df.height\n",
    "        mask = pl.Series(\"mask\", [True] * df.height + [False] * diff)\n",
    "        zeros = pl.DataFrame({\n",
    "            \"sample_id\": [group_id] * diff,\n",
    "            \"sin_day_in_year\": [0.0] * diff,\n",
    "            \"cos_day_in_year\": [0.0] * diff,\n",
    "            \"sin_hour_in_day\": [0.0] * diff,\n",
    "            \"cos_hour_in_day\": [0.0] * diff,\n",
    "            \"latitude_norm\": [0.0] * diff,\n",
    "            \"longitude_norm\": [0.0] * diff,\n",
    "            \"wind_speed_norm\": [0.0] * diff,\n",
    "            \"lowest_pressure_norm\": [0.0] * diff,\n",
    "        })\n",
    "        stacked = df.vstack(zeros)\n",
    "        # sort by date\n",
    "        return mask, stacked.sort(\"date\")\n",
    "    elif df.height >= EXPECTED_TIMESTAMP_COUNT:\n",
    "        # truncate\n",
    "        mask = pl.Series(\"mask\", [True] * EXPECTED_TIMESTAMP_COUNT)\n",
    "        return mask, df.head(EXPECTED_TIMESTAMP_COUNT)\n",
    "    else:\n",
    "        mask = pl.Series(\"mask\", [True] * df.height)\n",
    "        return mask, df\n",
    "\n",
    "\n",
    "filtered = filter(filter_out_short_sequence, grouped)\n",
    "padded = map(pad_or_truncate, filtered)\n",
    "\n",
    "\n",
    "# for some reason, the reduce function is not working\n",
    "def to_tensor(\n",
    "        id_and_df: Iterable[tuple[int,\n",
    "                                  pl.DataFrame]]) -> tuple[NDArray, NDArray]:\n",
    "    init_mask, init_data = np.empty(\n",
    "        (0, EXPECTED_TIMESTAMP_COUNT, 1)), np.empty(\n",
    "            (0, EXPECTED_TIMESTAMP_COUNT, df_features.width))\n",
    "    for mask, df in id_and_df:\n",
    "        current_data = df.to_numpy()\n",
    "        current_mask = np.expand_dims(mask.to_numpy(), axis=-1)\n",
    "        try:\n",
    "            new_data = np.vstack(\n",
    "                (init_data, np.expand_dims(current_data, axis=0)))\n",
    "            new_mask = np.vstack(\n",
    "                (init_mask, np.expand_dims(current_mask, axis=0)))\n",
    "        except ValueError as e:\n",
    "            logger.error(f\"ValueError: {e}\")\n",
    "            logger.info(\n",
    "                f\"init_data: {init_data.shape}, current_data: {current_data.shape}\"\n",
    "            )\n",
    "            logger.info(\n",
    "                f\"init_mask: {init_mask.shape}, current_mask: {current_mask.shape}\"\n",
    "            )\n",
    "            logger.info(\n",
    "                f\"init_data: {init_data}, current_data: {current_data}\")\n",
    "            logger.info(\n",
    "                f\"init_mask: {init_mask}, current_mask: {current_mask}\")\n",
    "\n",
    "        init_data, init_mask = new_data, new_mask\n",
    "    return init_data, init_mask\n",
    "\n",
    "\n",
    "data_with_id, mask = to_tensor(padded)\n",
    "# remove the sample_id column\n",
    "features = data_with_id[:, :, 1:]\n",
    "display((features.shape, mask.shape))\n",
    "\n",
    "# y_train should be the last 4 features\n",
    "y_train = features[:, -Y_TIME_STEPS:, -4:]\n",
    "X_train = features[:, :X_TIME_STEPS, :]\n",
    "display((X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "acfc35b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64747, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>category</th><th>len</th></tr><tr><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>4120</td></tr><tr><td>2</td><td>11081</td></tr><tr><td>1</td><td>17529</td></tr><tr><td>6</td><td>3870</td></tr><tr><td>3</td><td>11382</td></tr><tr><td>4</td><td>9388</td></tr><tr><td>5</td><td>4898</td></tr><tr><td>9</td><td>2479</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8, 2)\n",
       "┌──────────┬───────┐\n",
       "│ category ┆ len   │\n",
       "│ ---      ┆ ---   │\n",
       "│ i64      ┆ u32   │\n",
       "╞══════════╪═══════╡\n",
       "│ 0        ┆ 4120  │\n",
       "│ 2        ┆ 11081 │\n",
       "│ 1        ┆ 17529 │\n",
       "│ 6        ┆ 3870  │\n",
       "│ 3        ┆ 11382 │\n",
       "│ 4        ┆ 9388  │\n",
       "│ 5        ┆ 4898  │\n",
       "│ 9        ┆ 2479  │\n",
       "└──────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# one hot encoding for category\n",
    "# with sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "category = df_filtered[\"category\"].to_numpy()\n",
    "category = category.reshape(-1, 1)\n",
    "encoder = OneHotEncoder()\n",
    "category = encoder.fit_transform(category)\n",
    "display(category.shape)\n",
    "# get the count of each category\n",
    "category_count = df_filtered.group_by(\"category\").len()\n",
    "display(category_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "d1e00c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>count</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>2469.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>26.223977</td></tr><tr><td>&quot;std&quot;</td><td>13.942594</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td></tr><tr><td>&quot;25%&quot;</td><td>15.0</td></tr><tr><td>&quot;50%&quot;</td><td>25.0</td></tr><tr><td>&quot;75%&quot;</td><td>35.0</td></tr><tr><td>&quot;max&quot;</td><td>92.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 2)\n",
       "┌────────────┬───────────┐\n",
       "│ statistic  ┆ count     │\n",
       "│ ---        ┆ ---       │\n",
       "│ str        ┆ f64       │\n",
       "╞════════════╪═══════════╡\n",
       "│ count      ┆ 2469.0    │\n",
       "│ null_count ┆ 0.0       │\n",
       "│ mean       ┆ 26.223977 │\n",
       "│ std        ┆ 13.942594 │\n",
       "│ min        ┆ 1.0       │\n",
       "│ 25%        ┆ 15.0      │\n",
       "│ 50%        ┆ 25.0      │\n",
       "│ 75%        ┆ 35.0      │\n",
       "│ max        ┆ 92.0      │\n",
       "└────────────┴───────────┘"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the average count of samples per hurricane (by sample_id)\n",
    "average_samples_per_hurricane = df_features.group_by(\"sample_id\").agg(pl.col(\"sample_id\").count().alias(\"count\")).select(\"count\")\n",
    "average_samples_per_hurricane.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "4a6287e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(average_samples_per_hurricane[\"count\"], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "e20284c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-20 18:20:52.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1m[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "logger.info(tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "77b804da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "display(K.backend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "0db1af2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crosstyan/.conda/envs/cross/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"hurricane_lstm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"hurricane_lstm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_17                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_32 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m18,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_33 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_52 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_17                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m4,800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_53 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m4\u001b[0m)           │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,276</span> (149.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,276\u001b[0m (149.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,276</span> (149.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,276\u001b[0m (149.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, LSTM, Dense, Masking, Dropout, GRU, Bidirectional\n",
    "from keras.optimizers import AdamW, Lion\n",
    "\n",
    "dim_timesteps = X_train.shape[1]\n",
    "dim_features = X_train.shape[2]\n",
    "dim_output_features = y_train.shape[2]\n",
    "model = Sequential([\n",
    "    LSTM(64,\n",
    "         return_sequences=True,\n",
    "         input_shape=(dim_timesteps, dim_features),\n",
    "         kernel_regularizer=keras.regularizers.l1_l2(l1=1e-4, l2=1e-3),\n",
    "         recurrent_regularizer=keras.regularizers.l1_l2(l1=1e-4, l2=1e-3)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32,\n",
    "         return_sequences=True,\n",
    "         kernel_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "         recurrent_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4)),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(GRU(16, return_sequences=True)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(dim_output_features, activation=\"linear\"),\n",
    "],\n",
    "                   name=\"hurricane_lstm\")\n",
    "\n",
    "model.compile(optimizer=Lion(learning_rate=0.00075), loss=\"mean_squared_error\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "3d359152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.7746\n",
      "Epoch 1: val_loss improved from inf to 0.79441, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 190ms/step - loss: 0.8155 - val_loss: 0.7944\n",
      "Epoch 2/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.8071\n",
      "Epoch 2: val_loss improved from 0.79441 to 0.77047, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.8068 - val_loss: 0.7705\n",
      "Epoch 3/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.8359\n",
      "Epoch 3: val_loss improved from 0.77047 to 0.74597, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.7980 - val_loss: 0.7460\n",
      "Epoch 4/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.7789\n",
      "Epoch 4: val_loss improved from 0.74597 to 0.72117, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.7627 - val_loss: 0.7212\n",
      "Epoch 5/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7613\n",
      "Epoch 5: val_loss improved from 0.72117 to 0.69596, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.7432 - val_loss: 0.6960\n",
      "Epoch 6/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7542\n",
      "Epoch 6: val_loss improved from 0.69596 to 0.67105, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.7235 - val_loss: 0.6711\n",
      "Epoch 7/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6661\n",
      "Epoch 7: val_loss improved from 0.67105 to 0.64748, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6827 - val_loss: 0.6475\n",
      "Epoch 8/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6416\n",
      "Epoch 8: val_loss improved from 0.64748 to 0.62591, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6598 - val_loss: 0.6259\n",
      "Epoch 9/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6545\n",
      "Epoch 9: val_loss improved from 0.62591 to 0.60578, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6502 - val_loss: 0.6058\n",
      "Epoch 10/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6300\n",
      "Epoch 10: val_loss improved from 0.60578 to 0.58783, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6310 - val_loss: 0.5878\n",
      "Epoch 11/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6232\n",
      "Epoch 11: val_loss improved from 0.58783 to 0.56992, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6177 - val_loss: 0.5699\n",
      "Epoch 12/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6256\n",
      "Epoch 12: val_loss improved from 0.56992 to 0.54986, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.6073 - val_loss: 0.5499\n",
      "Epoch 13/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5783\n",
      "Epoch 13: val_loss improved from 0.54986 to 0.53040, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5813 - val_loss: 0.5304\n",
      "Epoch 14/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5610\n",
      "Epoch 14: val_loss improved from 0.53040 to 0.51415, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5637 - val_loss: 0.5142\n",
      "Epoch 15/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5544\n",
      "Epoch 15: val_loss improved from 0.51415 to 0.49824, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5478 - val_loss: 0.4982\n",
      "Epoch 16/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5179\n",
      "Epoch 16: val_loss improved from 0.49824 to 0.48284, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5295 - val_loss: 0.4828\n",
      "Epoch 17/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5030\n",
      "Epoch 17: val_loss improved from 0.48284 to 0.47057, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5146 - val_loss: 0.4706\n",
      "Epoch 18/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5303\n",
      "Epoch 18: val_loss improved from 0.47057 to 0.45986, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5171 - val_loss: 0.4599\n",
      "Epoch 19/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4883\n",
      "Epoch 19: val_loss improved from 0.45986 to 0.44629, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4950 - val_loss: 0.4463\n",
      "Epoch 20/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5003\n",
      "Epoch 20: val_loss improved from 0.44629 to 0.43574, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4918 - val_loss: 0.4357\n",
      "Epoch 21/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4662\n",
      "Epoch 21: val_loss improved from 0.43574 to 0.42704, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4771 - val_loss: 0.4270\n",
      "Epoch 22/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4696\n",
      "Epoch 22: val_loss improved from 0.42704 to 0.41743, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4665 - val_loss: 0.4174\n",
      "Epoch 23/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4546\n",
      "Epoch 23: val_loss improved from 0.41743 to 0.40994, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4578 - val_loss: 0.4099\n",
      "Epoch 24/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4747\n",
      "Epoch 24: val_loss improved from 0.40994 to 0.39993, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4540 - val_loss: 0.3999\n",
      "Epoch 25/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.4375\n",
      "Epoch 25: val_loss improved from 0.39993 to 0.39056, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4414 - val_loss: 0.3906\n",
      "Epoch 26/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4070\n",
      "Epoch 26: val_loss improved from 0.39056 to 0.38742, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4252 - val_loss: 0.3874\n",
      "Epoch 27/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4382\n",
      "Epoch 27: val_loss improved from 0.38742 to 0.37692, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4269 - val_loss: 0.3769\n",
      "Epoch 28/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4312\n",
      "Epoch 28: val_loss improved from 0.37692 to 0.37164, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4206 - val_loss: 0.3716\n",
      "Epoch 29/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3865\n",
      "Epoch 29: val_loss improved from 0.37164 to 0.36305, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4014 - val_loss: 0.3631\n",
      "Epoch 30/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4186\n",
      "Epoch 30: val_loss improved from 0.36305 to 0.35722, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4057 - val_loss: 0.3572\n",
      "Epoch 31/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3920\n",
      "Epoch 31: val_loss improved from 0.35722 to 0.35087, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3927 - val_loss: 0.3509\n",
      "Epoch 32/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4069\n",
      "Epoch 32: val_loss improved from 0.35087 to 0.34766, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3943 - val_loss: 0.3477\n",
      "Epoch 33/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3605\n",
      "Epoch 33: val_loss improved from 0.34766 to 0.34539, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3772 - val_loss: 0.3454\n",
      "Epoch 34/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3682\n",
      "Epoch 34: val_loss improved from 0.34539 to 0.34325, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3741 - val_loss: 0.3432\n",
      "Epoch 35/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3968\n",
      "Epoch 35: val_loss improved from 0.34325 to 0.33482, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3770 - val_loss: 0.3348\n",
      "Epoch 36/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3753\n",
      "Epoch 36: val_loss improved from 0.33482 to 0.32950, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3707 - val_loss: 0.3295\n",
      "Epoch 37/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3723\n",
      "Epoch 37: val_loss improved from 0.32950 to 0.32538, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3660 - val_loss: 0.3254\n",
      "Epoch 38/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3511\n",
      "Epoch 38: val_loss improved from 0.32538 to 0.32148, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3552 - val_loss: 0.3215\n",
      "Epoch 39/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3602\n",
      "Epoch 39: val_loss did not improve from 0.32148\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3551 - val_loss: 0.3231\n",
      "Epoch 40/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3755\n",
      "Epoch 40: val_loss improved from 0.32148 to 0.31658, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3589 - val_loss: 0.3166\n",
      "Epoch 41/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3520\n",
      "Epoch 41: val_loss improved from 0.31658 to 0.31167, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3497 - val_loss: 0.3117\n",
      "Epoch 42/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3526\n",
      "Epoch 42: val_loss improved from 0.31167 to 0.30735, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3479 - val_loss: 0.3074\n",
      "Epoch 43/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.3339\n",
      "Epoch 43: val_loss did not improve from 0.30735\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3408 - val_loss: 0.3092\n",
      "Epoch 44/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3538\n",
      "Epoch 44: val_loss improved from 0.30735 to 0.30132, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3445 - val_loss: 0.3013\n",
      "Epoch 45/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3344\n",
      "Epoch 45: val_loss improved from 0.30132 to 0.30129, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3388 - val_loss: 0.3013\n",
      "Epoch 46/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3342\n",
      "Epoch 46: val_loss improved from 0.30129 to 0.29545, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3346 - val_loss: 0.2954\n",
      "Epoch 47/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3427\n",
      "Epoch 47: val_loss improved from 0.29545 to 0.29388, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3353 - val_loss: 0.2939\n",
      "Epoch 48/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3366\n",
      "Epoch 48: val_loss improved from 0.29388 to 0.28996, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3334 - val_loss: 0.2900\n",
      "Epoch 49/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3316\n",
      "Epoch 49: val_loss did not improve from 0.28996\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3258 - val_loss: 0.2908\n",
      "Epoch 50/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3408\n",
      "Epoch 50: val_loss improved from 0.28996 to 0.28511, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3288 - val_loss: 0.2851\n",
      "Epoch 51/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3069\n",
      "Epoch 51: val_loss improved from 0.28511 to 0.28173, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3148 - val_loss: 0.2817\n",
      "Epoch 52/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3332\n",
      "Epoch 52: val_loss did not improve from 0.28173\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3256 - val_loss: 0.2829\n",
      "Epoch 53/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3257\n",
      "Epoch 53: val_loss improved from 0.28173 to 0.27793, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3180 - val_loss: 0.2779\n",
      "Epoch 54/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3200\n",
      "Epoch 54: val_loss improved from 0.27793 to 0.27529, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3143 - val_loss: 0.2753\n",
      "Epoch 55/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3160\n",
      "Epoch 55: val_loss did not improve from 0.27529\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3114 - val_loss: 0.2761\n",
      "Epoch 56/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2927\n",
      "Epoch 56: val_loss improved from 0.27529 to 0.27101, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3013 - val_loss: 0.2710\n",
      "Epoch 57/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3038\n",
      "Epoch 57: val_loss improved from 0.27101 to 0.26980, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3034 - val_loss: 0.2698\n",
      "Epoch 58/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2990\n",
      "Epoch 58: val_loss improved from 0.26980 to 0.26533, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3015 - val_loss: 0.2653\n",
      "Epoch 59/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2945\n",
      "Epoch 59: val_loss improved from 0.26533 to 0.26199, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2977 - val_loss: 0.2620\n",
      "Epoch 60/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2830\n",
      "Epoch 60: val_loss improved from 0.26199 to 0.26013, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2931 - val_loss: 0.2601\n",
      "Epoch 61/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2977\n",
      "Epoch 61: val_loss improved from 0.26013 to 0.25914, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2965 - val_loss: 0.2591\n",
      "Epoch 62/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2873\n",
      "Epoch 62: val_loss did not improve from 0.25914\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2900 - val_loss: 0.2594\n",
      "Epoch 63/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3078\n",
      "Epoch 63: val_loss improved from 0.25914 to 0.25598, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2949 - val_loss: 0.2560\n",
      "Epoch 64/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2853\n",
      "Epoch 64: val_loss improved from 0.25598 to 0.25318, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2877 - val_loss: 0.2532\n",
      "Epoch 65/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2943\n",
      "Epoch 65: val_loss improved from 0.25318 to 0.25161, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2903 - val_loss: 0.2516\n",
      "Epoch 66/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2617\n",
      "Epoch 66: val_loss improved from 0.25161 to 0.24857, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2790 - val_loss: 0.2486\n",
      "Epoch 67/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2833\n",
      "Epoch 67: val_loss improved from 0.24857 to 0.24853, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2841 - val_loss: 0.2485\n",
      "Epoch 68/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2834\n",
      "Epoch 68: val_loss improved from 0.24853 to 0.24506, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2786 - val_loss: 0.2451\n",
      "Epoch 69/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2735\n",
      "Epoch 69: val_loss improved from 0.24506 to 0.24501, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2771 - val_loss: 0.2450\n",
      "Epoch 70/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2801\n",
      "Epoch 70: val_loss improved from 0.24501 to 0.24275, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2775 - val_loss: 0.2427\n",
      "Epoch 71/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2604\n",
      "Epoch 71: val_loss improved from 0.24275 to 0.24195, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2712 - val_loss: 0.2419\n",
      "Epoch 72/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2833\n",
      "Epoch 72: val_loss did not improve from 0.24195\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2759 - val_loss: 0.2420\n",
      "Epoch 73/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2773\n",
      "Epoch 73: val_loss improved from 0.24195 to 0.23966, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2727 - val_loss: 0.2397\n",
      "Epoch 74/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2566\n",
      "Epoch 74: val_loss improved from 0.23966 to 0.23880, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2639 - val_loss: 0.2388\n",
      "Epoch 75/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2738\n",
      "Epoch 75: val_loss did not improve from 0.23880\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2695 - val_loss: 0.2460\n",
      "Epoch 76/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2817\n",
      "Epoch 76: val_loss improved from 0.23880 to 0.23774, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2744 - val_loss: 0.2377\n",
      "Epoch 77/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2702\n",
      "Epoch 77: val_loss did not improve from 0.23774\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2662 - val_loss: 0.2394\n",
      "Epoch 78/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2624\n",
      "Epoch 78: val_loss improved from 0.23774 to 0.23690, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2674 - val_loss: 0.2369\n",
      "Epoch 79/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2719\n",
      "Epoch 79: val_loss did not improve from 0.23690\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2690 - val_loss: 0.2377\n",
      "Epoch 80/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2603\n",
      "Epoch 80: val_loss improved from 0.23690 to 0.23392, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2628 - val_loss: 0.2339\n",
      "Epoch 81/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2581\n",
      "Epoch 81: val_loss improved from 0.23392 to 0.23261, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2622 - val_loss: 0.2326\n",
      "Epoch 82/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2742\n",
      "Epoch 82: val_loss improved from 0.23261 to 0.23257, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2668 - val_loss: 0.2326\n",
      "Epoch 83/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2721\n",
      "Epoch 83: val_loss improved from 0.23257 to 0.23059, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2614 - val_loss: 0.2306\n",
      "Epoch 84/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2654\n",
      "Epoch 84: val_loss did not improve from 0.23059\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2604 - val_loss: 0.2316\n",
      "Epoch 85/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2527\n",
      "Epoch 85: val_loss improved from 0.23059 to 0.22822, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2564 - val_loss: 0.2282\n",
      "Epoch 86/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2580\n",
      "Epoch 86: val_loss improved from 0.22822 to 0.22765, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2564 - val_loss: 0.2277\n",
      "Epoch 87/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2547\n",
      "Epoch 87: val_loss improved from 0.22765 to 0.22701, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2555 - val_loss: 0.2270\n",
      "Epoch 88/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2519\n",
      "Epoch 88: val_loss did not improve from 0.22701\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2545 - val_loss: 0.2291\n",
      "Epoch 89/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2439\n",
      "Epoch 89: val_loss improved from 0.22701 to 0.22593, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2452 - val_loss: 0.2259\n",
      "Epoch 90/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2516\n",
      "Epoch 90: val_loss improved from 0.22593 to 0.22517, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2513 - val_loss: 0.2252\n",
      "Epoch 91/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2460\n",
      "Epoch 91: val_loss did not improve from 0.22517\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2462 - val_loss: 0.2261\n",
      "Epoch 92/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2486\n",
      "Epoch 92: val_loss improved from 0.22517 to 0.22386, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2475 - val_loss: 0.2239\n",
      "Epoch 93/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2361\n",
      "Epoch 93: val_loss improved from 0.22386 to 0.22262, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2421 - val_loss: 0.2226\n",
      "Epoch 94/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2437\n",
      "Epoch 94: val_loss did not improve from 0.22262\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2425 - val_loss: 0.2233\n",
      "Epoch 95/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2395\n",
      "Epoch 95: val_loss improved from 0.22262 to 0.21961, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2434 - val_loss: 0.2196\n",
      "Epoch 96/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2363\n",
      "Epoch 96: val_loss did not improve from 0.21961\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2454 - val_loss: 0.2203\n",
      "Epoch 97/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2308\n",
      "Epoch 97: val_loss improved from 0.21961 to 0.21882, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2363 - val_loss: 0.2188\n",
      "Epoch 98/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2510\n",
      "Epoch 98: val_loss improved from 0.21882 to 0.21833, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2465 - val_loss: 0.2183\n",
      "Epoch 99/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2442\n",
      "Epoch 99: val_loss improved from 0.21833 to 0.21730, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2411 - val_loss: 0.2173\n",
      "Epoch 100/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2324\n",
      "Epoch 100: val_loss did not improve from 0.21730\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2363 - val_loss: 0.2181\n",
      "Epoch 101/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2293\n",
      "Epoch 101: val_loss did not improve from 0.21730\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2362 - val_loss: 0.2197\n",
      "Epoch 102/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2189\n",
      "Epoch 102: val_loss improved from 0.21730 to 0.21554, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2342 - val_loss: 0.2155\n",
      "Epoch 103/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2362\n",
      "Epoch 103: val_loss did not improve from 0.21554\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2378 - val_loss: 0.2164\n",
      "Epoch 104/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2333\n",
      "Epoch 104: val_loss improved from 0.21554 to 0.21518, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2364 - val_loss: 0.2152\n",
      "Epoch 105/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2340\n",
      "Epoch 105: val_loss did not improve from 0.21518\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2371 - val_loss: 0.2165\n",
      "Epoch 106/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2532\n",
      "Epoch 106: val_loss improved from 0.21518 to 0.21337, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2417 - val_loss: 0.2134\n",
      "Epoch 107/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2237\n",
      "Epoch 107: val_loss did not improve from 0.21337\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2307 - val_loss: 0.2148\n",
      "Epoch 108/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2328\n",
      "Epoch 108: val_loss improved from 0.21337 to 0.21254, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2347 - val_loss: 0.2125\n",
      "Epoch 109/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2286\n",
      "Epoch 109: val_loss did not improve from 0.21254\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2315 - val_loss: 0.2127\n",
      "Epoch 110/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2450\n",
      "Epoch 110: val_loss improved from 0.21254 to 0.21195, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2363 - val_loss: 0.2120\n",
      "Epoch 111/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2250\n",
      "Epoch 111: val_loss improved from 0.21195 to 0.21109, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2298 - val_loss: 0.2111\n",
      "Epoch 112/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2349\n",
      "Epoch 112: val_loss improved from 0.21109 to 0.21000, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2313 - val_loss: 0.2100\n",
      "Epoch 113/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2243\n",
      "Epoch 113: val_loss improved from 0.21000 to 0.20873, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2281 - val_loss: 0.2087\n",
      "Epoch 114/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2291\n",
      "Epoch 114: val_loss improved from 0.20873 to 0.20783, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2292 - val_loss: 0.2078\n",
      "Epoch 115/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2318\n",
      "Epoch 115: val_loss did not improve from 0.20783\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2297 - val_loss: 0.2106\n",
      "Epoch 116/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2078\n",
      "Epoch 116: val_loss did not improve from 0.20783\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2212 - val_loss: 0.2096\n",
      "Epoch 117/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2248\n",
      "Epoch 117: val_loss did not improve from 0.20783\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2265 - val_loss: 0.2103\n",
      "Epoch 118/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2291\n",
      "Epoch 118: val_loss improved from 0.20783 to 0.20773, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2262 - val_loss: 0.2077\n",
      "Epoch 119/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2243\n",
      "Epoch 119: val_loss improved from 0.20773 to 0.20740, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2241 - val_loss: 0.2074\n",
      "Epoch 120/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2299\n",
      "Epoch 120: val_loss improved from 0.20740 to 0.20656, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2249 - val_loss: 0.2066\n",
      "Epoch 121/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2266\n",
      "Epoch 121: val_loss did not improve from 0.20656\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2267 - val_loss: 0.2073\n",
      "Epoch 122/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2274\n",
      "Epoch 122: val_loss improved from 0.20656 to 0.20478, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2243 - val_loss: 0.2048\n",
      "Epoch 123/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2064\n",
      "Epoch 123: val_loss did not improve from 0.20478\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2169 - val_loss: 0.2057\n",
      "Epoch 124/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2121\n",
      "Epoch 124: val_loss did not improve from 0.20478\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2215 - val_loss: 0.2053\n",
      "Epoch 125/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2117\n",
      "Epoch 125: val_loss improved from 0.20478 to 0.20452, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2190 - val_loss: 0.2045\n",
      "Epoch 126/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2095\n",
      "Epoch 126: val_loss did not improve from 0.20452\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2172 - val_loss: 0.2061\n",
      "Epoch 127/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2421\n",
      "Epoch 127: val_loss improved from 0.20452 to 0.20252, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2285 - val_loss: 0.2025\n",
      "Epoch 128/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2172\n",
      "Epoch 128: val_loss improved from 0.20252 to 0.20176, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2184 - val_loss: 0.2018\n",
      "Epoch 129/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2379\n",
      "Epoch 129: val_loss did not improve from 0.20176\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2266 - val_loss: 0.2045\n",
      "Epoch 130/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2159\n",
      "Epoch 130: val_loss improved from 0.20176 to 0.20124, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2204 - val_loss: 0.2012\n",
      "Epoch 131/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2245\n",
      "Epoch 131: val_loss did not improve from 0.20124\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2215 - val_loss: 0.2021\n",
      "Epoch 132/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2056\n",
      "Epoch 132: val_loss did not improve from 0.20124\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2141 - val_loss: 0.2036\n",
      "Epoch 133/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2123\n",
      "Epoch 133: val_loss improved from 0.20124 to 0.19972, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2175 - val_loss: 0.1997\n",
      "Epoch 134/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2328\n",
      "Epoch 134: val_loss improved from 0.19972 to 0.19909, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2206 - val_loss: 0.1991\n",
      "Epoch 135/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2233\n",
      "Epoch 135: val_loss did not improve from 0.19909\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2208 - val_loss: 0.2006\n",
      "Epoch 136/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2310\n",
      "Epoch 136: val_loss improved from 0.19909 to 0.19819, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2203 - val_loss: 0.1982\n",
      "Epoch 137/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2282\n",
      "Epoch 137: val_loss did not improve from 0.19819\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2191 - val_loss: 0.1992\n",
      "Epoch 138/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2003\n",
      "Epoch 138: val_loss improved from 0.19819 to 0.19781, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2143 - val_loss: 0.1978\n",
      "Epoch 139/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2077\n",
      "Epoch 139: val_loss did not improve from 0.19781\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2136 - val_loss: 0.1988\n",
      "Epoch 140/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2255\n",
      "Epoch 140: val_loss did not improve from 0.19781\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2165 - val_loss: 0.1983\n",
      "Epoch 141/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2054\n",
      "Epoch 141: val_loss improved from 0.19781 to 0.19737, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2095 - val_loss: 0.1974\n",
      "Epoch 142/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2052\n",
      "Epoch 142: val_loss did not improve from 0.19737\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2136 - val_loss: 0.1977\n",
      "Epoch 143/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2203\n",
      "Epoch 143: val_loss did not improve from 0.19737\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2167 - val_loss: 0.1976\n",
      "Epoch 144/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2056\n",
      "Epoch 144: val_loss did not improve from 0.19737\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2115 - val_loss: 0.1983\n",
      "Epoch 145/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2068\n",
      "Epoch 145: val_loss did not improve from 0.19737\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2123 - val_loss: 0.1989\n",
      "Epoch 146/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2129\n",
      "Epoch 146: val_loss improved from 0.19737 to 0.19666, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2108 - val_loss: 0.1967\n",
      "Epoch 147/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2061\n",
      "Epoch 147: val_loss did not improve from 0.19666\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2131 - val_loss: 0.1986\n",
      "Epoch 148/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2212\n",
      "Epoch 148: val_loss did not improve from 0.19666\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2138 - val_loss: 0.1972\n",
      "Epoch 149/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2102\n",
      "Epoch 149: val_loss did not improve from 0.19666\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2091 - val_loss: 0.1992\n",
      "Epoch 150/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2003\n",
      "Epoch 150: val_loss did not improve from 0.19666\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2081 - val_loss: 0.1973\n",
      "Epoch 151/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2124\n",
      "Epoch 151: val_loss did not improve from 0.19666\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2086 - val_loss: 0.1970\n",
      "Epoch 152/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2080\n",
      "Epoch 152: val_loss did not improve from 0.19666\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2089 - val_loss: 0.1971\n",
      "Epoch 153/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2112\n",
      "Epoch 153: val_loss did not improve from 0.19666\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2106 - val_loss: 0.1968\n",
      "Epoch 154/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2149\n",
      "Epoch 154: val_loss improved from 0.19666 to 0.19486, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2117 - val_loss: 0.1949\n",
      "Epoch 155/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1948\n",
      "Epoch 155: val_loss improved from 0.19486 to 0.19471, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2061 - val_loss: 0.1947\n",
      "Epoch 156/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1985\n",
      "Epoch 156: val_loss improved from 0.19471 to 0.19469, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2036 - val_loss: 0.1947\n",
      "Epoch 157/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2159\n",
      "Epoch 157: val_loss did not improve from 0.19469\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2121 - val_loss: 0.1956\n",
      "Epoch 158/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2068\n",
      "Epoch 158: val_loss improved from 0.19469 to 0.19399, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2071 - val_loss: 0.1940\n",
      "Epoch 159/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2009\n",
      "Epoch 159: val_loss did not improve from 0.19399\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2064 - val_loss: 0.1951\n",
      "Epoch 160/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2075\n",
      "Epoch 160: val_loss improved from 0.19399 to 0.19368, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2052 - val_loss: 0.1937\n",
      "Epoch 161/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1910\n",
      "Epoch 161: val_loss did not improve from 0.19368\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2022 - val_loss: 0.1960\n",
      "Epoch 162/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1967\n",
      "Epoch 162: val_loss improved from 0.19368 to 0.19151, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2034 - val_loss: 0.1915\n",
      "Epoch 163/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2116\n",
      "Epoch 163: val_loss did not improve from 0.19151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2086 - val_loss: 0.1934\n",
      "Epoch 164/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2099\n",
      "Epoch 164: val_loss did not improve from 0.19151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2048 - val_loss: 0.1930\n",
      "Epoch 165/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2092\n",
      "Epoch 165: val_loss did not improve from 0.19151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2066 - val_loss: 0.1969\n",
      "Epoch 166/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2059\n",
      "Epoch 166: val_loss did not improve from 0.19151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2047 - val_loss: 0.1919\n",
      "Epoch 167/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2215\n",
      "Epoch 167: val_loss did not improve from 0.19151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2098 - val_loss: 0.1937\n",
      "Epoch 168/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1866\n",
      "Epoch 168: val_loss improved from 0.19151 to 0.19063, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1984 - val_loss: 0.1906\n",
      "Epoch 169/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2029\n",
      "Epoch 169: val_loss did not improve from 0.19063\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2047 - val_loss: 0.1933\n",
      "Epoch 170/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2033\n",
      "Epoch 170: val_loss did not improve from 0.19063\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2044 - val_loss: 0.1919\n",
      "Epoch 171/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2056\n",
      "Epoch 171: val_loss improved from 0.19063 to 0.18966, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2053 - val_loss: 0.1897\n",
      "Epoch 172/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1968\n",
      "Epoch 172: val_loss improved from 0.18966 to 0.18880, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2001 - val_loss: 0.1888\n",
      "Epoch 173/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2087\n",
      "Epoch 173: val_loss did not improve from 0.18880\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2042 - val_loss: 0.1900\n",
      "Epoch 174/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2089\n",
      "Epoch 174: val_loss did not improve from 0.18880\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2058 - val_loss: 0.1926\n",
      "Epoch 175/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1923\n",
      "Epoch 175: val_loss did not improve from 0.18880\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2025 - val_loss: 0.1895\n",
      "Epoch 176/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2038\n",
      "Epoch 176: val_loss did not improve from 0.18880\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2045 - val_loss: 0.1903\n",
      "Epoch 177/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2183\n",
      "Epoch 177: val_loss did not improve from 0.18880\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2087 - val_loss: 0.1893\n",
      "Epoch 178/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2012\n",
      "Epoch 178: val_loss did not improve from 0.18880\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2015 - val_loss: 0.1917\n",
      "Epoch 179/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1992\n",
      "Epoch 179: val_loss improved from 0.18880 to 0.18845, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2026 - val_loss: 0.1885\n",
      "Epoch 180/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2013\n",
      "Epoch 180: val_loss did not improve from 0.18845\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2022 - val_loss: 0.1901\n",
      "Epoch 181/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1979\n",
      "Epoch 181: val_loss did not improve from 0.18845\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2001 - val_loss: 0.1891\n",
      "Epoch 182/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2152\n",
      "Epoch 182: val_loss did not improve from 0.18845\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2036 - val_loss: 0.1900\n",
      "Epoch 183/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1922\n",
      "Epoch 183: val_loss did not improve from 0.18845\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1975 - val_loss: 0.1916\n",
      "Epoch 184/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1987\n",
      "Epoch 184: val_loss did not improve from 0.18845\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1991 - val_loss: 0.1925\n",
      "Epoch 185/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2021\n",
      "Epoch 185: val_loss did not improve from 0.18845\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2012 - val_loss: 0.1910\n",
      "Epoch 186/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1884\n",
      "Epoch 186: val_loss improved from 0.18845 to 0.18803, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1977 - val_loss: 0.1880\n",
      "Epoch 187/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2064\n",
      "Epoch 187: val_loss did not improve from 0.18803\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2033 - val_loss: 0.1894\n",
      "Epoch 188/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1957\n",
      "Epoch 188: val_loss did not improve from 0.18803\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1984 - val_loss: 0.1894\n",
      "Epoch 189/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1931\n",
      "Epoch 189: val_loss did not improve from 0.18803\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1977 - val_loss: 0.1885\n",
      "Epoch 190/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2013\n",
      "Epoch 190: val_loss did not improve from 0.18803\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2015 - val_loss: 0.1890\n",
      "Epoch 191/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2040\n",
      "Epoch 191: val_loss did not improve from 0.18803\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2029 - val_loss: 0.1900\n",
      "Epoch 192/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2028\n",
      "Epoch 192: val_loss improved from 0.18803 to 0.18742, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1988 - val_loss: 0.1874\n",
      "Epoch 193/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1873\n",
      "Epoch 193: val_loss improved from 0.18742 to 0.18710, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1935 - val_loss: 0.1871\n",
      "Epoch 194/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1980\n",
      "Epoch 194: val_loss did not improve from 0.18710\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1998 - val_loss: 0.1874\n",
      "Epoch 195/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2019\n",
      "Epoch 195: val_loss did not improve from 0.18710\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1981 - val_loss: 0.1882\n",
      "Epoch 196/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1943\n",
      "Epoch 196: val_loss did not improve from 0.18710\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1948 - val_loss: 0.1874\n",
      "Epoch 197/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1977\n",
      "Epoch 197: val_loss did not improve from 0.18710\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1987 - val_loss: 0.1873\n",
      "Epoch 198/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1839\n",
      "Epoch 198: val_loss did not improve from 0.18710\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1941 - val_loss: 0.1872\n",
      "Epoch 199/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1926\n",
      "Epoch 199: val_loss improved from 0.18710 to 0.18662, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1960 - val_loss: 0.1866\n",
      "Epoch 200/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2070\n",
      "Epoch 200: val_loss did not improve from 0.18662\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2002 - val_loss: 0.1888\n",
      "Epoch 201/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1993\n",
      "Epoch 201: val_loss improved from 0.18662 to 0.18471, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1976 - val_loss: 0.1847\n",
      "Epoch 202/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2010\n",
      "Epoch 202: val_loss did not improve from 0.18471\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1988 - val_loss: 0.1866\n",
      "Epoch 203/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2043\n",
      "Epoch 203: val_loss did not improve from 0.18471\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1963 - val_loss: 0.1870\n",
      "Epoch 204/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1874\n",
      "Epoch 204: val_loss did not improve from 0.18471\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1929 - val_loss: 0.1897\n",
      "Epoch 205/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1944\n",
      "Epoch 205: val_loss did not improve from 0.18471\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1966 - val_loss: 0.1855\n",
      "Epoch 206/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2057\n",
      "Epoch 206: val_loss did not improve from 0.18471\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1976 - val_loss: 0.1861\n",
      "Epoch 207/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1949\n",
      "Epoch 207: val_loss improved from 0.18471 to 0.18456, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1975 - val_loss: 0.1846\n",
      "Epoch 208/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1903\n",
      "Epoch 208: val_loss improved from 0.18456 to 0.18456, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1958 - val_loss: 0.1846\n",
      "Epoch 209/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1800\n",
      "Epoch 209: val_loss did not improve from 0.18456\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1912 - val_loss: 0.1856\n",
      "Epoch 210/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1981\n",
      "Epoch 210: val_loss improved from 0.18456 to 0.18422, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1962 - val_loss: 0.1842\n",
      "Epoch 211/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1919\n",
      "Epoch 211: val_loss did not improve from 0.18422\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1917 - val_loss: 0.1853\n",
      "Epoch 212/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1901\n",
      "Epoch 212: val_loss did not improve from 0.18422\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1931 - val_loss: 0.1863\n",
      "Epoch 213/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1894\n",
      "Epoch 213: val_loss did not improve from 0.18422\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1927 - val_loss: 0.1846\n",
      "Epoch 214/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1914\n",
      "Epoch 214: val_loss did not improve from 0.18422\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1918 - val_loss: 0.1856\n",
      "Epoch 215/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1930\n",
      "Epoch 215: val_loss did not improve from 0.18422\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1934 - val_loss: 0.1842\n",
      "Epoch 216/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2046\n",
      "Epoch 216: val_loss improved from 0.18422 to 0.18357, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.1970 - val_loss: 0.1836\n",
      "Epoch 217/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1905\n",
      "Epoch 217: val_loss did not improve from 0.18357\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1918 - val_loss: 0.1841\n",
      "Epoch 218/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2104\n",
      "Epoch 218: val_loss did not improve from 0.18357\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2001 - val_loss: 0.1851\n",
      "Epoch 219/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1922\n",
      "Epoch 219: val_loss did not improve from 0.18357\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1924 - val_loss: 0.1848\n",
      "Epoch 220/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1930\n",
      "Epoch 220: val_loss did not improve from 0.18357\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1938 - val_loss: 0.1839\n",
      "Epoch 221/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1886\n",
      "Epoch 221: val_loss improved from 0.18357 to 0.18297, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1907 - val_loss: 0.1830\n",
      "Epoch 222/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1991\n",
      "Epoch 222: val_loss did not improve from 0.18297\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1939 - val_loss: 0.1855\n",
      "Epoch 223/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1873\n",
      "Epoch 223: val_loss did not improve from 0.18297\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1910 - val_loss: 0.1833\n",
      "Epoch 224/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1981\n",
      "Epoch 224: val_loss did not improve from 0.18297\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1914 - val_loss: 0.1853\n",
      "Epoch 225/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2016\n",
      "Epoch 225: val_loss did not improve from 0.18297\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1967 - val_loss: 0.1832\n",
      "Epoch 226/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1922\n",
      "Epoch 226: val_loss improved from 0.18297 to 0.18269, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1911 - val_loss: 0.1827\n",
      "Epoch 227/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1888\n",
      "Epoch 227: val_loss improved from 0.18269 to 0.18038, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1899 - val_loss: 0.1804\n",
      "Epoch 228/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2039\n",
      "Epoch 228: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1957 - val_loss: 0.1838\n",
      "Epoch 229/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1805\n",
      "Epoch 229: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1895 - val_loss: 0.1806\n",
      "Epoch 230/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1865\n",
      "Epoch 230: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1876 - val_loss: 0.1816\n",
      "Epoch 231/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1895\n",
      "Epoch 231: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1897 - val_loss: 0.1829\n",
      "Epoch 232/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1889\n",
      "Epoch 232: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1910 - val_loss: 0.1814\n",
      "Epoch 233/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2029\n",
      "Epoch 233: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1921 - val_loss: 0.1819\n",
      "Epoch 234/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1908\n",
      "Epoch 234: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1876 - val_loss: 0.1836\n",
      "Epoch 235/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1787\n",
      "Epoch 235: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1854 - val_loss: 0.1826\n",
      "Epoch 236/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1789\n",
      "Epoch 236: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1863 - val_loss: 0.1822\n",
      "Epoch 237/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1897\n",
      "Epoch 237: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1906 - val_loss: 0.1822\n",
      "Epoch 238/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1866\n",
      "Epoch 238: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1890 - val_loss: 0.1816\n",
      "Epoch 239/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1912\n",
      "Epoch 239: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1892 - val_loss: 0.1822\n",
      "Epoch 240/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1849\n",
      "Epoch 240: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1870 - val_loss: 0.1826\n",
      "Epoch 241/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1966\n",
      "Epoch 241: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1913 - val_loss: 0.1834\n",
      "Epoch 242/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1896\n",
      "Epoch 242: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1878 - val_loss: 0.1845\n",
      "Epoch 243/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1906\n",
      "Epoch 243: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1868 - val_loss: 0.1814\n",
      "Epoch 244/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1704\n",
      "Epoch 244: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1817 - val_loss: 0.1805\n",
      "Epoch 245/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1908\n",
      "Epoch 245: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1887 - val_loss: 0.1842\n",
      "Epoch 246/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1973\n",
      "Epoch 246: val_loss did not improve from 0.18038\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1894 - val_loss: 0.1809\n",
      "Epoch 247/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1916\n",
      "Epoch 247: val_loss improved from 0.18038 to 0.17982, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1901 - val_loss: 0.1798\n",
      "Epoch 248/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1888\n",
      "Epoch 248: val_loss did not improve from 0.17982\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1884 - val_loss: 0.1816\n",
      "Epoch 249/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1798\n",
      "Epoch 249: val_loss did not improve from 0.17982\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1843 - val_loss: 0.1801\n",
      "Epoch 250/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1945\n",
      "Epoch 250: val_loss did not improve from 0.17982\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1879 - val_loss: 0.1830\n",
      "Epoch 251/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1874\n",
      "Epoch 251: val_loss did not improve from 0.17982\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1856 - val_loss: 0.1819\n",
      "Epoch 252/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1820\n",
      "Epoch 252: val_loss improved from 0.17982 to 0.17970, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1853 - val_loss: 0.1797\n",
      "Epoch 253/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1820\n",
      "Epoch 253: val_loss did not improve from 0.17970\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1854 - val_loss: 0.1804\n",
      "Epoch 254/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1794\n",
      "Epoch 254: val_loss did not improve from 0.17970\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1840 - val_loss: 0.1826\n",
      "Epoch 255/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1846\n",
      "Epoch 255: val_loss did not improve from 0.17970\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1883 - val_loss: 0.1811\n",
      "Epoch 256/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1820\n",
      "Epoch 256: val_loss did not improve from 0.17970\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1841 - val_loss: 0.1829\n",
      "Epoch 257/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1880\n",
      "Epoch 257: val_loss did not improve from 0.17970\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1851 - val_loss: 0.1813\n",
      "Epoch 258/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1914\n",
      "Epoch 258: val_loss did not improve from 0.17970\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1843 - val_loss: 0.1856\n",
      "Epoch 259/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1800\n",
      "Epoch 259: val_loss did not improve from 0.17970\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1827 - val_loss: 0.1824\n",
      "Epoch 260/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1916\n",
      "Epoch 260: val_loss improved from 0.17970 to 0.17957, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1850 - val_loss: 0.1796\n",
      "Epoch 261/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1810\n",
      "Epoch 261: val_loss did not improve from 0.17957\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1849 - val_loss: 0.1808\n",
      "Epoch 262/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1851\n",
      "Epoch 262: val_loss did not improve from 0.17957\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1847 - val_loss: 0.1814\n",
      "Epoch 263/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1797\n",
      "Epoch 263: val_loss improved from 0.17957 to 0.17907, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1836 - val_loss: 0.1791\n",
      "Epoch 264/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1774\n",
      "Epoch 264: val_loss did not improve from 0.17907\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1818 - val_loss: 0.1809\n",
      "Epoch 265/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1747\n",
      "Epoch 265: val_loss did not improve from 0.17907\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1820 - val_loss: 0.1829\n",
      "Epoch 266/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1888\n",
      "Epoch 266: val_loss did not improve from 0.17907\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1842 - val_loss: 0.1794\n",
      "Epoch 267/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1964\n",
      "Epoch 267: val_loss did not improve from 0.17907\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1869 - val_loss: 0.1793\n",
      "Epoch 268/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1805\n",
      "Epoch 268: val_loss did not improve from 0.17907\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1820 - val_loss: 0.1795\n",
      "Epoch 269/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1872\n",
      "Epoch 269: val_loss did not improve from 0.17907\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1834 - val_loss: 0.1817\n",
      "Epoch 270/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1858\n",
      "Epoch 270: val_loss did not improve from 0.17907\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1856 - val_loss: 0.1800\n",
      "Epoch 271/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1714\n",
      "Epoch 271: val_loss did not improve from 0.17907\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1795 - val_loss: 0.1812\n",
      "Epoch 272/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1656\n",
      "Epoch 272: val_loss improved from 0.17907 to 0.17864, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.1810 - val_loss: 0.1786\n",
      "Epoch 273/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1799\n",
      "Epoch 273: val_loss did not improve from 0.17864\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1816 - val_loss: 0.1804\n",
      "Epoch 274/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1779\n",
      "Epoch 274: val_loss did not improve from 0.17864\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1798 - val_loss: 0.1792\n",
      "Epoch 275/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1897\n",
      "Epoch 275: val_loss did not improve from 0.17864\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1858 - val_loss: 0.1806\n",
      "Epoch 276/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1813\n",
      "Epoch 276: val_loss improved from 0.17864 to 0.17766, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1818 - val_loss: 0.1777\n",
      "Epoch 277/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1854\n",
      "Epoch 277: val_loss did not improve from 0.17766\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1825 - val_loss: 0.1811\n",
      "Epoch 278/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1813\n",
      "Epoch 278: val_loss did not improve from 0.17766\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1818 - val_loss: 0.1778\n",
      "Epoch 279/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1795\n",
      "Epoch 279: val_loss improved from 0.17766 to 0.17729, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1820 - val_loss: 0.1773\n",
      "Epoch 280/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1878\n",
      "Epoch 280: val_loss improved from 0.17729 to 0.17721, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1841 - val_loss: 0.1772\n",
      "Epoch 281/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1805\n",
      "Epoch 281: val_loss improved from 0.17721 to 0.17567, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1820 - val_loss: 0.1757\n",
      "Epoch 282/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1823\n",
      "Epoch 282: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1803 - val_loss: 0.1779\n",
      "Epoch 283/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1854\n",
      "Epoch 283: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1816 - val_loss: 0.1796\n",
      "Epoch 284/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1804\n",
      "Epoch 284: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1793 - val_loss: 0.1778\n",
      "Epoch 285/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1826\n",
      "Epoch 285: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1818 - val_loss: 0.1775\n",
      "Epoch 286/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1786\n",
      "Epoch 286: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1795 - val_loss: 0.1787\n",
      "Epoch 287/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1745\n",
      "Epoch 287: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1749 - val_loss: 0.1780\n",
      "Epoch 288/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1968\n",
      "Epoch 288: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1840 - val_loss: 0.1784\n",
      "Epoch 289/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1835\n",
      "Epoch 289: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1836 - val_loss: 0.1761\n",
      "Epoch 290/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1780\n",
      "Epoch 290: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1781 - val_loss: 0.1768\n",
      "Epoch 291/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1824\n",
      "Epoch 291: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1805 - val_loss: 0.1774\n",
      "Epoch 292/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1852\n",
      "Epoch 292: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1814 - val_loss: 0.1792\n",
      "Epoch 293/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1914\n",
      "Epoch 293: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1869 - val_loss: 0.1770\n",
      "Epoch 294/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1740\n",
      "Epoch 294: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1786 - val_loss: 0.1789\n",
      "Epoch 295/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1824\n",
      "Epoch 295: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1790 - val_loss: 0.1781\n",
      "Epoch 296/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1727\n",
      "Epoch 296: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1753 - val_loss: 0.1774\n",
      "Epoch 297/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1803\n",
      "Epoch 297: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1774 - val_loss: 0.1766\n",
      "Epoch 298/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1746\n",
      "Epoch 298: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1757 - val_loss: 0.1797\n",
      "Epoch 299/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1797\n",
      "Epoch 299: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1792 - val_loss: 0.1782\n",
      "Epoch 300/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1813\n",
      "Epoch 300: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1798 - val_loss: 0.1789\n",
      "Epoch 301/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1851\n",
      "Epoch 301: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1803 - val_loss: 0.1790\n",
      "Epoch 302/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1848\n",
      "Epoch 302: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1795 - val_loss: 0.1786\n",
      "Epoch 303/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1774\n",
      "Epoch 303: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1781 - val_loss: 0.1769\n",
      "Epoch 304/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1697\n",
      "Epoch 304: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1763 - val_loss: 0.1816\n",
      "Epoch 305/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1694\n",
      "Epoch 305: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1757 - val_loss: 0.1794\n",
      "Epoch 306/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1717\n",
      "Epoch 306: val_loss did not improve from 0.17567\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1757 - val_loss: 0.1798\n",
      "Epoch 307/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1804\n",
      "Epoch 307: val_loss improved from 0.17567 to 0.17518, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1785 - val_loss: 0.1752\n",
      "Epoch 308/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1698\n",
      "Epoch 308: val_loss did not improve from 0.17518\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1743 - val_loss: 0.1770\n",
      "Epoch 309/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1756\n",
      "Epoch 309: val_loss did not improve from 0.17518\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1766 - val_loss: 0.1801\n",
      "Epoch 310/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1771\n",
      "Epoch 310: val_loss improved from 0.17518 to 0.17444, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1758 - val_loss: 0.1744\n",
      "Epoch 311/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1786\n",
      "Epoch 311: val_loss did not improve from 0.17444\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1780 - val_loss: 0.1767\n",
      "Epoch 312/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1788\n",
      "Epoch 312: val_loss did not improve from 0.17444\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1772 - val_loss: 0.1760\n",
      "Epoch 313/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1584\n",
      "Epoch 313: val_loss did not improve from 0.17444\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1707 - val_loss: 0.1776\n",
      "Epoch 314/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1673\n",
      "Epoch 314: val_loss did not improve from 0.17444\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1727 - val_loss: 0.1762\n",
      "Epoch 315/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1823\n",
      "Epoch 315: val_loss did not improve from 0.17444\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1769 - val_loss: 0.1782\n",
      "Epoch 316/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1679\n",
      "Epoch 316: val_loss did not improve from 0.17444\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1722 - val_loss: 0.1762\n",
      "Epoch 317/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1732\n",
      "Epoch 317: val_loss did not improve from 0.17444\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1756 - val_loss: 0.1777\n",
      "Epoch 318/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1758\n",
      "Epoch 318: val_loss did not improve from 0.17444\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1763 - val_loss: 0.1762\n",
      "Epoch 319/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1865\n",
      "Epoch 319: val_loss improved from 0.17444 to 0.17333, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1774 - val_loss: 0.1733\n",
      "Epoch 320/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1788\n",
      "Epoch 320: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1759 - val_loss: 0.1766\n",
      "Epoch 321/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1788\n",
      "Epoch 321: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1764 - val_loss: 0.1736\n",
      "Epoch 322/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1538\n",
      "Epoch 322: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1707 - val_loss: 0.1744\n",
      "Epoch 323/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1768\n",
      "Epoch 323: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1745 - val_loss: 0.1748\n",
      "Epoch 324/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1778\n",
      "Epoch 324: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1770 - val_loss: 0.1746\n",
      "Epoch 325/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1713\n",
      "Epoch 325: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1729 - val_loss: 0.1746\n",
      "Epoch 326/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1722\n",
      "Epoch 326: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1740 - val_loss: 0.1758\n",
      "Epoch 327/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1707\n",
      "Epoch 327: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1720 - val_loss: 0.1769\n",
      "Epoch 328/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1666\n",
      "Epoch 328: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1693 - val_loss: 0.1769\n",
      "Epoch 329/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1779\n",
      "Epoch 329: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1752 - val_loss: 0.1775\n",
      "Epoch 330/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1664\n",
      "Epoch 330: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1711 - val_loss: 0.1753\n",
      "Epoch 331/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1742\n",
      "Epoch 331: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1731 - val_loss: 0.1785\n",
      "Epoch 332/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1764\n",
      "Epoch 332: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1744 - val_loss: 0.1766\n",
      "Epoch 333/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1762\n",
      "Epoch 333: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1763 - val_loss: 0.1771\n",
      "Epoch 334/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1637\n",
      "Epoch 334: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1691 - val_loss: 0.1747\n",
      "Epoch 335/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1761\n",
      "Epoch 335: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1739 - val_loss: 0.1773\n",
      "Epoch 336/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1930\n",
      "Epoch 336: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1800 - val_loss: 0.1766\n",
      "Epoch 337/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1720\n",
      "Epoch 337: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1734 - val_loss: 0.1737\n",
      "Epoch 338/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1871\n",
      "Epoch 338: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1789 - val_loss: 0.1775\n",
      "Epoch 339/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1658\n",
      "Epoch 339: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1723 - val_loss: 0.1762\n",
      "Epoch 340/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1568\n",
      "Epoch 340: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1704 - val_loss: 0.1738\n",
      "Epoch 341/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1782\n",
      "Epoch 341: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1758 - val_loss: 0.1786\n",
      "Epoch 342/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1655\n",
      "Epoch 342: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1716 - val_loss: 0.1787\n",
      "Epoch 343/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1751\n",
      "Epoch 343: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1735 - val_loss: 0.1751\n",
      "Epoch 344/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1831\n",
      "Epoch 344: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1758 - val_loss: 0.1794\n",
      "Epoch 345/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1702\n",
      "Epoch 345: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1720 - val_loss: 0.1760\n",
      "Epoch 346/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1795\n",
      "Epoch 346: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1765 - val_loss: 0.1781\n",
      "Epoch 347/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1687\n",
      "Epoch 347: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1712 - val_loss: 0.1760\n",
      "Epoch 348/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1700\n",
      "Epoch 348: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1702 - val_loss: 0.1756\n",
      "Epoch 349/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1684\n",
      "Epoch 349: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1710 - val_loss: 0.1753\n",
      "Epoch 350/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1692\n",
      "Epoch 350: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1703 - val_loss: 0.1743\n",
      "Epoch 351/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1694\n",
      "Epoch 351: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1717 - val_loss: 0.1747\n",
      "Epoch 352/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1688\n",
      "Epoch 352: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1721 - val_loss: 0.1757\n",
      "Epoch 353/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1621\n",
      "Epoch 353: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1690 - val_loss: 0.1737\n",
      "Epoch 354/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1705\n",
      "Epoch 354: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1688 - val_loss: 0.1750\n",
      "Epoch 355/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1668\n",
      "Epoch 355: val_loss did not improve from 0.17333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1693 - val_loss: 0.1752\n",
      "Epoch 356/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1702\n",
      "Epoch 356: val_loss improved from 0.17333 to 0.17304, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.1712 - val_loss: 0.1730\n",
      "Epoch 357/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1687\n",
      "Epoch 357: val_loss did not improve from 0.17304\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1708 - val_loss: 0.1767\n",
      "Epoch 358/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1611\n",
      "Epoch 358: val_loss did not improve from 0.17304\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1681 - val_loss: 0.1794\n",
      "Epoch 359/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1722\n",
      "Epoch 359: val_loss did not improve from 0.17304\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1720 - val_loss: 0.1737\n",
      "Epoch 360/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1637\n",
      "Epoch 360: val_loss improved from 0.17304 to 0.17252, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1693 - val_loss: 0.1725\n",
      "Epoch 361/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1723\n",
      "Epoch 361: val_loss did not improve from 0.17252\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1706 - val_loss: 0.1736\n",
      "Epoch 362/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1592\n",
      "Epoch 362: val_loss did not improve from 0.17252\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1687 - val_loss: 0.1774\n",
      "Epoch 363/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1728\n",
      "Epoch 363: val_loss did not improve from 0.17252\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1703 - val_loss: 0.1725\n",
      "Epoch 364/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1618\n",
      "Epoch 364: val_loss improved from 0.17252 to 0.17225, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1679 - val_loss: 0.1722\n",
      "Epoch 365/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1691\n",
      "Epoch 365: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1729 - val_loss: 0.1742\n",
      "Epoch 366/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1616\n",
      "Epoch 366: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1664 - val_loss: 0.1739\n",
      "Epoch 367/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1721\n",
      "Epoch 367: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1734 - val_loss: 0.1732\n",
      "Epoch 368/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1769\n",
      "Epoch 368: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1725 - val_loss: 0.1728\n",
      "Epoch 369/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1564\n",
      "Epoch 369: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1658 - val_loss: 0.1774\n",
      "Epoch 370/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1800\n",
      "Epoch 370: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1731 - val_loss: 0.1750\n",
      "Epoch 371/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1747\n",
      "Epoch 371: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1698 - val_loss: 0.1730\n",
      "Epoch 372/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1758\n",
      "Epoch 372: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1693 - val_loss: 0.1755\n",
      "Epoch 373/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1688\n",
      "Epoch 373: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1703 - val_loss: 0.1737\n",
      "Epoch 374/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1713\n",
      "Epoch 374: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1700 - val_loss: 0.1747\n",
      "Epoch 375/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1615\n",
      "Epoch 375: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1658 - val_loss: 0.1745\n",
      "Epoch 376/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1652\n",
      "Epoch 376: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1687 - val_loss: 0.1747\n",
      "Epoch 377/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1656\n",
      "Epoch 377: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1662 - val_loss: 0.1755\n",
      "Epoch 378/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1731\n",
      "Epoch 378: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1709 - val_loss: 0.1761\n",
      "Epoch 379/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1542\n",
      "Epoch 379: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1652 - val_loss: 0.1726\n",
      "Epoch 380/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1663\n",
      "Epoch 380: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1684 - val_loss: 0.1730\n",
      "Epoch 381/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1650\n",
      "Epoch 381: val_loss did not improve from 0.17225\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1661 - val_loss: 0.1773\n",
      "Epoch 382/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1702\n",
      "Epoch 382: val_loss improved from 0.17225 to 0.17213, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1685 - val_loss: 0.1721\n",
      "Epoch 383/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1630\n",
      "Epoch 383: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1678 - val_loss: 0.1779\n",
      "Epoch 384/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1718\n",
      "Epoch 384: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1711 - val_loss: 0.1733\n",
      "Epoch 385/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1599\n",
      "Epoch 385: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1645 - val_loss: 0.1751\n",
      "Epoch 386/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1586\n",
      "Epoch 386: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1650 - val_loss: 0.1747\n",
      "Epoch 387/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1689\n",
      "Epoch 387: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1666 - val_loss: 0.1790\n",
      "Epoch 388/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1629\n",
      "Epoch 388: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1667 - val_loss: 0.1735\n",
      "Epoch 389/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1694\n",
      "Epoch 389: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1679 - val_loss: 0.1747\n",
      "Epoch 390/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1704\n",
      "Epoch 390: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1679 - val_loss: 0.1740\n",
      "Epoch 391/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1736\n",
      "Epoch 391: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1686 - val_loss: 0.1744\n",
      "Epoch 392/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1682\n",
      "Epoch 392: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1673 - val_loss: 0.1739\n",
      "Epoch 393/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1693\n",
      "Epoch 393: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1668 - val_loss: 0.1773\n",
      "Epoch 394/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1751\n",
      "Epoch 394: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1696 - val_loss: 0.1772\n",
      "Epoch 395/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1673\n",
      "Epoch 395: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1662 - val_loss: 0.1749\n",
      "Epoch 396/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1638\n",
      "Epoch 396: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1662 - val_loss: 0.1762\n",
      "Epoch 397/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1630\n",
      "Epoch 397: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1682 - val_loss: 0.1750\n",
      "Epoch 398/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1639\n",
      "Epoch 398: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1650 - val_loss: 0.1781\n",
      "Epoch 399/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1623\n",
      "Epoch 399: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1637 - val_loss: 0.1769\n",
      "Epoch 400/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1739\n",
      "Epoch 400: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1676 - val_loss: 0.1740\n",
      "Epoch 401/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1642\n",
      "Epoch 401: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1643 - val_loss: 0.1784\n",
      "Epoch 402/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1436\n",
      "Epoch 402: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1605 - val_loss: 0.1741\n",
      "Epoch 403/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1640\n",
      "Epoch 403: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1649 - val_loss: 0.1792\n",
      "Epoch 404/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1593\n",
      "Epoch 404: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1674 - val_loss: 0.1751\n",
      "Epoch 405/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1733\n",
      "Epoch 405: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1687 - val_loss: 0.1782\n",
      "Epoch 406/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1585\n",
      "Epoch 406: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1636 - val_loss: 0.1757\n",
      "Epoch 407/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1632\n",
      "Epoch 407: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1633 - val_loss: 0.1732\n",
      "Epoch 408/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1586\n",
      "Epoch 408: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1633 - val_loss: 0.1752\n",
      "Epoch 409/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1566\n",
      "Epoch 409: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1627 - val_loss: 0.1747\n",
      "Epoch 410/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1672\n",
      "Epoch 410: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1660 - val_loss: 0.1753\n",
      "Epoch 411/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1728\n",
      "Epoch 411: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1673 - val_loss: 0.1735\n",
      "Epoch 412/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1676\n",
      "Epoch 412: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1667 - val_loss: 0.1774\n",
      "Epoch 413/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1668\n",
      "Epoch 413: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1662 - val_loss: 0.1735\n",
      "Epoch 414/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1706\n",
      "Epoch 414: val_loss did not improve from 0.17213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1676 - val_loss: 0.1742\n",
      "Epoch 415/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1671\n",
      "Epoch 415: val_loss improved from 0.17213 to 0.17153, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1653 - val_loss: 0.1715\n",
      "Epoch 416/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1632\n",
      "Epoch 416: val_loss did not improve from 0.17153\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1631 - val_loss: 0.1763\n",
      "Epoch 417/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1607\n",
      "Epoch 417: val_loss did not improve from 0.17153\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1622 - val_loss: 0.1755\n",
      "Epoch 418/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1661\n",
      "Epoch 418: val_loss did not improve from 0.17153\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1632 - val_loss: 0.1750\n",
      "Epoch 419/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1651\n",
      "Epoch 419: val_loss did not improve from 0.17153\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1651 - val_loss: 0.1745\n",
      "Epoch 420/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1606\n",
      "Epoch 420: val_loss did not improve from 0.17153\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1642 - val_loss: 0.1729\n",
      "Epoch 421/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1568\n",
      "Epoch 421: val_loss did not improve from 0.17153\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1621 - val_loss: 0.1763\n",
      "Epoch 422/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1618\n",
      "Epoch 422: val_loss did not improve from 0.17153\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1645 - val_loss: 0.1757\n",
      "Epoch 423/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1597\n",
      "Epoch 423: val_loss did not improve from 0.17153\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1615 - val_loss: 0.1749\n",
      "Epoch 424/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1608\n",
      "Epoch 424: val_loss did not improve from 0.17153\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1639 - val_loss: 0.1741\n",
      "Epoch 425/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1596\n",
      "Epoch 425: val_loss did not improve from 0.17153\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1645 - val_loss: 0.1762\n",
      "Epoch 426/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1663\n",
      "Epoch 426: val_loss did not improve from 0.17153\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1632 - val_loss: 0.1740\n",
      "Epoch 427/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1625\n",
      "Epoch 427: val_loss did not improve from 0.17153\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1646 - val_loss: 0.1740\n",
      "Epoch 428/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1652\n",
      "Epoch 428: val_loss did not improve from 0.17153\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1647 - val_loss: 0.1738\n",
      "Epoch 429/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1726\n",
      "Epoch 429: val_loss improved from 0.17153 to 0.17151, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1663 - val_loss: 0.1715\n",
      "Epoch 430/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1550\n",
      "Epoch 430: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1602 - val_loss: 0.1765\n",
      "Epoch 431/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1540\n",
      "Epoch 431: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1594 - val_loss: 0.1731\n",
      "Epoch 432/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1550\n",
      "Epoch 432: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1607 - val_loss: 0.1762\n",
      "Epoch 433/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1539\n",
      "Epoch 433: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1615 - val_loss: 0.1742\n",
      "Epoch 434/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1644\n",
      "Epoch 434: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1618 - val_loss: 0.1731\n",
      "Epoch 435/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1611\n",
      "Epoch 435: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1620 - val_loss: 0.1746\n",
      "Epoch 436/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1758\n",
      "Epoch 436: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1678 - val_loss: 0.1721\n",
      "Epoch 437/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1601\n",
      "Epoch 437: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1624 - val_loss: 0.1743\n",
      "Epoch 438/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1774\n",
      "Epoch 438: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1662 - val_loss: 0.1719\n",
      "Epoch 439/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1557\n",
      "Epoch 439: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1585 - val_loss: 0.1793\n",
      "Epoch 440/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1600\n",
      "Epoch 440: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1627 - val_loss: 0.1740\n",
      "Epoch 441/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1535\n",
      "Epoch 441: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1590 - val_loss: 0.1757\n",
      "Epoch 442/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1519\n",
      "Epoch 442: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1579 - val_loss: 0.1722\n",
      "Epoch 443/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1696\n",
      "Epoch 443: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1627 - val_loss: 0.1741\n",
      "Epoch 444/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1662\n",
      "Epoch 444: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1641 - val_loss: 0.1764\n",
      "Epoch 445/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1618\n",
      "Epoch 445: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1642 - val_loss: 0.1736\n",
      "Epoch 446/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1637\n",
      "Epoch 446: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1628 - val_loss: 0.1749\n",
      "Epoch 447/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1583\n",
      "Epoch 447: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1621 - val_loss: 0.1739\n",
      "Epoch 448/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1611\n",
      "Epoch 448: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1612 - val_loss: 0.1744\n",
      "Epoch 449/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1695\n",
      "Epoch 449: val_loss did not improve from 0.17151\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1659 - val_loss: 0.1767\n",
      "Epoch 450/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1745\n",
      "Epoch 450: val_loss improved from 0.17151 to 0.17104, saving model to hurricane_lstm.keras\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1663 - val_loss: 0.1710\n",
      "Epoch 451/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1639\n",
      "Epoch 451: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1631 - val_loss: 0.1729\n",
      "Epoch 452/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1695\n",
      "Epoch 452: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1635 - val_loss: 0.1716\n",
      "Epoch 453/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1625\n",
      "Epoch 453: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1628 - val_loss: 0.1720\n",
      "Epoch 454/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1600\n",
      "Epoch 454: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1618 - val_loss: 0.1744\n",
      "Epoch 455/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1641\n",
      "Epoch 455: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1622 - val_loss: 0.1763\n",
      "Epoch 456/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1623\n",
      "Epoch 456: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1613 - val_loss: 0.1752\n",
      "Epoch 457/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1535\n",
      "Epoch 457: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1592 - val_loss: 0.1750\n",
      "Epoch 458/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1612\n",
      "Epoch 458: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1596 - val_loss: 0.1724\n",
      "Epoch 459/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1600\n",
      "Epoch 459: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.1602 - val_loss: 0.1760\n",
      "Epoch 460/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1648\n",
      "Epoch 460: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1627 - val_loss: 0.1736\n",
      "Epoch 461/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1681\n",
      "Epoch 461: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1618 - val_loss: 0.1748\n",
      "Epoch 462/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1542\n",
      "Epoch 462: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1604 - val_loss: 0.1780\n",
      "Epoch 463/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1537\n",
      "Epoch 463: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1587 - val_loss: 0.1737\n",
      "Epoch 464/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1602\n",
      "Epoch 464: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1608 - val_loss: 0.1773\n",
      "Epoch 465/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1568\n",
      "Epoch 465: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1589 - val_loss: 0.1757\n",
      "Epoch 466/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1560\n",
      "Epoch 466: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1582 - val_loss: 0.1759\n",
      "Epoch 467/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1631\n",
      "Epoch 467: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1587 - val_loss: 0.1832\n",
      "Epoch 468/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1605\n",
      "Epoch 468: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1623 - val_loss: 0.1743\n",
      "Epoch 469/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1560\n",
      "Epoch 469: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1566 - val_loss: 0.1740\n",
      "Epoch 470/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1564\n",
      "Epoch 470: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1567 - val_loss: 0.1744\n",
      "Epoch 471/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1513\n",
      "Epoch 471: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1584 - val_loss: 0.1770\n",
      "Epoch 472/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1619\n",
      "Epoch 472: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1611 - val_loss: 0.1746\n",
      "Epoch 473/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1681\n",
      "Epoch 473: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1630 - val_loss: 0.1775\n",
      "Epoch 474/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1569\n",
      "Epoch 474: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1585 - val_loss: 0.1760\n",
      "Epoch 475/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1615\n",
      "Epoch 475: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1598 - val_loss: 0.1784\n",
      "Epoch 476/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1546\n",
      "Epoch 476: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1592 - val_loss: 0.1750\n",
      "Epoch 477/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1615\n",
      "Epoch 477: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1616 - val_loss: 0.1799\n",
      "Epoch 478/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1557\n",
      "Epoch 478: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1575 - val_loss: 0.1742\n",
      "Epoch 479/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1657\n",
      "Epoch 479: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1610 - val_loss: 0.1738\n",
      "Epoch 480/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1607\n",
      "Epoch 480: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1589 - val_loss: 0.1740\n",
      "Epoch 481/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1642\n",
      "Epoch 481: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1603 - val_loss: 0.1734\n",
      "Epoch 482/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1690\n",
      "Epoch 482: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1639 - val_loss: 0.1740\n",
      "Epoch 483/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1557\n",
      "Epoch 483: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1576 - val_loss: 0.1761\n",
      "Epoch 484/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1536\n",
      "Epoch 484: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1574 - val_loss: 0.1763\n",
      "Epoch 485/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1463\n",
      "Epoch 485: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1538 - val_loss: 0.1770\n",
      "Epoch 486/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1593\n",
      "Epoch 486: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1600 - val_loss: 0.1740\n",
      "Epoch 487/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1435\n",
      "Epoch 487: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1526 - val_loss: 0.1771\n",
      "Epoch 488/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1482\n",
      "Epoch 488: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1559 - val_loss: 0.1760\n",
      "Epoch 489/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1649\n",
      "Epoch 489: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1614 - val_loss: 0.1766\n",
      "Epoch 490/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1571\n",
      "Epoch 490: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1604 - val_loss: 0.1776\n",
      "Epoch 491/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1539\n",
      "Epoch 491: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1572 - val_loss: 0.1750\n",
      "Epoch 492/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1443\n",
      "Epoch 492: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1542 - val_loss: 0.1794\n",
      "Epoch 493/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1429\n",
      "Epoch 493: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1547 - val_loss: 0.1754\n",
      "Epoch 494/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1575\n",
      "Epoch 494: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1596 - val_loss: 0.1770\n",
      "Epoch 495/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1599\n",
      "Epoch 495: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1576 - val_loss: 0.1774\n",
      "Epoch 496/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1554\n",
      "Epoch 496: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1601 - val_loss: 0.1740\n",
      "Epoch 497/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1530\n",
      "Epoch 497: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1566 - val_loss: 0.1770\n",
      "Epoch 498/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1599\n",
      "Epoch 498: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1584 - val_loss: 0.1774\n",
      "Epoch 499/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1473\n",
      "Epoch 499: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1520 - val_loss: 0.1768\n",
      "Epoch 500/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1604\n",
      "Epoch 500: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1583 - val_loss: 0.1755\n",
      "Epoch 501/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1405\n",
      "Epoch 501: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1539 - val_loss: 0.1782\n",
      "Epoch 502/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1470\n",
      "Epoch 502: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1545 - val_loss: 0.1765\n",
      "Epoch 503/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1501\n",
      "Epoch 503: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1552 - val_loss: 0.1798\n",
      "Epoch 504/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1612\n",
      "Epoch 504: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1574 - val_loss: 0.1812\n",
      "Epoch 505/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1512\n",
      "Epoch 505: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1547 - val_loss: 0.1786\n",
      "Epoch 506/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1576\n",
      "Epoch 506: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1577 - val_loss: 0.1809\n",
      "Epoch 507/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1519\n",
      "Epoch 507: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1584 - val_loss: 0.1755\n",
      "Epoch 508/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1598\n",
      "Epoch 508: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1565 - val_loss: 0.1752\n",
      "Epoch 509/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1556\n",
      "Epoch 509: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1577 - val_loss: 0.1802\n",
      "Epoch 510/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1571\n",
      "Epoch 510: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1571 - val_loss: 0.1758\n",
      "Epoch 511/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1537\n",
      "Epoch 511: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1552 - val_loss: 0.1778\n",
      "Epoch 512/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1550\n",
      "Epoch 512: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1559 - val_loss: 0.1749\n",
      "Epoch 513/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1567\n",
      "Epoch 513: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1575 - val_loss: 0.1754\n",
      "Epoch 514/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1455\n",
      "Epoch 514: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1541 - val_loss: 0.1781\n",
      "Epoch 515/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1488\n",
      "Epoch 515: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1539 - val_loss: 0.1738\n",
      "Epoch 516/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1590\n",
      "Epoch 516: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1569 - val_loss: 0.1744\n",
      "Epoch 517/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1628\n",
      "Epoch 517: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1602 - val_loss: 0.1780\n",
      "Epoch 518/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1615\n",
      "Epoch 518: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1579 - val_loss: 0.1735\n",
      "Epoch 519/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1525\n",
      "Epoch 519: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1551 - val_loss: 0.1743\n",
      "Epoch 520/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1563\n",
      "Epoch 520: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1561 - val_loss: 0.1738\n",
      "Epoch 521/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1508\n",
      "Epoch 521: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1543 - val_loss: 0.1762\n",
      "Epoch 522/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1650\n",
      "Epoch 522: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1599 - val_loss: 0.1730\n",
      "Epoch 523/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1496\n",
      "Epoch 523: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1541 - val_loss: 0.1763\n",
      "Epoch 524/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1507\n",
      "Epoch 524: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1551 - val_loss: 0.1781\n",
      "Epoch 525/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1531\n",
      "Epoch 525: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1556 - val_loss: 0.1821\n",
      "Epoch 526/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1703\n",
      "Epoch 526: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1594 - val_loss: 0.1754\n",
      "Epoch 527/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1607\n",
      "Epoch 527: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1582 - val_loss: 0.1782\n",
      "Epoch 528/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1632\n",
      "Epoch 528: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1578 - val_loss: 0.1783\n",
      "Epoch 529/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1572\n",
      "Epoch 529: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1575 - val_loss: 0.1765\n",
      "Epoch 530/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1549\n",
      "Epoch 530: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1553 - val_loss: 0.1757\n",
      "Epoch 531/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1547\n",
      "Epoch 531: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1537 - val_loss: 0.1790\n",
      "Epoch 532/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1509\n",
      "Epoch 532: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1536 - val_loss: 0.1772\n",
      "Epoch 533/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1528\n",
      "Epoch 533: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1541 - val_loss: 0.1821\n",
      "Epoch 534/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1516\n",
      "Epoch 534: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1537 - val_loss: 0.1759\n",
      "Epoch 535/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1507\n",
      "Epoch 535: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1534 - val_loss: 0.1786\n",
      "Epoch 536/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1544\n",
      "Epoch 536: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1569 - val_loss: 0.1765\n",
      "Epoch 537/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1570\n",
      "Epoch 537: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1550 - val_loss: 0.1784\n",
      "Epoch 538/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1491\n",
      "Epoch 538: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1523 - val_loss: 0.1800\n",
      "Epoch 539/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1482\n",
      "Epoch 539: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1533 - val_loss: 0.1786\n",
      "Epoch 540/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1518\n",
      "Epoch 540: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1535 - val_loss: 0.1771\n",
      "Epoch 541/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1452\n",
      "Epoch 541: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1500 - val_loss: 0.1811\n",
      "Epoch 542/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1517\n",
      "Epoch 542: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1544 - val_loss: 0.1832\n",
      "Epoch 543/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1514\n",
      "Epoch 543: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1515 - val_loss: 0.1798\n",
      "Epoch 544/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1488\n",
      "Epoch 544: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1519 - val_loss: 0.1782\n",
      "Epoch 545/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1502\n",
      "Epoch 545: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1535 - val_loss: 0.1780\n",
      "Epoch 546/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1613\n",
      "Epoch 546: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1573 - val_loss: 0.1806\n",
      "Epoch 547/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1492\n",
      "Epoch 547: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1529 - val_loss: 0.1800\n",
      "Epoch 548/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1496\n",
      "Epoch 548: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1504 - val_loss: 0.1752\n",
      "Epoch 549/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1420\n",
      "Epoch 549: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1510 - val_loss: 0.1822\n",
      "Epoch 550/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1533\n",
      "Epoch 550: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1532 - val_loss: 0.1810\n",
      "Epoch 551/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1552\n",
      "Epoch 551: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1533 - val_loss: 0.1795\n",
      "Epoch 552/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1467\n",
      "Epoch 552: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1507 - val_loss: 0.1790\n",
      "Epoch 553/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1512\n",
      "Epoch 553: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1544 - val_loss: 0.1810\n",
      "Epoch 554/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1645\n",
      "Epoch 554: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1577 - val_loss: 0.1787\n",
      "Epoch 555/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1529\n",
      "Epoch 555: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1534 - val_loss: 0.1777\n",
      "Epoch 556/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1546\n",
      "Epoch 556: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1546 - val_loss: 0.1798\n",
      "Epoch 557/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1523\n",
      "Epoch 557: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1536 - val_loss: 0.1816\n",
      "Epoch 558/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1523\n",
      "Epoch 558: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1538 - val_loss: 0.1763\n",
      "Epoch 559/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1554\n",
      "Epoch 559: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1541 - val_loss: 0.1821\n",
      "Epoch 560/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1636\n",
      "Epoch 560: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1560 - val_loss: 0.1766\n",
      "Epoch 561/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1611\n",
      "Epoch 561: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1519 - val_loss: 0.1780\n",
      "Epoch 562/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1526\n",
      "Epoch 562: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1536 - val_loss: 0.1815\n",
      "Epoch 563/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1566\n",
      "Epoch 563: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1564 - val_loss: 0.1776\n",
      "Epoch 564/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1500\n",
      "Epoch 564: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1516 - val_loss: 0.1801\n",
      "Epoch 565/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1534\n",
      "Epoch 565: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1515 - val_loss: 0.1815\n",
      "Epoch 566/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1432\n",
      "Epoch 566: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1492 - val_loss: 0.1827\n",
      "Epoch 567/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1509\n",
      "Epoch 567: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1517 - val_loss: 0.1782\n",
      "Epoch 568/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1490\n",
      "Epoch 568: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1503 - val_loss: 0.1798\n",
      "Epoch 569/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1391\n",
      "Epoch 569: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1459 - val_loss: 0.1756\n",
      "Epoch 570/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1533\n",
      "Epoch 570: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1508 - val_loss: 0.1823\n",
      "Epoch 571/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1497\n",
      "Epoch 571: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1515 - val_loss: 0.1766\n",
      "Epoch 572/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1529\n",
      "Epoch 572: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1509 - val_loss: 0.1784\n",
      "Epoch 573/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1504\n",
      "Epoch 573: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1514 - val_loss: 0.1785\n",
      "Epoch 574/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1533\n",
      "Epoch 574: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1545 - val_loss: 0.1792\n",
      "Epoch 575/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1511\n",
      "Epoch 575: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1531 - val_loss: 0.1797\n",
      "Epoch 576/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1623\n",
      "Epoch 576: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1578 - val_loss: 0.1850\n",
      "Epoch 577/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1425\n",
      "Epoch 577: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1495 - val_loss: 0.1752\n",
      "Epoch 578/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1583\n",
      "Epoch 578: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1528 - val_loss: 0.1774\n",
      "Epoch 579/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1477\n",
      "Epoch 579: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1519 - val_loss: 0.1813\n",
      "Epoch 580/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1416\n",
      "Epoch 580: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1488 - val_loss: 0.1796\n",
      "Epoch 581/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1564\n",
      "Epoch 581: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1522 - val_loss: 0.1813\n",
      "Epoch 582/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1478\n",
      "Epoch 582: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1504 - val_loss: 0.1757\n",
      "Epoch 583/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1518\n",
      "Epoch 583: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1511 - val_loss: 0.1813\n",
      "Epoch 584/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1542\n",
      "Epoch 584: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1523 - val_loss: 0.1749\n",
      "Epoch 585/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1475\n",
      "Epoch 585: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1497 - val_loss: 0.1758\n",
      "Epoch 586/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1490\n",
      "Epoch 586: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1515 - val_loss: 0.1753\n",
      "Epoch 587/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1530\n",
      "Epoch 587: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1509 - val_loss: 0.1788\n",
      "Epoch 588/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1482\n",
      "Epoch 588: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1505 - val_loss: 0.1758\n",
      "Epoch 589/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1490\n",
      "Epoch 589: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1528 - val_loss: 0.1794\n",
      "Epoch 590/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1537\n",
      "Epoch 590: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1510 - val_loss: 0.1788\n",
      "Epoch 591/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1531\n",
      "Epoch 591: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1505 - val_loss: 0.1759\n",
      "Epoch 592/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1557\n",
      "Epoch 592: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1514 - val_loss: 0.1773\n",
      "Epoch 593/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1524\n",
      "Epoch 593: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1512 - val_loss: 0.1794\n",
      "Epoch 594/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1491\n",
      "Epoch 594: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1505 - val_loss: 0.1763\n",
      "Epoch 595/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1365\n",
      "Epoch 595: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1463 - val_loss: 0.1779\n",
      "Epoch 596/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1461\n",
      "Epoch 596: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1490 - val_loss: 0.1743\n",
      "Epoch 597/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1509\n",
      "Epoch 597: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1495 - val_loss: 0.1805\n",
      "Epoch 598/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1525\n",
      "Epoch 598: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1500 - val_loss: 0.1796\n",
      "Epoch 599/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1426\n",
      "Epoch 599: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1470 - val_loss: 0.1842\n",
      "Epoch 600/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1536\n",
      "Epoch 600: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1519 - val_loss: 0.1792\n",
      "Epoch 601/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1372\n",
      "Epoch 601: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1467 - val_loss: 0.1786\n",
      "Epoch 602/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1500\n",
      "Epoch 602: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1488 - val_loss: 0.1799\n",
      "Epoch 603/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1519\n",
      "Epoch 603: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1495 - val_loss: 0.1803\n",
      "Epoch 604/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1439\n",
      "Epoch 604: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1484 - val_loss: 0.1832\n",
      "Epoch 605/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1560\n",
      "Epoch 605: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1528 - val_loss: 0.1777\n",
      "Epoch 606/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1442\n",
      "Epoch 606: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1492 - val_loss: 0.1831\n",
      "Epoch 607/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1544\n",
      "Epoch 607: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1518 - val_loss: 0.1773\n",
      "Epoch 608/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1478\n",
      "Epoch 608: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1499 - val_loss: 0.1886\n",
      "Epoch 609/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1525\n",
      "Epoch 609: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1495 - val_loss: 0.1773\n",
      "Epoch 610/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1504\n",
      "Epoch 610: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1503 - val_loss: 0.1793\n",
      "Epoch 611/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1474\n",
      "Epoch 611: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1503 - val_loss: 0.1781\n",
      "Epoch 612/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1423\n",
      "Epoch 612: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1470 - val_loss: 0.1875\n",
      "Epoch 613/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1442\n",
      "Epoch 613: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1483 - val_loss: 0.1773\n",
      "Epoch 614/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1588\n",
      "Epoch 614: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1519 - val_loss: 0.1819\n",
      "Epoch 615/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1556\n",
      "Epoch 615: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1520 - val_loss: 0.1766\n",
      "Epoch 616/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1522\n",
      "Epoch 616: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1493 - val_loss: 0.1774\n",
      "Epoch 617/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1461\n",
      "Epoch 617: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1490 - val_loss: 0.1829\n",
      "Epoch 618/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1454\n",
      "Epoch 618: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1485 - val_loss: 0.1746\n",
      "Epoch 619/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1389\n",
      "Epoch 619: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1457 - val_loss: 0.1826\n",
      "Epoch 620/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1420\n",
      "Epoch 620: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1467 - val_loss: 0.1751\n",
      "Epoch 621/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1519\n",
      "Epoch 621: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1488 - val_loss: 0.1779\n",
      "Epoch 622/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1554\n",
      "Epoch 622: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1514 - val_loss: 0.1789\n",
      "Epoch 623/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1579\n",
      "Epoch 623: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1512 - val_loss: 0.1767\n",
      "Epoch 624/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1466\n",
      "Epoch 624: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1490 - val_loss: 0.1827\n",
      "Epoch 625/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1580\n",
      "Epoch 625: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1523 - val_loss: 0.1800\n",
      "Epoch 626/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1518\n",
      "Epoch 626: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1492 - val_loss: 0.1874\n",
      "Epoch 627/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1528\n",
      "Epoch 627: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1503 - val_loss: 0.1783\n",
      "Epoch 628/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1445\n",
      "Epoch 628: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1464 - val_loss: 0.1807\n",
      "Epoch 629/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1471\n",
      "Epoch 629: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1489 - val_loss: 0.1800\n",
      "Epoch 630/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1567\n",
      "Epoch 630: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1493 - val_loss: 0.1758\n",
      "Epoch 631/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1480\n",
      "Epoch 631: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1464 - val_loss: 0.1805\n",
      "Epoch 632/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1489\n",
      "Epoch 632: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1486 - val_loss: 0.1763\n",
      "Epoch 633/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1368\n",
      "Epoch 633: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1453 - val_loss: 0.1772\n",
      "Epoch 634/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1609\n",
      "Epoch 634: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1506 - val_loss: 0.1837\n",
      "Epoch 635/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1337\n",
      "Epoch 635: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1424 - val_loss: 0.1859\n",
      "Epoch 636/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1416\n",
      "Epoch 636: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1451 - val_loss: 0.1781\n",
      "Epoch 637/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1515\n",
      "Epoch 637: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1486 - val_loss: 0.1796\n",
      "Epoch 638/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1474\n",
      "Epoch 638: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1467 - val_loss: 0.1758\n",
      "Epoch 639/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1462\n",
      "Epoch 639: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1470 - val_loss: 0.1820\n",
      "Epoch 640/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1580\n",
      "Epoch 640: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1509 - val_loss: 0.1799\n",
      "Epoch 641/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1522\n",
      "Epoch 641: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1489 - val_loss: 0.1818\n",
      "Epoch 642/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1533\n",
      "Epoch 642: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1478 - val_loss: 0.1833\n",
      "Epoch 643/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1387\n",
      "Epoch 643: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1457 - val_loss: 0.1816\n",
      "Epoch 644/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1449\n",
      "Epoch 644: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1475 - val_loss: 0.1879\n",
      "Epoch 645/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1424\n",
      "Epoch 645: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1436 - val_loss: 0.1815\n",
      "Epoch 646/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1478\n",
      "Epoch 646: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1480 - val_loss: 0.1803\n",
      "Epoch 647/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1460\n",
      "Epoch 647: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1454 - val_loss: 0.1814\n",
      "Epoch 648/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1415\n",
      "Epoch 648: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1445 - val_loss: 0.1783\n",
      "Epoch 649/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1515\n",
      "Epoch 649: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1477 - val_loss: 0.1831\n",
      "Epoch 650/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1433\n",
      "Epoch 650: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1454 - val_loss: 0.1818\n",
      "Epoch 651/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1462\n",
      "Epoch 651: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1474 - val_loss: 0.1785\n",
      "Epoch 652/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1494\n",
      "Epoch 652: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1479 - val_loss: 0.1773\n",
      "Epoch 653/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1538\n",
      "Epoch 653: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1495 - val_loss: 0.1759\n",
      "Epoch 654/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1501\n",
      "Epoch 654: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1498 - val_loss: 0.1758\n",
      "Epoch 655/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1512\n",
      "Epoch 655: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1484 - val_loss: 0.1814\n",
      "Epoch 656/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1455\n",
      "Epoch 656: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1479 - val_loss: 0.1771\n",
      "Epoch 657/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1471\n",
      "Epoch 657: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1461 - val_loss: 0.1800\n",
      "Epoch 658/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1591\n",
      "Epoch 658: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1507 - val_loss: 0.1801\n",
      "Epoch 659/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1454\n",
      "Epoch 659: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1469 - val_loss: 0.1790\n",
      "Epoch 660/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1457\n",
      "Epoch 660: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1457 - val_loss: 0.1835\n",
      "Epoch 661/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1408\n",
      "Epoch 661: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1460 - val_loss: 0.1826\n",
      "Epoch 662/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1449\n",
      "Epoch 662: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1449 - val_loss: 0.1782\n",
      "Epoch 663/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1407\n",
      "Epoch 663: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1421 - val_loss: 0.1848\n",
      "Epoch 664/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1516\n",
      "Epoch 664: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1487 - val_loss: 0.1816\n",
      "Epoch 665/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1388\n",
      "Epoch 665: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1445 - val_loss: 0.1816\n",
      "Epoch 666/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1504\n",
      "Epoch 666: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1476 - val_loss: 0.1765\n",
      "Epoch 667/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1458\n",
      "Epoch 667: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1455 - val_loss: 0.1814\n",
      "Epoch 668/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1492\n",
      "Epoch 668: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1490 - val_loss: 0.1810\n",
      "Epoch 669/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1429\n",
      "Epoch 669: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1459 - val_loss: 0.1855\n",
      "Epoch 670/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1468\n",
      "Epoch 670: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1466 - val_loss: 0.1876\n",
      "Epoch 671/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1522\n",
      "Epoch 671: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1474 - val_loss: 0.1825\n",
      "Epoch 672/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1516\n",
      "Epoch 672: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1488 - val_loss: 0.1799\n",
      "Epoch 673/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1430\n",
      "Epoch 673: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1436 - val_loss: 0.1891\n",
      "Epoch 674/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1350\n",
      "Epoch 674: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1408 - val_loss: 0.1802\n",
      "Epoch 675/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1543\n",
      "Epoch 675: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1482 - val_loss: 0.1853\n",
      "Epoch 676/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1442\n",
      "Epoch 676: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1471 - val_loss: 0.1830\n",
      "Epoch 677/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1544\n",
      "Epoch 677: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1471 - val_loss: 0.1884\n",
      "Epoch 678/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1381\n",
      "Epoch 678: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1434 - val_loss: 0.1866\n",
      "Epoch 679/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1485\n",
      "Epoch 679: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1476 - val_loss: 0.1785\n",
      "Epoch 680/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1413\n",
      "Epoch 680: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1455 - val_loss: 0.1803\n",
      "Epoch 681/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1435\n",
      "Epoch 681: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1448 - val_loss: 0.1859\n",
      "Epoch 682/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1484\n",
      "Epoch 682: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1465 - val_loss: 0.1837\n",
      "Epoch 683/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1388\n",
      "Epoch 683: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1439 - val_loss: 0.1807\n",
      "Epoch 684/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1352\n",
      "Epoch 684: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1425 - val_loss: 0.1814\n",
      "Epoch 685/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1387\n",
      "Epoch 685: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1444 - val_loss: 0.1840\n",
      "Epoch 686/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1450\n",
      "Epoch 686: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1454 - val_loss: 0.1817\n",
      "Epoch 687/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1348\n",
      "Epoch 687: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1413 - val_loss: 0.1799\n",
      "Epoch 688/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1356\n",
      "Epoch 688: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1422 - val_loss: 0.1806\n",
      "Epoch 689/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1433\n",
      "Epoch 689: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1443 - val_loss: 0.1846\n",
      "Epoch 690/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1488\n",
      "Epoch 690: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1454 - val_loss: 0.1860\n",
      "Epoch 691/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1416\n",
      "Epoch 691: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1435 - val_loss: 0.1860\n",
      "Epoch 692/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1436\n",
      "Epoch 692: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1434 - val_loss: 0.1826\n",
      "Epoch 693/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1545\n",
      "Epoch 693: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1478 - val_loss: 0.1856\n",
      "Epoch 694/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1444\n",
      "Epoch 694: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1462 - val_loss: 0.1857\n",
      "Epoch 695/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1429\n",
      "Epoch 695: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1438 - val_loss: 0.1803\n",
      "Epoch 696/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1501\n",
      "Epoch 696: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1450 - val_loss: 0.1837\n",
      "Epoch 697/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1431\n",
      "Epoch 697: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1447 - val_loss: 0.1800\n",
      "Epoch 698/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1474\n",
      "Epoch 698: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1455 - val_loss: 0.1833\n",
      "Epoch 699/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1371\n",
      "Epoch 699: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1404 - val_loss: 0.1789\n",
      "Epoch 700/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1431\n",
      "Epoch 700: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1440 - val_loss: 0.1879\n",
      "Epoch 701/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1467\n",
      "Epoch 701: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1448 - val_loss: 0.1838\n",
      "Epoch 702/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1382\n",
      "Epoch 702: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1434 - val_loss: 0.1839\n",
      "Epoch 703/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1472\n",
      "Epoch 703: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1444 - val_loss: 0.1866\n",
      "Epoch 704/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1431\n",
      "Epoch 704: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1445 - val_loss: 0.1841\n",
      "Epoch 705/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1454\n",
      "Epoch 705: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1442 - val_loss: 0.1865\n",
      "Epoch 706/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1286\n",
      "Epoch 706: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1396 - val_loss: 0.1821\n",
      "Epoch 707/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1465\n",
      "Epoch 707: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1437 - val_loss: 0.1853\n",
      "Epoch 708/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1493\n",
      "Epoch 708: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1468 - val_loss: 0.1781\n",
      "Epoch 709/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1389\n",
      "Epoch 709: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1411 - val_loss: 0.1841\n",
      "Epoch 710/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1442\n",
      "Epoch 710: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1441 - val_loss: 0.1827\n",
      "Epoch 711/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1419\n",
      "Epoch 711: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1425 - val_loss: 0.1849\n",
      "Epoch 712/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1417\n",
      "Epoch 712: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1448 - val_loss: 0.1805\n",
      "Epoch 713/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1615\n",
      "Epoch 713: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1502 - val_loss: 0.1853\n",
      "Epoch 714/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1411\n",
      "Epoch 714: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1415 - val_loss: 0.1855\n",
      "Epoch 715/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1387\n",
      "Epoch 715: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1432 - val_loss: 0.1800\n",
      "Epoch 716/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1496\n",
      "Epoch 716: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1463 - val_loss: 0.1853\n",
      "Epoch 717/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1374\n",
      "Epoch 717: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1399 - val_loss: 0.1847\n",
      "Epoch 718/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1423\n",
      "Epoch 718: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1431 - val_loss: 0.1840\n",
      "Epoch 719/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1399\n",
      "Epoch 719: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1411 - val_loss: 0.1850\n",
      "Epoch 720/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1399\n",
      "Epoch 720: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1424 - val_loss: 0.1813\n",
      "Epoch 721/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1352\n",
      "Epoch 721: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1393 - val_loss: 0.1868\n",
      "Epoch 722/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1376\n",
      "Epoch 722: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1418 - val_loss: 0.1830\n",
      "Epoch 723/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1436\n",
      "Epoch 723: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1423 - val_loss: 0.1841\n",
      "Epoch 724/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1405\n",
      "Epoch 724: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1429 - val_loss: 0.1801\n",
      "Epoch 725/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1370\n",
      "Epoch 725: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1381 - val_loss: 0.1864\n",
      "Epoch 726/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1477\n",
      "Epoch 726: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1419 - val_loss: 0.1879\n",
      "Epoch 727/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1444\n",
      "Epoch 727: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1442 - val_loss: 0.1831\n",
      "Epoch 728/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1375\n",
      "Epoch 728: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1401 - val_loss: 0.1840\n",
      "Epoch 729/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1366\n",
      "Epoch 729: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1418 - val_loss: 0.1803\n",
      "Epoch 730/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1402\n",
      "Epoch 730: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1424 - val_loss: 0.1853\n",
      "Epoch 731/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1486\n",
      "Epoch 731: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1442 - val_loss: 0.1832\n",
      "Epoch 732/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1403\n",
      "Epoch 732: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1411 - val_loss: 0.1851\n",
      "Epoch 733/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1393\n",
      "Epoch 733: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1410 - val_loss: 0.1892\n",
      "Epoch 734/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1499\n",
      "Epoch 734: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1481 - val_loss: 0.1821\n",
      "Epoch 735/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1441\n",
      "Epoch 735: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1418 - val_loss: 0.1906\n",
      "Epoch 736/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1389\n",
      "Epoch 736: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1413 - val_loss: 0.1826\n",
      "Epoch 737/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1521\n",
      "Epoch 737: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1441 - val_loss: 0.1826\n",
      "Epoch 738/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1469\n",
      "Epoch 738: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1449 - val_loss: 0.1871\n",
      "Epoch 739/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1444\n",
      "Epoch 739: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1426 - val_loss: 0.1856\n",
      "Epoch 740/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1347\n",
      "Epoch 740: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1382 - val_loss: 0.1820\n",
      "Epoch 741/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1426\n",
      "Epoch 741: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1403 - val_loss: 0.1890\n",
      "Epoch 742/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1453\n",
      "Epoch 742: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1419 - val_loss: 0.1824\n",
      "Epoch 743/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1363\n",
      "Epoch 743: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1406 - val_loss: 0.1903\n",
      "Epoch 744/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1389\n",
      "Epoch 744: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1392 - val_loss: 0.1834\n",
      "Epoch 745/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1368\n",
      "Epoch 745: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1398 - val_loss: 0.1875\n",
      "Epoch 746/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1371\n",
      "Epoch 746: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1413 - val_loss: 0.1882\n",
      "Epoch 747/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1473\n",
      "Epoch 747: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1436 - val_loss: 0.1814\n",
      "Epoch 748/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1374\n",
      "Epoch 748: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1404 - val_loss: 0.1826\n",
      "Epoch 749/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1339\n",
      "Epoch 749: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1395 - val_loss: 0.1862\n",
      "Epoch 750/750\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1427\n",
      "Epoch 750: val_loss did not improve from 0.17104\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1438 - val_loss: 0.1834\n"
     ]
    }
   ],
   "source": [
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"hurricane_lstm.keras\",\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    verbose=1)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=750,\n",
    "                    batch_size=512,\n",
    "                    validation_split=0.25,\n",
    "                    callbacks=[tensorboard_callback, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "94ebb59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"hurricane_lstm.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "7842e2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  12.7,  133.6,   15. , 1000. ],\n",
       "       [  13.2,  133.2,   20. ,  995. ],\n",
       "       [  13.9,  132.8,   20. ,  990. ],\n",
       "       [  14.5,  132.3,   30. ,  982. ],\n",
       "       [  15.1,  132. ,   35. ,  974. ],\n",
       "       [  15.9,  131.7,   45. ,  967. ],\n",
       "       [  16.6,  131.4,   50. ,  960. ],\n",
       "       [  17.2,  131.2,   50. ,  960. ],\n",
       "       [  18. ,  131. ,   50. ,  960. ],\n",
       "       [  18.8,  130.9,   50. ,  960. ],\n",
       "       [  19.5,  130.8,   50. ,  960. ],\n",
       "       [  20.3,  130.7,   50. ,  960. ],\n",
       "       [  21.3,  130.6,   50. ,  960. ],\n",
       "       [  22.4,  130.4,   50. ,  960. ],\n",
       "       [  23.9,  129.7,   50. ,  960. ],\n",
       "       [  25.3,  128.6,   50. ,  960. ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use the model to predict the next 10 time steps\n",
    "# use the last 10 time steps from the training set\n",
    "# random pick a sample\n",
    "random_sample_idx = random.randint(0, X_train.shape[0])\n",
    "X_sample = features[random_sample_idx, :, :]\n",
    "X_sample = X_sample.reshape(1, X_sample.shape[0], X_sample.shape[1])\n",
    "X_sample.shape\n",
    "wind_sample = wind_scaler.inverse_transform(X_sample[0, :, 6].reshape(-1, 1))\n",
    "pressure_sample = lowest_pressure_scaler.inverse_transform(X_sample[0, :, 7].reshape(-1, 1))\n",
    "lat_sample = lat_scaler.inverse_transform(X_sample[0, :, 4].reshape(-1, 1))\n",
    "long_sample = long_scaler.inverse_transform(X_sample[0, :, 5].reshape(-1, 1))\n",
    "X_test_example = np.hstack((lat_sample, long_sample, wind_sample, pressure_sample))\n",
    "display(X_test_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "403aa27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 23.129938, 123.03219 ,  35.589275, 985.6444  ],\n",
       "       [ 24.28164 , 123.31897 ,  31.018965, 987.44025 ],\n",
       "       [ 26.253365, 124.879974,  29.498682, 989.32886 ],\n",
       "       [ 27.790798, 125.686226,  27.595375, 992.2364  ],\n",
       "       [ 28.93821 , 125.52733 ,  26.026371, 994.45953 ],\n",
       "       [ 29.484936, 124.95974 ,  25.823515, 993.9464  ],\n",
       "       [ 29.832735, 125.02653 ,  25.953444, 992.32275 ],\n",
       "       [ 29.590643, 125.450645,  25.360807, 991.0488  ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 18. , 131. ,  50. , 960. ],\n",
       "       [ 18.8, 130.9,  50. , 960. ],\n",
       "       [ 19.5, 130.8,  50. , 960. ],\n",
       "       [ 20.3, 130.7,  50. , 960. ],\n",
       "       [ 21.3, 130.6,  50. , 960. ],\n",
       "       [ 22.4, 130.4,  50. , 960. ],\n",
       "       [ 23.9, 129.7,  50. , 960. ],\n",
       "       [ 25.3, 128.6,  50. , 960. ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_sample[:, X_TIME_STEPS:, :])\n",
    "y_pred.shape\n",
    "# reverse the normalization\n",
    "wind_pred = wind_scaler.inverse_transform(y_pred[:, :, 2])\n",
    "pressure_pred = lowest_pressure_scaler.inverse_transform(y_pred[:, :, 3])\n",
    "lat_pred = lat_scaler.inverse_transform(y_pred[:, :, 0])\n",
    "long_pred = long_scaler.inverse_transform(y_pred[:, :, 1])\n",
    "pred = np.vstack((lat_pred, long_pred, wind_pred, pressure_pred)).T\n",
    "display(pred)\n",
    "expected = X_test_example[-Y_TIME_STEPS:, :]\n",
    "display(expected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
